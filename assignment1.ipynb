{"cells":[{"cell_type":"markdown","metadata":{"id":"4j05XaIOUvcf"},"source":["#  Assignment 1 - Language Model Foundations"]},{"cell_type":"markdown","metadata":{"id":"GA3bGKeGUvcl"},"source":["<div style=\"padding:15px 20px 20px 20px;border-left:3px solid green;background-color:#e4fae4;border-radius: 20px;color:#424242;\">\n","\n","Welcome to the **1st assignment** for the **CS-552: Modern NLP course**!\n","\n","- üòÄ Name: **Abdurrahman Said G√ºrb√ºz**\n","- ‚úâÔ∏è Email: **said.gurbuz@epfl.ch**\n","- ü™™ SCIPER: **369141**\n","\n","In the first two parts of this assignment, you need to construct a dataset and use it to train language models (LSTM and Transformer);\n","\n","In the third part, you will finetune language models (RNN-based and Transformer-based Encoder-Decoder) on a text simplification task.\n","\n","### **Tasks**\n","- **[PART 1: Data Preprocessing](#1)**\n","    - [1.1 Data Cleaning](#11)\n","    - [1.2 Build Vocabulary](#12)\n","    - [1.2 Get PyTorch Dataset](#13)\n","- **[PART 2: Training Language Models](#2)**\n","    - [2.1 Vanilla LSTM](#21)\n","    - [2.2 Transformer (DistilGPT2)](#22)\n","- **[PART 3: Finetuning Language Models](#3)**\n","    - [3.1 Encoder-Decoder Model](#31)\n","    - [3.2 Transformer (T5)](#32)\n","\n","\n","### **Deliverables**\n","- ‚úÖ This Jupyter notebook\n","- ‚úÖ `data.py`, `modeling.py` file\n","- ‚úÖ Checkpoints for two LSTM-variant and DistilGPT2 language models (Part 2)\n","- ‚úÖ Checkpoints for finetuned encoder-decoder and T5 language models (Part 3)\n","- ‚úÖ `./tensorboard` directory with logs for all trained/finetuned models\n","\n","Large files such as model checkpoints and logs should be pushed to the repository with Git LFS. You may also find that training the models on a GPU can speed up the process, we recommend using Colab's free GPU service for this. A tutorial on how to use Git LFS and Colab can be found [here](https://github.com/epfl-nlp/cs-552-modern-nlp/blob/main/Exercises/tutorials.md).\n","\n","</div>"]},{"cell_type":"markdown","metadata":{},"source":["<div style=\"padding:15px 20px 20px 20px;border-left:3px solid orange;background-color:#fff5d6;border-radius: 20px;color:#424242;\">\n","\n","## How to implement this assignment\n","\n","Please read carefully the following points. All the information on how to read, implement and submit your assignment is explained in detail below.\n","\n","1. For this assignment, you will need to implement and fill in the missing code snippets for both the **Jupyter Notebook** `assignment1.ipynb` and the `data.py` and `modeling.py` python files. In the `data.py` and `modeling.py` files, you will add all the Dataset and Model classes you will implement according to the skeleton present in the files. In the notebook, you will use the definitions from those python files to prepare datasets, train and finetune models and add the report at the end.\n","\n","2. To implement your coding part, you can import the external libraries we provide in the `requirements.txt` file, however, you should not use any other package not included in these requirements. We recommend using **python=3.10** for this assignment\n","\n","3. At the end of the notebook, you will need to fill in a **report** template, providing the results of your implementation. We provide you with the template for the report, therefore you need to fill in the missing Markdown cells with the requested information. \n","\n","4. Along with the `assignment1.ipynb` and the `data.py`, `modeling.py` files, you need to additionally upload model files under the `models/` dir, regarding the following models:\n","    - the two LSTM-variant models (PART 2)  \n","    - the trained-from-scratch DistilGPT2 model (PART 2) \n","    - the fine-tuned Encoder-Decoder model (PART 3) \n","    - the fine-tuned T5 model (PART 3)\n","    \n","You will provide test results on all of the model variants according to the report template.\n","\n","5. Finally, you will need to log your training pipelines using Tensorboard. Please follow the instructions in the `README.md` of the [tensorboard/](tensorboard/README.md) directory.\n","</div>"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# This cell makes sure modules are auto-loaded when you change external python files\n","%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# If you are working in Colab, then consider mounting your assignment folder to your drive\n","# from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# and change the path below to point to the assignment folder\n","# %cd /content/drive/MyDrive/path-to-your-assignment-folder"]},{"cell_type":"markdown","metadata":{"id":"YYTL0zJ1nIE_"},"source":["### Setup"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":205,"status":"ok","timestamp":1707662501644,"user":{"displayName":"Simin Fan","userId":"15154949338491351516"},"user_tz":-60},"id":"eiPc1rRNiS__","outputId":"bf7a2474-666b-495e-a833-4322826231cd"},"outputs":[],"source":["import os\n","os.environ[\"WANDB_DISABLED\"] = \"true\"\n","os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n","os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" # limiting to one GPU"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"uexGOS0GiS__"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: numpy==1.25.2 in /media1/data/said/encdec/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (1.25.2)\n","Requirement already satisfied: tqdm==4.66.2 in /media1/data/said/encdec/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (4.66.2)\n","Requirement already satisfied: torch==2.2.1+cu118 in /media1/data/said/encdec/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (2.2.1+cu118)\n","Requirement already satisfied: datasets==2.17.1 in /media1/data/said/encdec/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (2.17.1)\n","Requirement already satisfied: gensim==4.3.2 in /media1/data/said/encdec/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (4.3.2)\n","Requirement already satisfied: transformers==4.37.2 in /media1/data/said/encdec/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (4.37.2)\n","Requirement already satisfied: accelerate==0.27.2 in /media1/data/said/encdec/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (0.27.2)\n","Requirement already satisfied: evaluate==0.4.1 in /media1/data/said/encdec/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (0.4.1)\n","Requirement already satisfied: matplotlib==3.7.1 in /media1/data/said/encdec/lib/python3.10/site-packages (from -r requirements.txt (line 9)) (3.7.1)\n","Requirement already satisfied: nltk==3.8.1 in /media1/data/said/encdec/lib/python3.10/site-packages (from -r requirements.txt (line 10)) (3.8.1)\n","Requirement already satisfied: rouge_score==0.1.2 in /media1/data/said/encdec/lib/python3.10/site-packages (from -r requirements.txt (line 11)) (0.1.2)\n","Requirement already satisfied: tensorboard==2.15.2 in /media1/data/said/encdec/lib/python3.10/site-packages (from -r requirements.txt (line 12)) (2.15.2)\n","Requirement already satisfied: filelock in /media1/data/said/encdec/lib/python3.10/site-packages (from torch==2.2.1+cu118->-r requirements.txt (line 3)) (3.13.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /media1/data/said/encdec/lib/python3.10/site-packages (from torch==2.2.1+cu118->-r requirements.txt (line 3)) (4.10.0)\n","Requirement already satisfied: sympy in /media1/data/said/encdec/lib/python3.10/site-packages (from torch==2.2.1+cu118->-r requirements.txt (line 3)) (1.12)\n","Requirement already satisfied: networkx in /media1/data/said/encdec/lib/python3.10/site-packages (from torch==2.2.1+cu118->-r requirements.txt (line 3)) (3.2.1)\n","Requirement already satisfied: jinja2 in /media1/data/said/encdec/lib/python3.10/site-packages (from torch==2.2.1+cu118->-r requirements.txt (line 3)) (3.1.3)\n","Requirement already satisfied: fsspec in /media1/data/said/encdec/lib/python3.10/site-packages (from torch==2.2.1+cu118->-r requirements.txt (line 3)) (2023.10.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /media1/data/said/encdec/lib/python3.10/site-packages (from torch==2.2.1+cu118->-r requirements.txt (line 3)) (11.8.89)\n","Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /media1/data/said/encdec/lib/python3.10/site-packages (from torch==2.2.1+cu118->-r requirements.txt (line 3)) (11.8.89)\n","Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /media1/data/said/encdec/lib/python3.10/site-packages (from torch==2.2.1+cu118->-r requirements.txt (line 3)) (11.8.87)\n","Requirement already satisfied: nvidia-cudnn-cu11==8.7.0.84 in /media1/data/said/encdec/lib/python3.10/site-packages (from torch==2.2.1+cu118->-r requirements.txt (line 3)) (8.7.0.84)\n","Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /media1/data/said/encdec/lib/python3.10/site-packages (from torch==2.2.1+cu118->-r requirements.txt (line 3)) (11.11.3.6)\n","Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /media1/data/said/encdec/lib/python3.10/site-packages (from torch==2.2.1+cu118->-r requirements.txt (line 3)) (10.9.0.58)\n","Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /media1/data/said/encdec/lib/python3.10/site-packages (from torch==2.2.1+cu118->-r requirements.txt (line 3)) (10.3.0.86)\n","Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /media1/data/said/encdec/lib/python3.10/site-packages (from torch==2.2.1+cu118->-r requirements.txt (line 3)) (11.4.1.48)\n","Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /media1/data/said/encdec/lib/python3.10/site-packages (from torch==2.2.1+cu118->-r requirements.txt (line 3)) (11.7.5.86)\n","Requirement already satisfied: nvidia-nccl-cu11==2.19.3 in /media1/data/said/encdec/lib/python3.10/site-packages (from torch==2.2.1+cu118->-r requirements.txt (line 3)) (2.19.3)\n","Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /media1/data/said/encdec/lib/python3.10/site-packages (from torch==2.2.1+cu118->-r requirements.txt (line 3)) (11.8.86)\n","Requirement already satisfied: triton==2.2.0 in /media1/data/said/encdec/lib/python3.10/site-packages (from torch==2.2.1+cu118->-r requirements.txt (line 3)) (2.2.0)\n","Requirement already satisfied: pyarrow>=12.0.0 in /media1/data/said/encdec/lib/python3.10/site-packages (from datasets==2.17.1->-r requirements.txt (line 4)) (15.0.1)\n","Requirement already satisfied: pyarrow-hotfix in /media1/data/said/encdec/lib/python3.10/site-packages (from datasets==2.17.1->-r requirements.txt (line 4)) (0.6)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /media1/data/said/encdec/lib/python3.10/site-packages (from datasets==2.17.1->-r requirements.txt (line 4)) (0.3.8)\n","Requirement already satisfied: pandas in /media1/data/said/encdec/lib/python3.10/site-packages (from datasets==2.17.1->-r requirements.txt (line 4)) (2.2.1)\n","Requirement already satisfied: requests>=2.19.0 in /media1/data/said/encdec/lib/python3.10/site-packages (from datasets==2.17.1->-r requirements.txt (line 4)) (2.31.0)\n","Requirement already satisfied: xxhash in /media1/data/said/encdec/lib/python3.10/site-packages (from datasets==2.17.1->-r requirements.txt (line 4)) (3.4.1)\n","Requirement already satisfied: multiprocess in /media1/data/said/encdec/lib/python3.10/site-packages (from datasets==2.17.1->-r requirements.txt (line 4)) (0.70.16)\n","Requirement already satisfied: aiohttp in /media1/data/said/encdec/lib/python3.10/site-packages (from datasets==2.17.1->-r requirements.txt (line 4)) (3.9.3)\n","Requirement already satisfied: huggingface-hub>=0.19.4 in /media1/data/said/encdec/lib/python3.10/site-packages (from datasets==2.17.1->-r requirements.txt (line 4)) (0.21.4)\n","Requirement already satisfied: packaging in /media1/data/said/encdec/lib/python3.10/site-packages (from datasets==2.17.1->-r requirements.txt (line 4)) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /media1/data/said/encdec/lib/python3.10/site-packages (from datasets==2.17.1->-r requirements.txt (line 4)) (6.0.1)\n","Requirement already satisfied: scipy>=1.7.0 in /media1/data/said/encdec/lib/python3.10/site-packages (from gensim==4.3.2->-r requirements.txt (line 5)) (1.12.0)\n","Requirement already satisfied: smart-open>=1.8.1 in /media1/data/said/encdec/lib/python3.10/site-packages (from gensim==4.3.2->-r requirements.txt (line 5)) (7.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /media1/data/said/encdec/lib/python3.10/site-packages (from transformers==4.37.2->-r requirements.txt (line 6)) (2023.12.25)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /media1/data/said/encdec/lib/python3.10/site-packages (from transformers==4.37.2->-r requirements.txt (line 6)) (0.15.2)\n","Requirement already satisfied: safetensors>=0.4.1 in /media1/data/said/encdec/lib/python3.10/site-packages (from transformers==4.37.2->-r requirements.txt (line 6)) (0.4.2)\n","Requirement already satisfied: psutil in /media1/data/said/encdec/lib/python3.10/site-packages (from accelerate==0.27.2->-r requirements.txt (line 7)) (5.9.8)\n","Requirement already satisfied: responses<0.19 in /media1/data/said/encdec/lib/python3.10/site-packages (from evaluate==0.4.1->-r requirements.txt (line 8)) (0.18.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /media1/data/said/encdec/lib/python3.10/site-packages (from matplotlib==3.7.1->-r requirements.txt (line 9)) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /media1/data/said/encdec/lib/python3.10/site-packages (from matplotlib==3.7.1->-r requirements.txt (line 9)) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /media1/data/said/encdec/lib/python3.10/site-packages (from matplotlib==3.7.1->-r requirements.txt (line 9)) (4.49.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /media1/data/said/encdec/lib/python3.10/site-packages (from matplotlib==3.7.1->-r requirements.txt (line 9)) (1.4.5)\n","Requirement already satisfied: pillow>=6.2.0 in /media1/data/said/encdec/lib/python3.10/site-packages (from matplotlib==3.7.1->-r requirements.txt (line 9)) (10.2.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /media1/data/said/encdec/lib/python3.10/site-packages (from matplotlib==3.7.1->-r requirements.txt (line 9)) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /media1/data/said/encdec/lib/python3.10/site-packages (from matplotlib==3.7.1->-r requirements.txt (line 9)) (2.9.0.post0)\n","Requirement already satisfied: click in /media1/data/said/encdec/lib/python3.10/site-packages (from nltk==3.8.1->-r requirements.txt (line 10)) (8.1.7)\n","Requirement already satisfied: joblib in /media1/data/said/encdec/lib/python3.10/site-packages (from nltk==3.8.1->-r requirements.txt (line 10)) (1.3.2)\n","Requirement already satisfied: absl-py in /media1/data/said/encdec/lib/python3.10/site-packages (from rouge_score==0.1.2->-r requirements.txt (line 11)) (2.1.0)\n","Requirement already satisfied: six>=1.14.0 in /media1/data/said/encdec/lib/python3.10/site-packages (from rouge_score==0.1.2->-r requirements.txt (line 11)) (1.16.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /media1/data/said/encdec/lib/python3.10/site-packages (from tensorboard==2.15.2->-r requirements.txt (line 12)) (1.62.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /media1/data/said/encdec/lib/python3.10/site-packages (from tensorboard==2.15.2->-r requirements.txt (line 12)) (2.28.2)\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /media1/data/said/encdec/lib/python3.10/site-packages (from tensorboard==2.15.2->-r requirements.txt (line 12)) (1.2.0)\n","Requirement already satisfied: markdown>=2.6.8 in /media1/data/said/encdec/lib/python3.10/site-packages (from tensorboard==2.15.2->-r requirements.txt (line 12)) (3.5.2)\n","Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /media1/data/said/encdec/lib/python3.10/site-packages (from tensorboard==2.15.2->-r requirements.txt (line 12)) (4.25.3)\n","Requirement already satisfied: setuptools>=41.0.0 in /media1/data/said/encdec/lib/python3.10/site-packages (from tensorboard==2.15.2->-r requirements.txt (line 12)) (68.2.2)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /media1/data/said/encdec/lib/python3.10/site-packages (from tensorboard==2.15.2->-r requirements.txt (line 12)) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /media1/data/said/encdec/lib/python3.10/site-packages (from tensorboard==2.15.2->-r requirements.txt (line 12)) (3.0.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /media1/data/said/encdec/lib/python3.10/site-packages (from aiohttp->datasets==2.17.1->-r requirements.txt (line 4)) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /media1/data/said/encdec/lib/python3.10/site-packages (from aiohttp->datasets==2.17.1->-r requirements.txt (line 4)) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /media1/data/said/encdec/lib/python3.10/site-packages (from aiohttp->datasets==2.17.1->-r requirements.txt (line 4)) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /media1/data/said/encdec/lib/python3.10/site-packages (from aiohttp->datasets==2.17.1->-r requirements.txt (line 4)) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /media1/data/said/encdec/lib/python3.10/site-packages (from aiohttp->datasets==2.17.1->-r requirements.txt (line 4)) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /media1/data/said/encdec/lib/python3.10/site-packages (from aiohttp->datasets==2.17.1->-r requirements.txt (line 4)) (4.0.3)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /media1/data/said/encdec/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard==2.15.2->-r requirements.txt (line 12)) (5.3.3)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /media1/data/said/encdec/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard==2.15.2->-r requirements.txt (line 12)) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /media1/data/said/encdec/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard==2.15.2->-r requirements.txt (line 12)) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /media1/data/said/encdec/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard==2.15.2->-r requirements.txt (line 12)) (1.4.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /media1/data/said/encdec/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.17.1->-r requirements.txt (line 4)) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /media1/data/said/encdec/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.17.1->-r requirements.txt (line 4)) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /media1/data/said/encdec/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.17.1->-r requirements.txt (line 4)) (2.2.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /media1/data/said/encdec/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.17.1->-r requirements.txt (line 4)) (2024.2.2)\n","Requirement already satisfied: wrapt in /media1/data/said/encdec/lib/python3.10/site-packages (from smart-open>=1.8.1->gensim==4.3.2->-r requirements.txt (line 5)) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /media1/data/said/encdec/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard==2.15.2->-r requirements.txt (line 12)) (2.1.5)\n","Requirement already satisfied: pytz>=2020.1 in /media1/data/said/encdec/lib/python3.10/site-packages (from pandas->datasets==2.17.1->-r requirements.txt (line 4)) (2024.1)\n","Requirement already satisfied: tzdata>=2022.7 in /media1/data/said/encdec/lib/python3.10/site-packages (from pandas->datasets==2.17.1->-r requirements.txt (line 4)) (2024.1)\n","Requirement already satisfied: mpmath>=0.19 in /media1/data/said/encdec/lib/python3.10/site-packages (from sympy->torch==2.2.1+cu118->-r requirements.txt (line 3)) (1.3.0)\n"]},{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /media1/data/said/encdec/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard==2.15.2->-r requirements.txt (line 12)) (0.5.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /media1/data/said/encdec/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard==2.15.2->-r requirements.txt (line 12)) (3.2.2)\n"]}],"source":["!pip install -r requirements.txt"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"q0bmJE-0iTAA"},"outputs":[{"name":"stderr","output_type":"stream","text":["/media1/data/said/encdec/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["from datasets import load_dataset\n","import math\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import torch\n","import torch.optim as optim\n","import torch.nn as nn\n","import evaluate\n","import gensim\n","import transformers\n","import nltk"]},{"cell_type":"markdown","metadata":{},"source":["<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #03befc;background-color:#eff7fe;border-radius: 15px;color:#424242;\">\n","\n","**TODOüîª: Enter your SCIPER number below!**\n","     \n","</div>"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["import re\n","import random\n","import numpy as np\n","import torch\n","\n","## Enter your SCIPER here: ##\n","SCIPER = \"369141\"\n","\n","try:\n","    assert re.match(\"\\d{6}\", SCIPER)[0] == SCIPER, \"Invalid SCIPER given. please enter your correct 6-digit SCIPER number above!\"\n","except:\n","    print(\"Invalid SCIPER given. please enter your correct 6-digit SCIPER number above!\")\n","\n","student_seed = int(SCIPER)\n","\n","\n","\"\"\"Set seed for reproducibility.\"\"\"\n","random.seed(student_seed)\n","np.random.seed(student_seed)\n","torch.manual_seed(student_seed)\n","torch.cuda.manual_seed_all(student_seed)\n","torch.mps.manual_seed(student_seed)"]},{"cell_type":"markdown","metadata":{"id":"m06WLo6qUvcm"},"source":["---\n","\n","<a name=\"1\"></a>\n","# PART 1: Data Preprocessing\n","\n","We will train a language model using the `wikitext-103` dataset.\n","\n","> `wikitext-103` dataset is a large collection of articles with verified\n","good and featured quality from Wikipedia. We will use the open-source dataset from Huggingface (https://huggingface.co/datasets/wikitext)."]},{"cell_type":"code","execution_count":8,"metadata":{"id":"v4hUSpJMzuM9"},"outputs":[],"source":["from utils import *\n","from test_A1 import *\n","from data import filter_by_length, data_clean, count_tokens, build_vocabulary"]},{"cell_type":"markdown","metadata":{"id":"jBU8CTeo1Uy4"},"source":["### Load `wikitext-103` Dataset"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2486,"status":"ok","timestamp":1707662515805,"user":{"displayName":"Simin Fan","userId":"15154949338491351516"},"user_tz":-60},"id":"F_ImpO7n05kj","outputId":"ba208190-5450-40e1-daf5-69dcea4067cc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Size of the dataset is 1801350\n","{'text': ''}\n","{'text': ' The game \\'s battle system , the <unk> system , is carried over directly from <unk> Chronicles . During missions , players select each unit using a top @-@ down perspective of the battlefield map : once a character is selected , the player moves the character around the battlefield in third @-@ person . A character can only act once per @-@ turn , but characters can be granted multiple turns at the expense of other characters \\' turns . Each character has a field and distance of movement limited by their Action Gauge . Up to nine characters can be assigned to a single mission . During gameplay , characters will call out if something happens to them , such as their health points ( HP ) getting low or being knocked out by enemy attacks . Each character has specific \" Potentials \" , skills unique to each character . They are divided into \" Personal Potential \" , which are innate skills that remain unaltered unless otherwise dictated by the story and can either help or impede a character , and \" Battle Potentials \" , which are grown throughout the game and always grant boons to a character . To learn Battle Potentials , each character has a unique \" Masters Table \" , a grid @-@ based skill table that can be used to acquire and link different skills . Characters also have Special Abilities that grant them temporary boosts on the battlefield : Kurt can activate \" Direct Command \" and move around the battlefield without depleting his Action Point gauge , the character <unk> can shift into her \" Valkyria Form \" and become invincible , while Imca can target multiple enemy units with her heavy weapon . \\n'}\n","{'text': ' 96 ammunition packing boxes \\n'}\n"]}],"source":["wikitext_dataset = load_dataset(\"wikitext\", 'wikitext-103-v1', split=\"train\")\n","\n","print(f\"Size of the dataset is {len(wikitext_dataset)}\")\n","\n","# You can print some samples to get a sense of the data\n","print(wikitext_dataset[0])\n","print(wikitext_dataset[10])\n","print(wikitext_dataset[100])"]},{"cell_type":"markdown","metadata":{"id":"ZOD9aSZIiTAC"},"source":["<a id=\"11\"></a>\n","## üéØ Q1.1: **Data Cleaning**.\n","\n","We find some problems in the dataset:\n","- some samples are empty (with no tokens) or too short;\n","- some contains noisy texts (e.g. `==== <> ====`);\n","- some have non-English texts.\n","\n","So we need a data cleaning before feeding it to the model.\n","\n","***Test:*** After each function, you can test your implementation by running a simple test case. (Note: passing these simple cases do not necessarily mean your implementation is 100% correct.)"]},{"cell_type":"markdown","metadata":{"id":"YfMJBW7OAnj-"},"source":["<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #03befc;background-color:#eff7fe;border-radius: 15px;color:#424242;\">\n","\n","**We will perform 4-step data cleaning:**\n","\n","- **Step 1**: filter out sequences shorter than `min_len=100` or longer than `max_len=128`;\n","- **Step 2**: filter out sequences with particular pattern `= * =\\n`, where `*` denotes any possible sequences;\n","- **Step 3**: filter out Non-English sequences;\n","- **Step 4**: lowercase all sequences.\n","\n","**TODOüîª: Implement `filter_by_length` and `data_clean` function in `data.py`**.\n","\n","More instructions are provided in the function description.\n","</div>"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"fXz9W7tZiTAD"},"outputs":[],"source":["# ETS: take ~1-3mins to run #\n","from data import data_clean\n","\n","wikitext_dataset = data_clean(wikitext_dataset, min_len=100, max_len=128)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1707662518086,"user":{"displayName":"Simin Fan","userId":"15154949338491351516"},"user_tz":-60},"id":"AHPGnLRn5qKK","outputId":"e57eab88-6755-402c-feb5-fb63cba2d349"},"outputs":[{"name":"stdout","output_type":"stream","text":["Test Passed ‚úÖ\n"]}],"source":["test_data_clean(wikitext_dataset)"]},{"cell_type":"markdown","metadata":{"id":"6Mmm46nr6SZK"},"source":["<a id=\"12\"></a>\n","## üéØ Q1.2: **Build Vocabulary**.\n","\n","\n","<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #03befc;background-color:#eff7fe;border-radius: 15px;color:#424242;\">\n","\n","**We have to build a vocabulary dictionary for the cleaned `wikitext_dataset` following four steps:**\n","\n","- **Step 1**: Compute frequency of occurences for each unique token in the dataset;\n","\n","- **Step 2**: Find a set of rare tokens with frequency lower than `min_freq=5`. Replace them with `unk_token='<unk>'`;\n","\n","- **Step 3**: Filter out sequences with more than 15\\% rare tokens. (*We implemented this for you.*)\n","\n","- **Step 4**: Recompute the token frequency to get final vocabulary dict.\n","\n","**TODOüîª: Implement `count_tokens` and `build_vocabulary` function in `data.py`**.\n","\n","More instructions are provided in the function description.\n","</div>"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":40385,"status":"ok","timestamp":1707662560874,"user":{"displayName":"Simin Fan","userId":"15154949338491351516"},"user_tz":-60},"id":"6pywsRBT7YMu","outputId":"ad48f120-0628-499b-e49c-22a23b8ecb46"},"outputs":[],"source":["# ETS: take ~1-3mins to run #\n","from data import build_vocabulary\n","\n","wikitext_dataset, token_freq_dict = build_vocabulary(wikitext_dataset, min_freq=5, unk_token='<unk>')"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1707662560875,"user":{"displayName":"Simin Fan","userId":"15154949338491351516"},"user_tz":-60},"id":"sljyM8tt8h6n","outputId":"0cd45532-22b0-4765-86fb-3610dbc7a9d4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Test1 Passed ‚úÖ\n","Test2 Passed ‚úÖ\n"]}],"source":["test_vocab_build(wikitext_dataset, token_freq_dict)"]},{"cell_type":"markdown","metadata":{"id":"drmgakSq97Hm"},"source":["**Let's look at the vocabulary distribution with a histogram:**\n","\n","- we can observe that tokens with very low frequency are filtered out :)"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":434},"executionInfo":{"elapsed":1047,"status":"ok","timestamp":1707662385158,"user":{"displayName":"Simin Fan","userId":"15154949338491351516"},"user_tz":-60},"id":"Lgzc0VT6-GrM","outputId":"62caff42-ae6c-4c73-8f16-025e88d0076c"},"outputs":[{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAjkAAAGhCAYAAACDNqXeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAl9klEQVR4nO3dfXBU9b3H8U8ezIPAbni42WVlgfTWIhGEGiCmCpWaIWK0g42dUlOhtyncehMrRKThauNDLaGxVEQpFO0UbwtTpFMoJddIblBSIQZMbxRSgzgXCkp3YydkF9ISINn7h5MzrERZwiab/eX9mtmZ7jnfc873fKvNp2fPno0JBAIBAQAAGCY20g0AAAD0BkIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICR4iPdQCR1dnbqxIkTGjJkiGJiYiLdDgAACEEgENCpU6fkcrkUG/vp12sGdMg5ceKE3G53pNsAAAA9cPz4cY0aNepT1w/okDNkyBBJHw/JZrNFuBsAABAKv98vt9tt/R3/NAM65HR9RGWz2Qg5AABEmUvdasKNxwAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjxUe6AUSvsSUVPdru6IrcMHcCAMDFuJIDAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjHTZIaempkZ33XWXXC6XYmJitG3btqD1gUBApaWlGjlypJKTk5Wdna3Dhw8H1bS0tCg/P182m00pKSkqKCjQ6dOng2reeecdTZ8+XUlJSXK73SovL7+oly1btui6665TUlKSJk6cqP/+7/++3NMBAACGuuyQ09bWpkmTJmnNmjXdri8vL9fq1au1bt061dXVadCgQcrJydGZM2esmvz8fDU2Nqqqqko7duxQTU2NFi5caK33+/2aNWuWxowZo/r6ej399NN6/PHHtX79eqtm7969+uY3v6mCggL97//+r+bMmaM5c+bo4MGDl3tKAADAQDGBQCDQ441jYrR161bNmTNH0sdXcVwulx566CEtWbJEkuTz+eRwOLRhwwbNnTtX7777rtLT07V//35NmTJFklRZWak77rhDH3zwgVwul9auXatHHnlEHo9HCQkJkqSSkhJt27ZNTU1NkqRvfOMbamtr044dO6x+brrpJk2ePFnr1q3rtt/29na1t7db7/1+v9xut3w+n2w2W0/HMGCNLano0XZHV+SGuRMAwEDi9/tlt9sv+fc7rPfkHDlyRB6PR9nZ2dYyu92uzMxM1dbWSpJqa2uVkpJiBRxJys7OVmxsrOrq6qyaGTNmWAFHknJycnTo0CGdPHnSqrnwOF01XcfpTllZmex2u/Vyu91XftIAAKBfCmvI8Xg8kiSHwxG03OFwWOs8Ho9SU1OD1sfHx2vYsGFBNd3t48JjfFpN1/ruLFu2TD6fz3odP378ck8RAABEifhIN9CXEhMTlZiYGOk2AABAHwjrlRyn0ylJ8nq9Qcu9Xq+1zul0qrm5OWj9+fPn1dLSElTT3T4uPMan1XStBwAAA1tYQ05aWpqcTqeqq6utZX6/X3V1dcrKypIkZWVlqbW1VfX19VbNrl271NnZqczMTKumpqZG586ds2qqqqo0btw4DR061Kq58DhdNV3HAQAAA9tlh5zTp0+roaFBDQ0Nkj6+2bihoUHHjh1TTEyMFi1apKeeekrbt2/XgQMHNG/ePLlcLusbWOPHj9ftt9+uBQsWaN++fdqzZ4+Kioo0d+5cuVwuSdK9996rhIQEFRQUqLGxUZs3b9azzz6r4uJiq48HH3xQlZWVWrlypZqamvT444/rrbfeUlFR0ZVPBQAARL3Lvifnrbfe0syZM633XcFj/vz52rBhg5YuXaq2tjYtXLhQra2tuuWWW1RZWamkpCRrm40bN6qoqEi33XabYmNjlZeXp9WrV1vr7Xa7du7cqcLCQmVkZGjEiBEqLS0NepbOl770JW3atEmPPvqo/vM//1PXXnuttm3bpgkTJvRoEAAAwCxX9JycaBfq9+zRPZ6TAwCIhIg8JwcAAKC/IOQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARoqPdAMYeMaWVPRou6MrcsPcCQDAZFzJAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGCksIecjo4O/fCHP1RaWpqSk5P1r//6r/rRj36kQCBg1QQCAZWWlmrkyJFKTk5Wdna2Dh8+HLSflpYW5efny2azKSUlRQUFBTp9+nRQzTvvvKPp06crKSlJbrdb5eXl4T4dAAAQpcIecn7yk59o7dq1ev755/Xuu+/qJz/5icrLy/Xcc89ZNeXl5Vq9erXWrVunuro6DRo0SDk5OTpz5oxVk5+fr8bGRlVVVWnHjh2qqanRwoULrfV+v1+zZs3SmDFjVF9fr6efflqPP/641q9fH+5TAgAAUSgmcOElljC488475XA49Mtf/tJalpeXp+TkZP3mN79RIBCQy+XSQw89pCVLlkiSfD6fHA6HNmzYoLlz5+rdd99Venq69u/frylTpkiSKisrdccdd+iDDz6Qy+XS2rVr9cgjj8jj8SghIUGSVFJSom3btqmpqanb3trb29Xe3m699/v9crvd8vl8stls4RzDgDC2pKJPj3d0RW6fHg8A0D/5/X7Z7fZL/v0O+5WcL33pS6qurtZ7770nSXr77bf1xhtvaPbs2ZKkI0eOyOPxKDs729rGbrcrMzNTtbW1kqTa2lqlpKRYAUeSsrOzFRsbq7q6OqtmxowZVsCRpJycHB06dEgnT57streysjLZ7Xbr5Xa7w3vyAACg34gP9w5LSkrk9/t13XXXKS4uTh0dHfrxj3+s/Px8SZLH45EkORyOoO0cDoe1zuPxKDU1NbjR+HgNGzYsqCYtLe2ifXStGzp06EW9LVu2TMXFxdb7ris5AADAPGEPOS+//LI2btyoTZs26frrr1dDQ4MWLVokl8ul+fPnh/twlyUxMVGJiYkR7QEAAPSNsIechx9+WCUlJZo7d64kaeLEifrrX/+qsrIyzZ8/X06nU5Lk9Xo1cuRIazuv16vJkydLkpxOp5qbm4P2e/78ebW0tFjbO51Oeb3eoJqu9101AABg4Ar7PTn/+Mc/FBsbvNu4uDh1dnZKktLS0uR0OlVdXW2t9/v9qqurU1ZWliQpKytLra2tqq+vt2p27dqlzs5OZWZmWjU1NTU6d+6cVVNVVaVx48Z1+1EVAAAYWMIecu666y79+Mc/VkVFhY4ePaqtW7fqZz/7me6++25JUkxMjBYtWqSnnnpK27dv14EDBzRv3jy5XC7NmTNHkjR+/HjdfvvtWrBggfbt26c9e/aoqKhIc+fOlcvlkiTde++9SkhIUEFBgRobG7V582Y9++yzQffcAACAgSvsH1c999xz+uEPf6j/+I//UHNzs1wul/793/9dpaWlVs3SpUvV1tamhQsXqrW1VbfccosqKyuVlJRk1WzcuFFFRUW67bbbFBsbq7y8PK1evdpab7fbtXPnThUWFiojI0MjRoxQaWlp0LN0AADAwBX25+REk1C/Z4/u8ZwcAEAkROw5OQAAAP0BIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAI8VHugEgVGNLKnq03dEVuWHuBAAQDbiSAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIzUKyHnww8/1Le+9S0NHz5cycnJmjhxot566y1rfSAQUGlpqUaOHKnk5GRlZ2fr8OHDQftoaWlRfn6+bDabUlJSVFBQoNOnTwfVvPPOO5o+fbqSkpLkdrtVXl7eG6cDAACiUNhDzsmTJ3XzzTfrqquu0iuvvKK//OUvWrlypYYOHWrVlJeXa/Xq1Vq3bp3q6uo0aNAg5eTk6MyZM1ZNfn6+GhsbVVVVpR07dqimpkYLFy601vv9fs2aNUtjxoxRfX29nn76aT3++ONav359uE8JAABEoZhAIBAI5w5LSkq0Z88e/elPf+p2fSAQkMvl0kMPPaQlS5ZIknw+nxwOhzZs2KC5c+fq3XffVXp6uvbv368pU6ZIkiorK3XHHXfogw8+kMvl0tq1a/XII4/I4/EoISHBOva2bdvU1NTU7bHb29vV3t5uvff7/XK73fL5fLLZbOEcw4AwtqQi0i2E5OiK3Ei3AAAII7/fL7vdfsm/32G/krN9+3ZNmTJFX//615WamqovfvGLeuGFF6z1R44ckcfjUXZ2trXMbrcrMzNTtbW1kqTa2lqlpKRYAUeSsrOzFRsbq7q6OqtmxowZVsCRpJycHB06dEgnT57streysjLZ7Xbr5Xa7w3ruAACg/wh7yPm///s/rV27Vtdee61effVV3X///fr+97+vl156SZLk8XgkSQ6HI2g7h8NhrfN4PEpNTQ1aHx8fr2HDhgXVdLePC4/xScuWLZPP57Nex48fv8KzBQAA/VV8uHfY2dmpKVOmaPny5ZKkL37xizp48KDWrVun+fPnh/twlyUxMVGJiYkR7QEAAPSNsF/JGTlypNLT04OWjR8/XseOHZMkOZ1OSZLX6w2q8Xq91jqn06nm5uag9efPn1dLS0tQTXf7uPAYAABg4Ap7yLn55pt16NChoGXvvfeexowZI0lKS0uT0+lUdXW1td7v96uurk5ZWVmSpKysLLW2tqq+vt6q2bVrlzo7O5WZmWnV1NTU6Ny5c1ZNVVWVxo0bF/RNLgAAMDCFPeQsXrxYb775ppYvX673339fmzZt0vr161VYWChJiomJ0aJFi/TUU09p+/btOnDggObNmyeXy6U5c+ZI+vjKz+23364FCxZo37592rNnj4qKijR37ly5XC5J0r333quEhAQVFBSosbFRmzdv1rPPPqvi4uJwnxIAAIhCYb8nZ+rUqdq6dauWLVumJ598UmlpaVq1apXy8/OtmqVLl6qtrU0LFy5Ua2urbrnlFlVWViopKcmq2bhxo4qKinTbbbcpNjZWeXl5Wr16tbXebrdr586dKiwsVEZGhkaMGKHS0tKgZ+kAAICBK+zPyYkmoX7PHt3jOTkAgEiI2HNyAAAA+gNCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYKew/0An0Nz39jS1+8woAohtXcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwUnykGwD6q7ElFT3a7uiK3DB3AgDoCa7kAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYqddDzooVKxQTE6NFixZZy86cOaPCwkINHz5cgwcPVl5enrxeb9B2x44dU25urq6++mqlpqbq4Ycf1vnz54NqXn/9dd14441KTEzU5z//eW3YsKG3TwcAAESJXg05+/fv1y9+8QvdcMMNQcsXL16sP/7xj9qyZYt2796tEydO6Gtf+5q1vqOjQ7m5uTp79qz27t2rl156SRs2bFBpaalVc+TIEeXm5mrmzJlqaGjQokWL9N3vflevvvpqb54SAACIEr0Wck6fPq38/Hy98MILGjp0qLXc5/Ppl7/8pX72s5/pK1/5ijIyMvSrX/1Ke/fu1ZtvvilJ2rlzp/7yl7/oN7/5jSZPnqzZs2frRz/6kdasWaOzZ89KktatW6e0tDStXLlS48ePV1FRke655x4988wzvXVKAAAgivRayCksLFRubq6ys7ODltfX1+vcuXNBy6+77jqNHj1atbW1kqTa2lpNnDhRDofDqsnJyZHf71djY6NV88l95+TkWPvoTnt7u/x+f9ALAACYqVd+1uG3v/2t/vznP2v//v0XrfN4PEpISFBKSkrQcofDIY/HY9VcGHC61net+6wav9+vf/7zn0pOTr7o2GVlZXriiSd6fF4AACB6hP1KzvHjx/Xggw9q48aNSkpKCvfur8iyZcvk8/ms1/HjxyPdEgAA6CVhDzn19fVqbm7WjTfeqPj4eMXHx2v37t1avXq14uPj5XA4dPbsWbW2tgZt5/V65XQ6JUlOp/Oib1t1vb9Ujc1m6/YqjiQlJibKZrMFvQAAgJnCHnJuu+02HThwQA0NDdZrypQpys/Pt/7zVVddperqamubQ4cO6dixY8rKypIkZWVl6cCBA2pubrZqqqqqZLPZlJ6ebtVcuI+umq59AACAgS3s9+QMGTJEEyZMCFo2aNAgDR8+3FpeUFCg4uJiDRs2TDabTQ888ICysrJ00003SZJmzZql9PR03XfffSovL5fH49Gjjz6qwsJCJSYmSpK+973v6fnnn9fSpUv1ne98R7t27dLLL7+sioqKcJ8SAACIQr1y4/GlPPPMM4qNjVVeXp7a29uVk5Ojn//859b6uLg47dixQ/fff7+ysrI0aNAgzZ8/X08++aRVk5aWpoqKCi1evFjPPvusRo0apRdffFE5OTmROCUAANDPxAQCgUCkm4gUv98vu90un8/H/Tk9MLaEq2bdOboiN9ItAIDRQv37zW9XAQAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACPFR7oBwDRjSyp6tN3RFblh7gQABjau5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADBSfKQbAPCxsSUVPdru6IrcMHcCAGbgSg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASGEPOWVlZZo6daqGDBmi1NRUzZkzR4cOHQqqOXPmjAoLCzV8+HANHjxYeXl58nq9QTXHjh1Tbm6urr76aqWmpurhhx/W+fPng2pef/113XjjjUpMTNTnP/95bdiwIdynAwAAolTYQ87u3btVWFioN998U1VVVTp37pxmzZqltrY2q2bx4sX64x//qC1btmj37t06ceKEvva1r1nrOzo6lJubq7Nnz2rv3r166aWXtGHDBpWWllo1R44cUW5urmbOnKmGhgYtWrRI3/3ud/Xqq6+G+5QAAEAUigkEAoHePMBHH32k1NRU7d69WzNmzJDP59O//Mu/aNOmTbrnnnskSU1NTRo/frxqa2t100036ZVXXtGdd96pEydOyOFwSJLWrVunH/zgB/roo4+UkJCgH/zgB6qoqNDBgwetY82dO1etra2qrKwMqTe/3y+73S6fzyebzRb+kzfc2JKKSLcASUdX5Ea6BQDoU6H+/e71e3J8Pp8kadiwYZKk+vp6nTt3TtnZ2VbNddddp9GjR6u2tlaSVFtbq4kTJ1oBR5JycnLk9/vV2Nho1Vy4j66arn10p729XX6/P+gFAADM1Kshp7OzU4sWLdLNN9+sCRMmSJI8Ho8SEhKUkpISVOtwOOTxeKyaCwNO1/qudZ9V4/f79c9//rPbfsrKymS3262X2+2+4nMEAAD9U3xv7rywsFAHDx7UG2+80ZuHCdmyZctUXFxsvff7/QQdRL2efmzIx1wATNdrIaeoqEg7duxQTU2NRo0aZS13Op06e/asWltbg67meL1eOZ1Oq2bfvn1B++v69tWFNZ/8RpbX65XNZlNycnK3PSUmJioxMfGKzw0AAPR/Yf+4KhAIqKioSFu3btWuXbuUlpYWtD4jI0NXXXWVqqurrWWHDh3SsWPHlJWVJUnKysrSgQMH1NzcbNVUVVXJZrMpPT3dqrlwH101XfsAAAADW9iv5BQWFmrTpk36wx/+oCFDhlj30NjtdiUnJ8tut6ugoEDFxcUaNmyYbDabHnjgAWVlZemmm26SJM2aNUvp6em67777VF5eLo/Ho0cffVSFhYXWlZjvfe97ev7557V06VJ95zvf0a5du/Tyyy+rooJv/AAAgF64krN27Vr5fD7deuutGjlypPXavHmzVfPMM8/ozjvvVF5enmbMmCGn06nf//731vq4uDjt2LFDcXFxysrK0re+9S3NmzdPTz75pFWTlpamiooKVVVVadKkSVq5cqVefPFF5eTkhPuUAABAFOr15+T0Zzwn58rwnJzoxo3HAKJVv3lODgAAQCQQcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjNSrP9AJoP/ihz0BmI4rOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJH7WAcBl4ecgAEQLruQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACPxxGMAfaKnT0qWeFoygJ7hSg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBJPPAbQ7/X0ack8KRkY2LiSAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASHy7CoCx+FYWMLBxJQcAABiJkAMAAIxEyAEAAEYi5AAAACNx4zEAfAI3LANm4EoOAAAwEiEHAAAYiY+rACBM+JgL6F+4kgMAAIxEyAEAAEaK+o+r1qxZo6effloej0eTJk3Sc889p2nTpkW6rajR08vrAAD0d1EdcjZv3qzi4mKtW7dOmZmZWrVqlXJycnTo0CGlpqZGuj0ACAn38gC9IyYQCAQi3URPZWZmaurUqXr++eclSZ2dnXK73XrggQdUUlJyye39fr/sdrt8Pp9sNltvt9svcSUHGHgIR4h2of79jtorOWfPnlV9fb2WLVtmLYuNjVV2drZqa2u73aa9vV3t7e3We5/PJ+njYUW7CY+9GukWAESJ0Yu3RLqFkBx8IqdH213J/x729JjoW11/ty91nSZqQ87f//53dXR0yOFwBC13OBxqamrqdpuysjI98cQTFy13u9290iMAoOfsqwbGMdFzp06dkt1u/9T1URtyemLZsmUqLi623nd2dqqlpUXDhw9XTEyMtXzq1Knav3//Rdt/cvmnvff7/XK73Tp+/HivfAz2af1d6TaXqgl1Lt0tM21Wl6pjVqHX9casJPXqvJhV6Hoyq1C3661ZfXJZX83qs/q+0m36alYXvu/NWQUCAZ06dUoul+sz66I25IwYMUJxcXHyer1By71er5xOZ7fbJCYmKjExMWhZSkrKRXVxcXHd/hfyyeWXem+z2XrlX4JP6+9Kt7lUTahz6W6ZabO6VB2zCr2uN2cl9c68mFXoejKrULfrrVl9cllfzerTjhWObfpqVt29761ZfdYVnC5R+5ychIQEZWRkqLq62lrW2dmp6upqZWVlXdG+CwsLQ1p+qfe9pSfHCWWbS9WEOpfulpk2q0vVMavQ65hV6HUDZVahbtdbs/rksr6aVU+P1Z9mFWo/fSWqv121efNmzZ8/X7/4xS80bdo0rVq1Si+//LKampouulenL/GtrdAxq9Axq8vDvELHrELHrELXH2YVtR9XSdI3vvENffTRRyotLZXH49HkyZNVWVkZ0YAjffyx2GOPPXbRR2O4GLMKHbO6PMwrdMwqdMwqdP1hVlF9JQcAAODTRO09OQAAAJ+FkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOX1sx44dGjdunK699lq9+OKLkW6n37v77rs1dOhQ3XPPPZFupV87fvy4br31VqWnp+uGG27Qli3R8QOMkdDa2qopU6Zo8uTJmjBhgl544YVIt9Tv/eMf/9CYMWO0ZMmSSLfSr40dO1Y33HCDJk+erJkzZ0a6nX7tyJEjmjlzptLT0zVx4kS1tbX1ynH4CnkfOn/+vNLT0/Xaa6/JbrcrIyNDe/fu1fDhwyPdWr/1+uuv69SpU3rppZf0u9/9LtLt9Ft/+9vf5PV6NXnyZHk8HmVkZOi9997ToEGDIt1av9PR0aH29nZdffXVamtr04QJE/TWW2/x7+FneOSRR/T+++/L7Xbrpz/9aaTb6bfGjh2rgwcPavDgwZFupd/78pe/rKeeekrTp09XS0uLbDab4uPD/+g+ruT0oX379un666/XNddco8GDB2v27NnauXNnpNvq12699VYNGTIk0m30eyNHjtTkyZMlSU6nUyNGjFBLS0tkm+qn4uLidPXVV0uS2tvbFQgExP/X+3SHDx9WU1OTZs+eHelWYIjGxkZdddVVmj59uiRp2LBhvRJwJELOZampqdFdd90ll8ulmJgYbdu27aKaNWvWaOzYsUpKSlJmZqb27dtnrTtx4oSuueYa6/0111yjDz/8sC9aj4grnddAEs5Z1dfXq6OjQ263u5e7joxwzKq1tVWTJk3SqFGj9PDDD2vEiBF91H3fCseslixZorKysj7qOHLCMauYmBh9+ctf1tSpU7Vx48Y+6rzvXemsDh8+rMGDB+uuu+7SjTfeqOXLl/dar4Scy9DW1qZJkyZpzZo13a7fvHmziouL9dhjj+nPf/6zJk2apJycHDU3N/dxp/0D8wpduGbV0tKiefPmaf369X3RdkSEY1YpKSl6++23deTIEW3atEler7ev2u9TVzqrP/zhD/rCF76gL3zhC33ZdkSE45+rN954Q/X19dq+fbuWL1+ud955p6/a71NXOqvz58/rT3/6k37+85+rtrZWVVVVqqqq6p1mA+gRSYGtW7cGLZs2bVqgsLDQet/R0RFwuVyBsrKyQCAQCOzZsycwZ84ca/2DDz4Y2LhxY5/0G2k9mVeX1157LZCXl9cXbfYLPZ3VmTNnAtOnTw/813/9V1+1GnFX8s9Vl/vvvz+wZcuW3myzX+jJrEpKSgKjRo0KjBkzJjB8+PCAzWYLPPHEE33ZdkSE45+rJUuWBH71q1/1Ypf9Q09mtXfv3sCsWbOs9eXl5YHy8vJe6Y8rOWFy9uxZ1dfXKzs721oWGxur7Oxs1dbWSpKmTZumgwcP6sMPP9Tp06f1yiuvKCcnJ1ItR1Qo88LHQplVIBDQt7/9bX3lK1/RfffdF6lWIy6UWXm9Xp06dUqS5PP5VFNTo3HjxkWk30gKZVZlZWU6fvy4jh49qp/+9KdasGCBSktLI9VyxIQyq7a2Nuufq9OnT2vXrl26/vrrI9JvJIUyq6lTp6q5uVknT55UZ2enampqNH78+F7pJ6p/hbw/+fvf/66Ojo6LfgHd4XCoqalJkhQfH6+VK1dq5syZ6uzs1NKlSwfsNzpCmZckZWdn6+2331ZbW5tGjRqlLVu2KCsrq6/bjahQZrVnzx5t3rxZN9xwg/X5+K9//WtNnDixr9uNqFBm9de//lULFy60bjh+4IEHBtycpND/HURos/J6vbr77rslffwNvgULFmjq1Kl93mukhfq3cPny5ZoxY4YCgYBmzZqlO++8s1f6IeT0sa9+9av66le/Guk2osb//M//RLqFqHDLLbeos7Mz0m1EhWnTpqmhoSHSbUSdb3/725FuoV/73Oc+p7fffjvSbUSN2bNn98k39vi4KkxGjBihuLi4i25g9Hq9cjqdEeqq/2JeoWNWoWNWoWNWoWNWoetvsyLkhElCQoIyMjJUXV1tLevs7FR1dfWA+3glFMwrdMwqdMwqdMwqdMwqdP1tVnxcdRlOnz6t999/33p/5MgRNTQ0aNiwYRo9erSKi4s1f/58TZkyRdOmTdOqVavU1tamf/u3f4tg15HDvELHrELHrELHrELHrEIXVbPqle9sGeq1114LSLroNX/+fKvmueeeC4wePTqQkJAQmDZtWuDNN9+MXMMRxrxCx6xCx6xCx6xCx6xCF02z4rerAACAkbgnBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAj/T8xnZqho8A+dgAAAABJRU5ErkJggg==","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["plt.hist(token_freq_dict.values(), bins=10**np.linspace(0,6,33))\n","plt.xscale(\"log\")"]},{"cell_type":"markdown","metadata":{"id":"07Q5by1kiTAQ"},"source":["<a id=\"13\"></a>\n","## üéØ Q1.3: **Build Pytorch Dataset**.\n","\n","<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #03befc;background-color:#eff7fe;border-radius: 15px;color:#424242;\">\n","\n","**We build a Pytorch Dataset using cleaned `wikitext_dataset`:**\n","\n","- **Step 1**: we have to add some special tokens for each sequence:\n","  - `<start>`: add to the start of a sequence;\n","  - `<stop>`: add to the end of a sequence;\n","  - `<pad>`: padding token. add padding token until the length of the sequence reach `MAX_SEQ_LENGTH`.\n","\n","- **Step 2**: when we fetch a sequence in the dataset by indexing, it should return a sequence of token indices.\n","\n","**TODOüîª: Implement `__init__` and `__getitem__` function in `RNNDataset` class in `data.py`**.\n","\n","Detailed instructions are provided in the function description.\n","</div>\n"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31793,"status":"ok","timestamp":1707662592665,"user":{"displayName":"Simin Fan","userId":"15154949338491351516"},"user_tz":-60},"id":"SmSdlO_BBbFO","outputId":"ec0880c3-3a54-46ab-c024-36d3d567fdd4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Getting the vocabulary for the train dataset\n"]},{"name":"stderr","output_type":"stream","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 97536/97536 [00:05<00:00, 16963.25it/s]\n"]}],"source":["from data import RNNDataset\n","\n","# ETS: take ~1min to run #\n","MAX_SEQ_LENGTH = 128\n","rnn_dataset = RNNDataset(dataset=wikitext_dataset,\n","                         max_seq_length=MAX_SEQ_LENGTH)"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":211,"status":"ok","timestamp":1707662592866,"user":{"displayName":"Simin Fan","userId":"15154949338491351516"},"user_tz":-60},"id":"i3HrGoeNC7ur","outputId":"d03c14ff-9d39-49be-a00f-322cc7f24bb2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Test1 Passed ‚úÖ\n","Test2 Passed ‚úÖ\n"]}],"source":["test_rnn_dataset(rnn_dataset)"]},{"cell_type":"markdown","metadata":{"id":"KvfS1HLxE7NP"},"source":["<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #03befc;background-color:#eff7fe;border-radius: 15px;color:#424242;\">\n","\n","**Once we create the `rnn_dataset`, we have to split it into train/test dataset, and build a DataLoader for each::**\n","\n","- **Step 1**: split `rnn_dataset` into train/test datasets, with `test_ratio=0.1`:\n","\n","- **Step 2**: Build pytorch dataloader for train/test dataset with `batch_size=8`.\n","\n","**TODOüîª: Implement `get_dataloader` function in `data.py`**.\n","\n","Detailed instructions are provided in the function description.\n","</div>\n"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"f8TP_CXoE5V6"},"outputs":[],"source":["from data import get_dataloader\n","\n","# ETS: ~1min #\n","train_dataloader, test_dataloader = get_dataloader(rnn_dataset, test_ratio=0.1)"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1707662592866,"user":{"displayName":"Simin Fan","userId":"15154949338491351516"},"user_tz":-60},"id":"0PGShHPNHevY","outputId":"461f9160-d854-4efa-c334-137f06c63829"},"outputs":[{"name":"stdout","output_type":"stream","text":["Test1 Passed ‚úÖ\n","Test1 Passed ‚úÖ\n"]}],"source":["test_dataloaders(train_dataloader, test_dataloader)"]},{"cell_type":"markdown","metadata":{"id":"8ZpVeuyWiTAU"},"source":["<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #8e7cc3;background-color:#e4e1eb;border-radius: 15px;color:#424242;\">\n","\n","üéâ **Excellent work!** By this point, we have all core building blocks for Part 2 :)\n","   \n","- [X] `rnn_dataset`: A `Dataset` obj with the data, the vocabulary, the pad index, and mapping from tokens to indices;\n","- [X] `train_dataloader`: A `DataLoader` obj with training sequences;\n","- [X] `test_dataloader`: A `DataLoader` obj with testing sequences.\n","\n","_Tip: Try to familiarize with functionalities and attributes they provide._\n","    \n","</div>"]},{"cell_type":"markdown","metadata":{"id":"HPDNtdxFUvcn"},"source":["---\n","\n","<a id=\"2\"></a>\n","# PART 2:  Training Language Models\n","\n","#### Language Model: a probabilistic model of a sequence of tokens.\n","\n","üîµ **What?**\n","\n","Language modeling (LM) is the use of various statistical and probabilistic techniques to determine the probability of a given sequence of words occurring in a sentence. Language models analyze bodies of text data to provide a basis for their word predictions. They are used in natural language processing (NLP) applications, particularly ones that generate text as an output. Some of these applications include, machine translation and question-answering.\n","\n","üü° **How?**\n","\n","There are several different probabilistic approaches to modeling language, which vary depending on the purpose of the language model. From a technical perspective, the various types differ by the amount of text data they analyze and the math they use to analyze it (architecture). Some LMs we've already seen and will learn about during lectures are n-gram / count-based models, Recurrent Neural Networks (RNNs), and Transformer models.\n","\n","üü£ **Why?**\n","\n","Language modeling is crucial in modern NLP applications. It is the reason that machines can understand qualitative information. Each language model type, in one way or another, turns qualitative information into quantitative information. This allows people to communicate with machines as they do with each other to a limited extent. It is used directly in a variety of industries including tech, finance, healthcare, transportation, legal, military and government. Additionally, it's likely most people reading this have interacted with a language model in some way at some point in the day, whether it be through Google search, an autocomplete text function or engaging with a voice assistant.\n","\n","‚ÑπÔ∏è Source: [Original article](https://www.techtarget.com/searchenterpriseai/definition/language-modeling#:~:text=Language%20models%20determine%20word%20probability,predict%20or%20produce%20new%20sentences.)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"X_CK0Zl7iTAU"},"source":["<div style=\"padding:15px 15px 15px 15px;border-left:3px solid gray;background-color:#F3F3F3;border-radius: 15px;color:#424242;\">\n","\n","**In this part, you will train your own language models using the dataset created in Part 1.**\n","\n","You need to implement **3 different model variants**;\n","train and evaluate their perplexity.\n","    \n","| Model | Variant | Description |\n","|:---- |:----- | :----- |\n","|**LSTM** | Token embeddings trained from scratch | An LSTM model with a trainable token Embedding layer <br>that will be initialized randomly and trained from scratch along with the LM. |\n","| | Pre-trained token embeddings| An LSTM model with pre-trained GloVe embeddings as input <br>that will be ***frozen*** while the LM is training. |\n","| **Transformer** | Trained from scratch | A Transformer based model that follows the architecture of [DistilGPT2](https://huggingface.co/distilgpt2). |\n","    \n","</div>"]},{"cell_type":"markdown","metadata":{"id":"Smi1xBm3iTAV"},"source":["<a id=\"21\"></a>\n","## üéØ Q2.1: **Vanilla LSTM**.\n","\n","\n","<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #03befc;background-color:#eff7fe;border-radius: 15px;color:#424242;\">\n","\n","**First, we train a vanilla LSTM on our train/test dataLoaders:**\n","\n","- **Step 1**: Build the `VanillaLSTM` class, which takes:\n","  - `vocab_size`: size of vocabulary,\n","  - `embedding_dim`: dimension of token embedding,\n","  - `hidden_dim`: hidden dimension of lstm layer;\n","  - `num_layers`: number of stacked lstm layers;\n","  - `embedding_weights`: pretrained embedding weights. Train from scratch if set to `None`. Default: None;\n","  - `freeze_embeddings`: whether to freeze pretrained embeddings. Only be functional when `embedding_weights` is not None.\n","\n","- **Step 2**: Train the LSTM model with `train_dataloader`. We usually run only one epoch for language modelling task to prevent overfitting;\n","\n","- **Step 3**: Evaluate the LSTM by perplexity scores on `test_dataloader`.\n","\n","**TODOüîª: Implement `VanillaLSTM`, `train_lstm` and `test_lstm` function in `modeling.py`**.\n","\n","Detailed instructions are provided in the function description.\n","</div>\n"]},{"cell_type":"markdown","metadata":{"id":"Wsyfaq8yUg0j"},"source":["#### **LSTM from Scratch**\n","\n","We here train the LSTM embedding weights from scratch. The dimension of embedding is defined as `embedding_dim`.\n","\n","We set the `embedding_dim` as 100 here to compare with gensim pretrained embeddings."]},{"cell_type":"code","execution_count":21,"metadata":{"id":"pIdJ9c9-Uvco"},"outputs":[],"source":["from modeling import VanillaLSTM\n","\n","# Define the parameters to VanillaLSTM\n","## Hint: what do we have from Part1?\n","vocab_size = len(rnn_dataset.token2idx)\n","embedding_dim = 100\n","hidden_dim = 100\n","num_layers = 2\n","dropout_rate = 0.15\n","lr = 1e-3\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"PcfLRY96S2uk"},"outputs":[],"source":["model = VanillaLSTM(vocab_size, embedding_dim, hidden_dim, num_layers, dropout_rate).to(device)"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1707662593184,"user":{"displayName":"Simin Fan","userId":"15154949338491351516"},"user_tz":-60},"id":"eJ2Pqr0wTwAv","outputId":"cf6f2087-2188-4526-844d-6f67624ffe03"},"outputs":[{"name":"stdout","output_type":"stream","text":["Test Passed ‚úÖ\n"]}],"source":["test_lstm_scratch(model)"]},{"cell_type":"markdown","metadata":{"id":"BbpZkBndX259"},"source":["##### Train&Evaluation (LSTM-scratch)"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"yZTG7WHHTLd6"},"outputs":[],"source":["# Define optimizer and criterion (loss function)\n","## Hint: what do we have from Part1?\n","optimizer = optim.Adam(model.parameters(), lr=lr)\n","criterion = nn.CrossEntropyLoss(ignore_index=rnn_dataset.pad_idx)"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"5rHIOncbT1sW"},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/10973 [00:00<?, ?it/s]"]},{"name":"stderr","output_type":"stream","text":["  5%|‚ñç         | 503/10973 [00:43<14:53, 11.72it/s]"]},{"name":"stdout","output_type":"stream","text":["[Step   501] loss: 6.269\n"]},{"name":"stderr","output_type":"stream","text":["  9%|‚ñâ         | 1003/10973 [01:25<14:10, 11.73it/s]"]},{"name":"stdout","output_type":"stream","text":["[Step  1001] loss: 4.481\n"]},{"name":"stderr","output_type":"stream","text":[" 14%|‚ñà‚ñé        | 1503/10973 [02:08<13:26, 11.74it/s]"]},{"name":"stdout","output_type":"stream","text":["[Step  1501] loss: 3.684\n"]},{"name":"stderr","output_type":"stream","text":[" 18%|‚ñà‚ñä        | 2003/10973 [02:50<12:43, 11.75it/s]"]},{"name":"stdout","output_type":"stream","text":["[Step  2001] loss: 3.086\n"]},{"name":"stderr","output_type":"stream","text":[" 23%|‚ñà‚ñà‚ñé       | 2503/10973 [03:33<12:00, 11.76it/s]"]},{"name":"stdout","output_type":"stream","text":["[Step  2501] loss: 2.624\n"]},{"name":"stderr","output_type":"stream","text":[" 27%|‚ñà‚ñà‚ñã       | 3003/10973 [04:16<11:21, 11.70it/s]"]},{"name":"stdout","output_type":"stream","text":["[Step  3001] loss: 2.247\n"]},{"name":"stderr","output_type":"stream","text":[" 32%|‚ñà‚ñà‚ñà‚ñè      | 3503/10973 [04:58<10:35, 11.76it/s]"]},{"name":"stdout","output_type":"stream","text":["[Step  3501] loss: 1.937\n"]},{"name":"stderr","output_type":"stream","text":[" 36%|‚ñà‚ñà‚ñà‚ñã      | 4003/10973 [05:41<09:57, 11.67it/s]"]},{"name":"stdout","output_type":"stream","text":["[Step  4001] loss: 1.697\n"]},{"name":"stderr","output_type":"stream","text":[" 41%|‚ñà‚ñà‚ñà‚ñà      | 4503/10973 [06:23<09:11, 11.74it/s]"]},{"name":"stdout","output_type":"stream","text":["[Step  4501] loss: 1.485\n"]},{"name":"stderr","output_type":"stream","text":[" 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 5003/10973 [07:06<08:30, 11.70it/s]"]},{"name":"stdout","output_type":"stream","text":["[Step  5001] loss: 1.322\n"]},{"name":"stderr","output_type":"stream","text":[" 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 5503/10973 [07:49<07:45, 11.75it/s]"]},{"name":"stdout","output_type":"stream","text":["[Step  5501] loss: 1.175\n"]},{"name":"stderr","output_type":"stream","text":[" 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 6003/10973 [08:31<07:04, 11.71it/s]"]},{"name":"stdout","output_type":"stream","text":["[Step  6001] loss: 1.048\n"]},{"name":"stderr","output_type":"stream","text":[" 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 6503/10973 [09:14<06:23, 11.67it/s]"]},{"name":"stdout","output_type":"stream","text":["[Step  6501] loss: 0.939\n"]},{"name":"stderr","output_type":"stream","text":[" 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 7003/10973 [09:57<05:38, 11.73it/s]"]},{"name":"stdout","output_type":"stream","text":["[Step  7001] loss: 0.853\n"]},{"name":"stderr","output_type":"stream","text":[" 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 7503/10973 [10:39<04:55, 11.75it/s]"]},{"name":"stdout","output_type":"stream","text":["[Step  7501] loss: 0.780\n"]},{"name":"stderr","output_type":"stream","text":[" 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 8003/10973 [11:22<04:13, 11.71it/s]"]},{"name":"stdout","output_type":"stream","text":["[Step  8001] loss: 0.706\n"]},{"name":"stderr","output_type":"stream","text":[" 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 8503/10973 [12:04<03:30, 11.75it/s]"]},{"name":"stdout","output_type":"stream","text":["[Step  8501] loss: 0.650\n"]},{"name":"stderr","output_type":"stream","text":[" 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 9003/10973 [12:47<02:47, 11.73it/s]"]},{"name":"stdout","output_type":"stream","text":["[Step  9001] loss: 0.594\n"]},{"name":"stderr","output_type":"stream","text":[" 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 9503/10973 [13:30<02:05, 11.71it/s]"]},{"name":"stdout","output_type":"stream","text":["[Step  9501] loss: 0.550\n"]},{"name":"stderr","output_type":"stream","text":[" 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 10003/10973 [14:12<01:22, 11.72it/s]"]},{"name":"stdout","output_type":"stream","text":["[Step 10001] loss: 0.506\n"]},{"name":"stderr","output_type":"stream","text":[" 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 10503/10973 [14:55<00:40, 11.72it/s]"]},{"name":"stdout","output_type":"stream","text":["[Step 10501] loss: 0.472\n"]},{"name":"stderr","output_type":"stream","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10973/10973 [15:35<00:00, 11.73it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch Loss: 1.7100\n"]}],"source":["from modeling import train_lstm, test_lstm\n","\n","# ETS: take ~30mins for training #\n","train_lstm(model, train_dataloader, optimizer, criterion, device=device, tensorboard_path=\"./tensorboard/lstm_scratch\")\n","torch.save(model.state_dict(), 'models/lstm_scratch.pt')"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 4/1220 [00:00<01:09, 17.57it/s]"]},{"name":"stderr","output_type":"stream","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1220/1220 [00:59<00:00, 20.44it/s]"]},{"name":"stdout","output_type":"stream","text":["Test loss: 0.235\n","Test Perplexity: 1.264\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"data":{"text/plain":["(0.23453849934530063, 1.2643251471892072)"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["test_lstm(model, test_dataloader, criterion, device=device)"]},{"cell_type":"markdown","metadata":{"id":"3wBTcLdQUotA"},"source":["#### **LSTM with Pretrained Embeddings**\n","\n","We first download the gensim embeddings, then fix the embedding layer in the LSTM model."]},{"cell_type":"code","execution_count":27,"metadata":{"id":"qnQp3iCNUrmB"},"outputs":[{"name":"stdout","output_type":"stream","text":["[==================================================] 100.0% 128.1/128.1MB downloaded\n"]}],"source":["import gensim.downloader\n","# Download the \"glove-wiki-gigaword-100\" embeddings\n","glove_vectors = gensim.downloader.load('glove-wiki-gigaword-100')\n","initial_embedding_weight = torch.nn.Embedding(len(rnn_dataset.token2idx),\n","                                              embedding_dim).weight.detach().numpy()\n","\n","# Get the pretrained embeddings from gensim for each tokens\n","for word_type, idx in rnn_dataset.token2idx.items():\n","  if word_type in glove_vectors.key_to_index.keys():\n","      initial_embedding_weight[idx] = glove_vectors[word_type]"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"etXoX2HDVrzj"},"outputs":[],"source":["# Define the parameters to VanillaLSTM\n","## Hint: Use the same params as LSTM_scratch\n","vocab_size = len(rnn_dataset.token2idx)\n","embedding_dim = 100\n","hidden_dim = 100\n","num_layers = 2\n","dropout_rate = 0.15\n","lr = 1e-3\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"EBUZJet7XbpS"},"outputs":[],"source":["model = VanillaLSTM(vocab_size, embedding_dim, hidden_dim,\n","                    num_layers, dropout_rate=dropout_rate,\n","                    embedding_weights=initial_embedding_weight,\n","                    freeze_embeddings=True).to(device)\n","\n","## Define optimizer and criterion\n","optimizer = optim.Adam(model.parameters(), lr=lr)\n","criterion = nn.CrossEntropyLoss(ignore_index=rnn_dataset.pad_idx)"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1707662620832,"user":{"displayName":"Simin Fan","userId":"15154949338491351516"},"user_tz":-60},"id":"AtlqPsZeZg7s","outputId":"59b9101a-c92c-416e-eb81-6c09ddfdec07"},"outputs":[{"name":"stdout","output_type":"stream","text":["Test Passed ‚úÖ\n"]}],"source":["test_lstm_pretrained(model)"]},{"cell_type":"markdown","metadata":{"id":"ZyRP0QzGX8_4"},"source":["##### Train&Evaluation (LSTM-pretrained)"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"RZN6B8L3XxSa"},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 2/10973 [00:00<19:28,  9.39it/s]"]},{"name":"stderr","output_type":"stream","text":["  5%|‚ñç         | 502/10973 [00:42<14:46, 11.81it/s]"]},{"name":"stdout","output_type":"stream","text":["[Step   501] loss: 6.716\n"]},{"name":"stderr","output_type":"stream","text":["  9%|‚ñâ         | 1002/10973 [01:24<14:02, 11.84it/s]"]},{"name":"stdout","output_type":"stream","text":["[Step  1001] loss: 4.921\n"]},{"name":"stderr","output_type":"stream","text":[" 14%|‚ñà‚ñé        | 1502/10973 [02:07<13:22, 11.81it/s]"]},{"name":"stdout","output_type":"stream","text":["[Step  1501] loss: 4.103\n"]},{"name":"stderr","output_type":"stream","text":[" 18%|‚ñà‚ñä        | 2002/10973 [02:49<12:42, 11.77it/s]"]},{"name":"stdout","output_type":"stream","text":["[Step  2001] loss: 3.545\n"]},{"name":"stderr","output_type":"stream","text":[" 23%|‚ñà‚ñà‚ñé       | 2502/10973 [03:31<11:58, 11.79it/s]"]},{"name":"stdout","output_type":"stream","text":["[Step  2501] loss: 3.142\n"]},{"name":"stderr","output_type":"stream","text":[" 27%|‚ñà‚ñà‚ñã       | 3002/10973 [04:14<11:17, 11.77it/s]"]},{"name":"stdout","output_type":"stream","text":["[Step  3001] loss: 2.770\n"]},{"name":"stderr","output_type":"stream","text":[" 32%|‚ñà‚ñà‚ñà‚ñè      | 3502/10973 [04:56<10:33, 11.79it/s]"]},{"name":"stdout","output_type":"stream","text":["[Step  3501] loss: 2.474\n"]},{"name":"stderr","output_type":"stream","text":[" 36%|‚ñà‚ñà‚ñà‚ñã      | 4002/10973 [05:39<09:51, 11.79it/s]"]},{"name":"stdout","output_type":"stream","text":["[Step  4001] loss: 2.211\n"]},{"name":"stderr","output_type":"stream","text":[" 41%|‚ñà‚ñà‚ñà‚ñà      | 4502/10973 [06:21<09:11, 11.74it/s]"]},{"name":"stdout","output_type":"stream","text":["[Step  4501] loss: 1.976\n"]},{"name":"stderr","output_type":"stream","text":[" 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 5002/10973 [07:03<08:26, 11.79it/s]"]},{"name":"stdout","output_type":"stream","text":["[Step  5001] loss: 1.778\n"]},{"name":"stderr","output_type":"stream","text":[" 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 5502/10973 [07:46<07:44, 11.78it/s]"]},{"name":"stdout","output_type":"stream","text":["[Step  5501] loss: 1.614\n"]},{"name":"stderr","output_type":"stream","text":[" 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 6002/10973 [08:28<07:01, 11.80it/s]"]},{"name":"stdout","output_type":"stream","text":["[Step  6001] loss: 1.466\n"]},{"name":"stderr","output_type":"stream","text":[" 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 6502/10973 [09:11<06:19, 11.77it/s]"]},{"name":"stdout","output_type":"stream","text":["[Step  6501] loss: 1.329\n"]},{"name":"stderr","output_type":"stream","text":[" 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 7002/10973 [09:53<05:37, 11.77it/s]"]},{"name":"stdout","output_type":"stream","text":["[Step  7001] loss: 1.229\n"]},{"name":"stderr","output_type":"stream","text":[" 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 7502/10973 [10:36<04:54, 11.77it/s]"]},{"name":"stdout","output_type":"stream","text":["[Step  7501] loss: 1.137\n"]},{"name":"stderr","output_type":"stream","text":[" 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 8002/10973 [11:18<04:12, 11.75it/s]"]},{"name":"stdout","output_type":"stream","text":["[Step  8001] loss: 1.058\n"]},{"name":"stderr","output_type":"stream","text":[" 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 8502/10973 [12:00<03:30, 11.74it/s]"]},{"name":"stdout","output_type":"stream","text":["[Step  8501] loss: 0.979\n"]},{"name":"stderr","output_type":"stream","text":[" 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 9002/10973 [12:43<02:47, 11.80it/s]"]},{"name":"stdout","output_type":"stream","text":["[Step  9001] loss: 0.919\n"]},{"name":"stderr","output_type":"stream","text":[" 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 9502/10973 [13:25<02:04, 11.77it/s]"]},{"name":"stdout","output_type":"stream","text":["[Step  9501] loss: 0.870\n"]},{"name":"stderr","output_type":"stream","text":[" 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 10002/10973 [14:08<01:22, 11.76it/s]"]},{"name":"stdout","output_type":"stream","text":["[Step 10001] loss: 0.824\n"]},{"name":"stderr","output_type":"stream","text":[" 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 10502/10973 [14:50<00:40, 11.72it/s]"]},{"name":"stdout","output_type":"stream","text":["[Step 10501] loss: 0.786\n"]},{"name":"stderr","output_type":"stream","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10973/10973 [15:30<00:00, 11.79it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch Loss: 2.1215\n"]},{"name":"stderr","output_type":"stream","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1220/1220 [00:59<00:00, 20.34it/s]"]},{"name":"stdout","output_type":"stream","text":["Test loss: 0.489\n","Test Perplexity: 1.631\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"data":{"text/plain":["(0.4888955529473844, 1.6305144083032515)"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["# ETS: take ~30mins for training #\n","train_lstm(model, train_dataloader, optimizer, criterion, device=device, tensorboard_path=\"./tensorboard/lstm_pretrained\")\n","torch.save(model.state_dict(), 'models/lstm_pretrained.pt')\n","test_lstm(model, test_dataloader, criterion, device=device)"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[],"source":["model3 = VanillaLSTM(vocab_size, embedding_dim, hidden_dim, num_layers, dropout_rate).to(device)"]},{"cell_type":"markdown","metadata":{"id":"vFYGXHj1YESh"},"source":["#### **Compare LSTM-scratch and LSTM-pretrained?**\n","\n","**TODOüîª: compare the *performance* and *training efficiency* between `LSTM-scratch` and `LSTM-pretrained`**."]},{"cell_type":"markdown","metadata":{"id":"UGW7lXk7YIvI"},"source":["\n","\n","ans: The test loss and perplexity of the LSTM-scratch model is lower than the LSTM-pretrained model (around 1.26 vs 1.63 perplexity respectively). The reason for this can be the data leakage between training and test data and since the pretrained embeddings are trained on a large corpus, they are expected to generalize better, however, for this task, creating task-specific embeddings helps to achieve better results.The training efficiency of the LSTM-pretrained model is better than the LSTM-scratch model (around 11.72it/s for LSTM-scratch while 11.80it/s for LSTM-pretrained) as the pretrained embeddings are already trained (so we freeze embedding layer) and the model only needs to learn the weights of the LSTM layers. The LSTM-scratch model needs to learn the weights of the embeddings and the LSTM layers."]},{"cell_type":"markdown","metadata":{"id":"ieaNrQIJzow-"},"source":["<a id=\"22\"></a>\n","## üéØ Q2.2: **Train a Transformer: DistillGPT2**.\n","\n","\n","<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #03befc;background-color:#eff7fe;border-radius: 15px;color:#424242;\">\n","\n","**We train a DistillGPT2 on our train/test dataLoaders:**\n","\n","- **Step 1**: Rebuild the datasets and dataloaders using huggingface tokenizer;\n","\n","- **Step 2**: Train a DistilGPT2 efficiently using Trainer form `transformers`.\n","\n","- **Step 3**: Evaluate perplexity scores on `test_dataloader`.\n","\n","**TODOüîª: follow the instructions below**.\n","</div>"]},{"cell_type":"code","execution_count":36,"metadata":{"id":"jUWqgNzvzoj-"},"outputs":[],"source":["from transformers import AutoConfig, AutoModelWithLMHead, AutoTokenizer, DataCollatorForLanguageModeling, Trainer, TrainingArguments\n","\n","model_name = \"distilgpt2\"\n","tokenizer_checkpoint = \"distilgpt2\""]},{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2675,"status":"ok","timestamp":1707660065541,"user":{"displayName":"Simin Fan","userId":"15154949338491351516"},"user_tz":-60},"id":"QLaG6iasiTAd","outputId":"8568c927-1698-4e29-fb0c-c32e860ef5d5"},"outputs":[{"name":"stderr","output_type":"stream","text":["/media1/data/said/encdec/lib/python3.10/site-packages/transformers/models/auto/modeling_auto.py:1571: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n","  warnings.warn(\n"]}],"source":["MAX_SEQ_LENGTH = 128\n","\n","# Load model from scratch\n","model_config = AutoConfig.from_pretrained(model_name)\n","gpt2_scratch_model = AutoModelWithLMHead.from_config(model_config)\n","gpt_tokenizer = AutoTokenizer.from_pretrained(model_name)\n","gpt_tokenizer.pad_token = gpt_tokenizer.eos_token"]},{"cell_type":"markdown","metadata":{"id":"Z29EEczseE9-"},"source":["#### **Tokenize Datasets**\n"," Huggingface provides pretrained tokenizer for `DistilGPT2`, so we have to tokenize our dataset with this tokenizer.\n","\n","**TODOüîª: Implement `get_encoded_dataset`**."]},{"cell_type":"code","execution_count":38,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["d9487cb740524a9989e94ce5d87e8c98","c7c1bcb88c7a4f48ba5f818a4a697f5e","fd072dd48e394637ae6b4068e4ad30de","c22beae6fb16496e9f3f25239341becf","138871ee82ff47c3af673a08bd3ec4d0","093cb168c2b24cfbb199171a0f60b96e","6263c708fb1448de8587a657fcf2d38f","827526a107f745b0b686efe5da122833","5da3fb9adbaa4d99a44b2054506c8b12","8b6fd1a431a14aea98b821f4aaf34a31","70f25545be2d42ccad3d36fd1974f942","bb2190eebc7e428b96d4bede0f1f9d55","192d348aadd647b081f0f52a232fc953","c88866f880d74e83a45d94c624f2a30e","7540eab42af64d088cbb5d3e92c994a5","d66f1974b6e34111b538985e810f3837","f9155aa243924a1c8135ca6d06a63d1b","68953a0dfe4345238ceb3c41e647dbc7","61616b00cc534fa8b321a5dbad789e24","7095989fcb954bbbb0512bb5363f19c4","ff2575473f3443c1b71d30f29b507cca","1da2811f157d44b9bf33518ddaaf7442","9d87dc786c0c4b7a92140a6859c86e2f","8250f82beb194339b7a0272dc7da6bbe","04d7f784399e421493ffbd8d02e007da","f56202dca8854edfb0fdc69c131cad6b","1dfcf13e5feb491aa0fd84f03851f326","de7a729fa16544de9b9480e41f1a9d60","eb23d79b77ca4e5e920032339b4eabb8","285a4d5837b2481f9a9c94902d501f31","c38330ee41c94fe08dc11c047fb57db8","98297cde5bff45c594db633c7845e8a1","a1d3e6439dad4c57b8f94115a153fe25","33a9fa0d8d604710bec9fc806a6917d2","830aa101c887417a918712f2a5ee18ef","3f3b978021f34c93941567c169f312b4","1dbcea3369004cc8bcbb563845e8185b","eb11abc069224b2f9e8ee35f403f9b88","3bf734883fb64e8b97625db34c364f40","0fb98d2d737d4148a75386484c838fb8","2a5278ebb1774d2b83a4dbeb47a2cd9b","da19f2f9eaeb4724aae004722a1b1e3e","c308ad3e35d64a428afa303d9bdd3fde","d191da7183e440838dc22930b47eb76e"]},"executionInfo":{"elapsed":563338,"status":"ok","timestamp":1707660628873,"user":{"displayName":"Simin Fan","userId":"15154949338491351516"},"user_tz":-60},"id":"6CrcpJNQceve","outputId":"5b634f1a-baca-4286-ed76-7999d44c53e8"},"outputs":[{"name":"stderr","output_type":"stream","text":["Map:   2%|‚ñè         | 2000/97536 [00:00<00:13, 6828.25 examples/s]"]},{"name":"stderr","output_type":"stream","text":["Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 97536/97536 [00:12<00:00, 8067.98 examples/s]\n","Filter: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 97536/97536 [00:08<00:00, 11433.81 examples/s]\n","Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 33935/33935 [00:06<00:00, 5546.59 examples/s]\n","Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 33935/33935 [00:06<00:00, 5513.02 examples/s]\n"]}],"source":["def get_encoded_dataset(wikitext_dataset):\n","  # TODO: Tokenize wikitext_dataset with DistilGPT2 tokenizer. Padding to `max_length`.\n","  # I used the `map` with batched=true to speed up the process ref: https://huggingface.co/docs/datasets/en/about_map_batch\n","  encoded_dataset = wikitext_dataset.map(lambda sample: gpt_tokenizer(sample[\"text\"], padding=\"max_length\", max_length=MAX_SEQ_LENGTH), batched=True) \n","  # TODO: Filter out samples longer than MAX_SEQ_LENGTH=128\n","  encoded_dataset = encoded_dataset.filter(lambda sample: len(sample[\"input_ids\"]) <= MAX_SEQ_LENGTH)\n","\n","  encoded_dataset = encoded_dataset.map(\n","    lambda example: {\"input_ids\": example['input_ids'][:MAX_SEQ_LENGTH],\n","                     \"attention_mask\": example[\"attention_mask\"][:MAX_SEQ_LENGTH]})\n","  encoded_dataset = encoded_dataset.remove_columns(\"text\")\n","  encoded_dataset = encoded_dataset.with_format(\"torch\")\n","  encoded_dataset = encoded_dataset.map(lambda example:{\"labels\": example[\"input_ids\"]})\n","  return encoded_dataset\n","\n","## ETS: ~10mins to run.\n","encoded_dataset = get_encoded_dataset(wikitext_dataset)\n","transformer_train_dataset, transformer_test_dataset = torch.utils.data.random_split(encoded_dataset,\n","                                                               [int(len(encoded_dataset)*0.9), len(encoded_dataset)-int(len(encoded_dataset)*0.9)])"]},{"cell_type":"markdown","metadata":{"id":"DdNMjJm4gK8W"},"source":["#### **Build Trainer**\n"," Huggingface provides very efficient `Trainer` wrapper for language model training and evaluation.\n","\n","**TODOüîª: Run the following blocks to define the training arguements and trainer, then start training simply by `trainer.train()`**."]},{"cell_type":"code","execution_count":39,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":528,"status":"ok","timestamp":1707661298931,"user":{"displayName":"Simin Fan","userId":"15154949338491351516"},"user_tz":-60},"id":"JV7Zq35AiTAf","outputId":"aaea89f4-f2a3-4151-dbe3-ad78beda8f67"},"outputs":[],"source":["data_collator = DataCollatorForLanguageModeling(tokenizer=gpt_tokenizer, mlm=False)\n","training_args = TrainingArguments(\n","    output_dir=f\"{model_name}-wikitext103\",\n","    evaluation_strategy = \"steps\",\n","    num_train_epochs = 1.0,\n","    logging_steps=500,\n","    learning_rate=2e-5,\n","    save_steps=1000,\n","    weight_decay=0.01,\n","    report_to=\"tensorboard\",\n","    logging_dir=\"./tensorboard/distilgpt2-scratch\")\n","\n","trainer = Trainer(\n","    model=gpt2_scratch_model,\n","    args=training_args,\n","    tokenizer=gpt_tokenizer,\n","    train_dataset=transformer_train_dataset,\n","    eval_dataset=transformer_test_dataset,\n","    data_collator=data_collator,)"]},{"cell_type":"code","execution_count":40,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":435},"executionInfo":{"elapsed":26184,"status":"error","timestamp":1707661333228,"user":{"displayName":"Simin Fan","userId":"15154949338491351516"},"user_tz":-60},"id":"W9gVEQ6nUvcp","outputId":"8bef41ee-c8b3-4fa8-fa21-c2f509e31e9b","scrolled":true},"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2' max='3818' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [   2/3818 : < :, Epoch 0.00/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["# ETS: ~20mins to run.\n","trainer.train()\n","trainer.save_model('models/distilgpt2_scratch')"]},{"cell_type":"markdown","metadata":{"id":"zXHew822jUZl"},"source":["**TODOüîª: Run evaluation by `trainer.evaluate()`**."]},{"cell_type":"code","execution_count":41,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":124},"executionInfo":{"elapsed":37833,"status":"ok","timestamp":1707661376315,"user":{"displayName":"Simin Fan","userId":"15154949338491351516"},"user_tz":-60},"id":"HiuwHEY6iTAg","outputId":"d548a5df-50c0-4349-d393-4899666c2117","scrolled":true},"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='13' max='425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 13/425 00:00 < 00:10, 39.82 it/s]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["The perplexity on the test dataset is 362.730\n"]}],"source":["# ETS: ~1min to run.\n","eval_result = trainer.evaluate()\n","perplexity_from_scratch = math.exp(eval_result[\"eval_loss\"])\n","print(f\"The perplexity on the test dataset is {perplexity_from_scratch:.3f}\")"]},{"cell_type":"markdown","metadata":{"id":"zyg5BbR6jgoB"},"source":["#### **Compare to the Pretrained DistilGPT2**\n","\n","**TODOüîª: Load the pretrained `DistilGPT2` checkpoint from Huggingface.\n","We only run evaluation of the `trainsformer_test_dataset` here. Compare the performance between `gpt2_scratch_model` and `gpt2_pretrained_model`.**."]},{"cell_type":"code","execution_count":42,"metadata":{"id":"OJpB8U-1iTAh"},"outputs":[],"source":["from transformers import AutoModelForCausalLM, AutoTokenizer\n","from transformers import Trainer, TrainingArguments\n","\n","model_id = \"distilgpt2\"\n","gpt2_pretrained_model = AutoModelForCausalLM.from_pretrained(model_id)\n","tokenizer_pretrained_gpt = AutoTokenizer.from_pretrained(model_id)\n","tokenizer_pretrained_gpt.pad_token = tokenizer_pretrained_gpt.eos_token\n"]},{"cell_type":"code","execution_count":43,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":197,"status":"ok","timestamp":1707661642031,"user":{"displayName":"Simin Fan","userId":"15154949338491351516"},"user_tz":-60},"id":"bHrdXr64iTAh","outputId":"668daeec-67ea-4677-bfa1-095c952b1caf"},"outputs":[],"source":["training_args = TrainingArguments(\n","    output_dir=f\"pretrained_{model_id}-wikitext103\",\n","    evaluation_strategy = \"steps\",\n","    num_train_epochs = 1.0,\n","    logging_steps=500,\n","    learning_rate=2e-5,\n","    save_steps=1000,\n","    weight_decay=0.01,\n","    report_to=\"tensorboard\",\n","    logging_dir=\"./tensorboard/distilgpt2-pretrained\")\n","\n","pretrained_trainer = Trainer(\n","    model=gpt2_pretrained_model,\n","    args=training_args,\n","    tokenizer=tokenizer_pretrained_gpt,\n","    train_dataset=transformer_train_dataset,\n","    eval_dataset=transformer_test_dataset,\n","    data_collator=data_collator,)"]},{"cell_type":"code","execution_count":44,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"elapsed":38088,"status":"ok","timestamp":1707661693096,"user":{"displayName":"Simin Fan","userId":"15154949338491351516"},"user_tz":-60},"id":"Rm_7YZY6iTAi","outputId":"a2127f6b-fec2-4534-839b-7bfaa035e948"},"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='13' max='425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 13/425 00:00 < 00:10, 40.54 it/s]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["The perplexity of pretrained distilgpt2 on the test dataset is 100.631\n"]}],"source":["# ETS: ~1min.\n","eval_result = pretrained_trainer.evaluate()\n","perplexity_pretrained_model = math.exp(eval_result[\"eval_loss\"])\n","print(f\"The perplexity of pretrained {model_id} on the test dataset is {perplexity_pretrained_model:.3f}\")"]},{"cell_type":"markdown","metadata":{"id":"6FxdACC5iTAi"},"source":["<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #8e7cc3;background-color:#e4e1eb;border-radius: 15px;color:#424242;\">\n","    \n","üéâ  **Excellent work!** We have completed Langauge Modelling tasks!\n","\n","#### Part 2 - Checklist\n","Here are the core building blocks you created and that you will need for Part 3:\n","   \n","- [X] LSTM-variants checkpoints.\n","- [X] LSTM-variants ppl scores.\n","- [X] Transformer-variants ppl scores.\n","\n","</div>"]},{"cell_type":"markdown","metadata":{},"source":["Just before you move on to the Part 3, let's save a few things which we will use in the Part 3 so that you don't have to run Part 1 and 2 every time."]},{"cell_type":"markdown","metadata":{},"source":["#### Save wikitext vocabulary"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[],"source":["from utils import save_binary\n","\n","save_binary(rnn_dataset.dataset_vocab, \"wikitext_vocab.pkl\")"]},{"cell_type":"markdown","metadata":{},"source":["---\n","\n","<a id=\"3\"></a>\n","# PART 3: Fine-tune on the Text Simplification task üöÄ\n","\n","In this part we will fine-tune and test language models on the downstream task of text simplification (a.k.a text compression). In this task, given a piece of text, the goal is to simplify (or compress) this text by extracting the most important information from it. We will consider encoder-decoder models built on top of the LSTM models you built in Part 2 and also pretrained transformer models from Huggingface.\n"," \n","Hence, there will be two sections in this final part of the assignment:\n","- [3.1 Finetune a custom Encoder-Decoder model on text simplification task](#32)\n","- [3.2 Finetune pretrained T5 model (an encoder-decoder) model on text simplification task](#33)\n","\n","### Dataset\n","In this part, we will use a sentence compression [dataset](https://huggingface.co/datasets/embedding-data/sentence-compression) available on Huggingface. Each row in this dataset contains two sentences: the original sentence and the simplified one.\n","\n","An example from this dataset is the following:\n","\n","**Original sentence:** \"The JSE kept toying with an all time high by midday today as resources continued to fuel the bourse.\"\n","\n","**Simplified sentence:** \"JSE keeps toying with all time high\"\n","\n","This dataset contains around 180k examples, but we will only use a subset of it."]},{"cell_type":"markdown","metadata":{},"source":["### Load and preprocess sentence-compression dataset"]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to /home/said/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"data":{"text/plain":["True"]},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":["# We will use NLTK to tokenize the text\n","from datasets import load_dataset\n","import nltk\n","nltk.download('punkt')"]},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading readme: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.88k/4.88k [00:00<00:00, 10.9MB/s]\n","Downloading data: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14.2M/14.2M [00:00<00:00, 21.1MB/s]\n","Generating train split: 180000 examples [00:00, 1123897.42 examples/s]\n"]}],"source":["scomp = load_dataset(\"embedding-data/sentence-compression\")"]},{"cell_type":"markdown","metadata":{},"source":["Let's inspect the dataset. Note that this dataset only contains a train split (we will create our own train, validation and test sets from this split later)"]},{"cell_type":"code","execution_count":48,"metadata":{},"outputs":[{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['set'],\n","        num_rows: 180000\n","    })\n","})"]},"execution_count":48,"metadata":{},"output_type":"execute_result"}],"source":["scomp"]},{"cell_type":"code","execution_count":49,"metadata":{},"outputs":[{"data":{"text/plain":["{'set': [\"The USHL completed an expansion draft on Monday as 10 players who were on the rosters of USHL teams during the 2009-10 season were selected by the League's two newest entries, the Muskegon Lumberjacks and Dubuque Fighting Saints.\",\n","  'USHL completes expansion draft']}"]},"execution_count":49,"metadata":{},"output_type":"execute_result"}],"source":["scomp[\"train\"][0]"]},{"cell_type":"markdown","metadata":{},"source":["First to make our dataset and sentences smaller, let's filter examples where the original sentence has more than 10 and less than 100 words."]},{"cell_type":"markdown","metadata":{},"source":["<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #03befc;background-color:#eff7fe;border-radius: 15px;color:#424242;\">\n","\n","üéØ Goal: Keep only the examples that has more than 10 and less than 100 words in its original sentence.\n","\n","</div>"]},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Filter: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 180000/180000 [00:22<00:00, 7905.58 examples/s]\n"]}],"source":["scomp_small_train = scomp[\"train\"].filter(lambda sample: 10 < len(nltk.word_tokenize(sample[\"set\"][0])) < 100)\n"]},{"cell_type":"code","execution_count":51,"metadata":{},"outputs":[],"source":["scomp_small = scomp\n","scomp_small[\"train\"] = scomp_small_train"]},{"cell_type":"markdown","metadata":{},"source":["Next, let's define our train, validation and test sets of size 10k, 1k, and 1k respectively and also get rid of the 'set' attribute."]},{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[],"source":["scomp_train, scomp_val, scomp_test = scomp_small[\"train\"][:10000]['set'], scomp_small[\"train\"][10000:11000]['set'], scomp_small[\"train\"][11000:12000]['set']"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"22\"></a>\n","## üéØ Q3.1: **Finetune custom encoder-decoder model on sentence simplification task**.\n","\n","\n","<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #03befc;background-color:#eff7fe;border-radius: 15px; color:#424242;\">\n","\n","**In this section, we will build a model based on the [encoder-decoder architecture](https://arxiv.org/abs/1409.3215) and finetune it on our text simplification task. As you probably know by now that vanilla encoder-decoder models do not perform well when we have long-range dependencies. Therefore, we will build one where the decoder uses [additive attention](https://arxiv.org/abs/1409.0473) over encoder outputs. You will need to finish the following main steps:**\n","\n","- **Step 1**: Implement a Tokenizer\n","\n","- **Step 2**: Build a Pytorch Dataset\n","\n","- **Step 3**: Implement an Encoder-Decoder Model\n","\n","- **Step 4**: Finetune the model on the task\n","\n","- **Step 5**: Test and evaluate model performance\n","\n","**TODOüîª: follow the instructions below**.\n","</div>"]},{"cell_type":"markdown","metadata":{},"source":["### Implement a tokenizer\n","We will first implement a tokenizer for our dataset. This tokenizer will take our vocabulary from the Part 1 and will have methods to encode a given text and decode a given text ids."]},{"cell_type":"markdown","metadata":{},"source":["<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #03befc;background-color:#eff7fe;border-radius: 15px;color:#424242;\">\n","\n","üéØ Goal:  **Go to `data.py` and implement the `CustomTokenizer` class.**\n","    \n","</div>"]},{"cell_type":"markdown","metadata":{},"source":["Let's first load our wikitext vocabulary from Part 1."]},{"cell_type":"code","execution_count":53,"metadata":{},"outputs":[],"source":["from utils import load_binary\n","\n","wikitext_vocab = load_binary(\"wikitext_vocab.pkl\")"]},{"cell_type":"markdown","metadata":{},"source":["Initialize the custom tokenizer with this vocabulary."]},{"cell_type":"code","execution_count":54,"metadata":{},"outputs":[],"source":["from data import CustomTokenizer\n","\n","custom_tokenizer = CustomTokenizer(vocab=wikitext_vocab)"]},{"cell_type":"markdown","metadata":{},"source":["### Implement a pytorch dataset\n","Now we will implement a Pytorch dataset that will represent our data in a suitable format for our model fine-tuning later."]},{"cell_type":"markdown","metadata":{},"source":["<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #03befc;background-color:#eff7fe;border-radius: 15px;color:#424242;\">\n","\n","üéØ Goal:  **Go to `data.py` and implement the `SCompDataset` class.**\n","    \n","</div>"]},{"cell_type":"markdown","metadata":{},"source":["Initialize train, validation and test pytorch datasets."]},{"cell_type":"code","execution_count":55,"metadata":{},"outputs":[],"source":["from data import SCompDataset\n","\n","MAX_SEQ_LENGTH = 128\n","scomp_train_ds = SCompDataset(scomp_train, custom_tokenizer, MAX_SEQ_LENGTH)\n","scomp_val_ds = SCompDataset(scomp_val, custom_tokenizer, MAX_SEQ_LENGTH)\n","scomp_test_ds = SCompDataset(scomp_test, custom_tokenizer, MAX_SEQ_LENGTH)"]},{"cell_type":"markdown","metadata":{},"source":["Initialize dataloaders for our datasets respectively."]},{"cell_type":"code","execution_count":56,"metadata":{},"outputs":[],"source":["from torch.utils.data import DataLoader\n","\n","# feel free to change batch size according to your GPU memory\n","scomp_train_dataloader = DataLoader(scomp_train_ds, batch_size=32, shuffle=True)\n","scomp_val_dataloader = DataLoader(scomp_val_ds, batch_size=32, shuffle=True)\n","scomp_test_dataloader = DataLoader(scomp_test_ds, batch_size=32, shuffle=True)"]},{"cell_type":"markdown","metadata":{},"source":["### Implement an Encoder-Decoder model\n","In this section, you will implement a model based on Encoder-Decoder architecture where the encoder will be one of the LSTM variants you implemented in Part 2. You will specifically implement an attention-based encoder-decoder where decoder attends over the encoder outputs to allow it to handle long range dependencies well."]},{"cell_type":"markdown","metadata":{},"source":["<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #03befc;background-color:#eff7fe;border-radius: 15px;color:#424242;\">\n","\n","üéØ Goal:  **Go to `modeling.py` and implement the `Encoder`, `AdditiveAttention`, `Decoder` and `EncoderDecoder` classes.**\n","    \n","</div>"]},{"cell_type":"markdown","metadata":{},"source":["Next we will load a pretrained encoder from Part 2. Choose the encoder that had best performance based on the perplexity metric."]},{"cell_type":"code","execution_count":58,"metadata":{},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":58,"metadata":{},"output_type":"execute_result"}],"source":["from modeling import VanillaLSTM\n","\n","vocab_size = len(wikitext_vocab)\n","embedding_dim = 100\n","hidden_dim = 100\n","num_layers = 2\n","dropout_rate = 0.15\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n","\n","pretrained_encoder = VanillaLSTM(vocab_size, embedding_dim, hidden_dim,\n","                                  num_layers, dropout_rate=dropout_rate).to(device)\n","\n","# TODO: Load the pretrained model from the file\n","pretrained_encoder.load_state_dict(torch.load('models/lstm_scratch.pt'))"]},{"cell_type":"markdown","metadata":{},"source":["Next we will need to implement training, evaluation and generation methods."]},{"cell_type":"markdown","metadata":{},"source":["<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #03befc;background-color:#eff7fe;border-radius: 15px;color:#424242;\">\n","\n","üéØ Goal:  **Go to `modeling.py` and implement the `seq2seq_train`, `seq2seq_eval` and `seq2seq_generate` functions.**\n","    \n","</div>"]},{"cell_type":"markdown","metadata":{},"source":["Now we are ready to finetune our encoder-decoder models on the sentence simplification dataset."]},{"cell_type":"code","execution_count":59,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["The model has 25,470,167 trainable parameters\n"]}],"source":["from modeling import EncoderDecoder\n","\n","lr = 1e-3\n","dropout_rate = 0.15\n","bos_token_id = custom_tokenizer.bos_token_id\n","encoder_decoder = EncoderDecoder(hidden_dim, vocab_size, vocab_size, bos_token_id=bos_token_id, dropout_rate=dropout_rate, pretrained_encoder=pretrained_encoder).to(device)\n","optimizer = optim.Adam(encoder_decoder.parameters(), lr=lr)\n","criterion = nn.NLLLoss(ignore_index=custom_tokenizer.pad_token_id)\n","num_params = sum(p.numel() for p in encoder_decoder.parameters() if p.requires_grad)\n","print(f'The model has {num_params:,} trainable parameters')"]},{"cell_type":"code","execution_count":60,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/20 [00:00<?, ?it/s]"]},{"name":"stderr","output_type":"stream","text":[]},{"name":"stdout","output_type":"stream","text":["[1,   100] loss: 5.600\n"]},{"name":"stderr","output_type":"stream","text":[]},{"name":"stdout","output_type":"stream","text":["[1,   200] loss: 4.692\n"]},{"name":"stderr","output_type":"stream","text":[]},{"name":"stdout","output_type":"stream","text":["[1,   300] loss: 4.549\n"]},{"name":"stderr","output_type":"stream","text":[]},{"name":"stdout","output_type":"stream","text":["Epoch 1 | Train Loss: 4.9262\n"]},{"name":"stderr","output_type":"stream","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:03<00:00,  9.29it/s]\n","  5%|‚ñå         | 1/20 [02:11<41:45, 131.87s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 1 | Eval Loss: 4.5141\n"]},{"name":"stderr","output_type":"stream","text":[]},{"name":"stdout","output_type":"stream","text":["[2,   100] loss: 4.265\n"]},{"name":"stderr","output_type":"stream","text":[]},{"name":"stdout","output_type":"stream","text":["[2,   200] loss: 4.240\n"]},{"name":"stderr","output_type":"stream","text":[]},{"name":"stdout","output_type":"stream","text":["[2,   300] loss: 4.219\n"]},{"name":"stderr","output_type":"stream","text":[]},{"name":"stdout","output_type":"stream","text":["Epoch 2 | Train Loss: 4.2417\n"]},{"name":"stderr","output_type":"stream","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:03<00:00,  9.93it/s]\n"," 10%|‚ñà         | 2/20 [04:23<39:32, 131.83s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 2 | Eval Loss: 4.4099\n"]},{"name":"stderr","output_type":"stream","text":[]},{"name":"stdout","output_type":"stream","text":["[3,   100] loss: 4.040\n"]},{"name":"stderr","output_type":"stream","text":[]},{"name":"stdout","output_type":"stream","text":["[3,   200] loss: 4.007\n"]},{"name":"stderr","output_type":"stream","text":[]},{"name":"stdout","output_type":"stream","text":["[3,   300] loss: 3.981\n"]},{"name":"stderr","output_type":"stream","text":[]},{"name":"stdout","output_type":"stream","text":["Epoch 3 | Train Loss: 4.0080\n"]},{"name":"stderr","output_type":"stream","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:03<00:00, 10.42it/s]\n"," 15%|‚ñà‚ñå        | 3/20 [06:36<37:28, 132.27s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 3 | Eval Loss: 4.3057\n"]},{"name":"stderr","output_type":"stream","text":[]},{"name":"stdout","output_type":"stream","text":["[4,   100] loss: 3.769\n"]},{"name":"stderr","output_type":"stream","text":[]},{"name":"stdout","output_type":"stream","text":["[4,   200] loss: 3.757\n"]},{"name":"stderr","output_type":"stream","text":[]},{"name":"stdout","output_type":"stream","text":["[4,   300] loss: 3.793\n"]},{"name":"stderr","output_type":"stream","text":[]},{"name":"stdout","output_type":"stream","text":["Epoch 4 | Train Loss: 3.7720\n"]},{"name":"stderr","output_type":"stream","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:03<00:00,  9.05it/s]\n"," 20%|‚ñà‚ñà        | 4/20 [08:48<35:12, 132.04s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 4 | Eval Loss: 4.2379\n"]},{"name":"stderr","output_type":"stream","text":[]},{"name":"stdout","output_type":"stream","text":["[5,   100] loss: 3.525\n"]},{"name":"stderr","output_type":"stream","text":[]},{"name":"stdout","output_type":"stream","text":["[5,   200] loss: 3.542\n"]},{"name":"stderr","output_type":"stream","text":[]},{"name":"stdout","output_type":"stream","text":["[5,   300] loss: 3.468\n"]},{"name":"stderr","output_type":"stream","text":[]},{"name":"stdout","output_type":"stream","text":["Epoch 5 | Train Loss: 3.5119\n"]},{"name":"stderr","output_type":"stream","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:03<00:00, 10.02it/s]\n"," 25%|‚ñà‚ñà‚ñå       | 5/20 [11:00<33:03, 132.21s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 5 | Eval Loss: 4.1755\n"]},{"name":"stderr","output_type":"stream","text":[]},{"name":"stdout","output_type":"stream","text":["[6,   100] loss: 3.223\n"]},{"name":"stderr","output_type":"stream","text":[]},{"name":"stdout","output_type":"stream","text":["[6,   200] loss: 3.227\n"]},{"name":"stderr","output_type":"stream","text":[]},{"name":"stdout","output_type":"stream","text":["[6,   300] loss: 3.214\n"]},{"name":"stderr","output_type":"stream","text":[]},{"name":"stdout","output_type":"stream","text":["Epoch 6 | Train Loss: 3.2251\n"]},{"name":"stderr","output_type":"stream","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:03<00:00,  9.51it/s]\n"," 30%|‚ñà‚ñà‚ñà       | 6/20 [13:12<30:50, 132.15s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 6 | Eval Loss: 4.1455\n"]},{"name":"stderr","output_type":"stream","text":[]},{"name":"stdout","output_type":"stream","text":["[7,   100] loss: 2.921\n"]},{"name":"stderr","output_type":"stream","text":[]},{"name":"stdout","output_type":"stream","text":["[7,   200] loss: 2.913\n"]},{"name":"stderr","output_type":"stream","text":[]},{"name":"stdout","output_type":"stream","text":["[7,   300] loss: 2.949\n"]},{"name":"stderr","output_type":"stream","text":[]},{"name":"stdout","output_type":"stream","text":["Epoch 7 | Train Loss: 2.9274\n"]},{"name":"stderr","output_type":"stream","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:03<00:00,  9.42it/s]\n"," 35%|‚ñà‚ñà‚ñà‚ñå      | 7/20 [15:24<28:35, 131.96s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 7 | Eval Loss: 4.0701\n"]},{"name":"stderr","output_type":"stream","text":[]},{"name":"stdout","output_type":"stream","text":["[8,   100] loss: 2.597\n"]},{"name":"stderr","output_type":"stream","text":[]},{"name":"stdout","output_type":"stream","text":["[8,   200] loss: 2.640\n"]},{"name":"stderr","output_type":"stream","text":[]},{"name":"stdout","output_type":"stream","text":["[8,   300] loss: 2.666\n"]},{"name":"stderr","output_type":"stream","text":[]},{"name":"stdout","output_type":"stream","text":["Epoch 8 | Train Loss: 2.6367\n"]},{"name":"stderr","output_type":"stream","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:03<00:00,  8.78it/s]\n"," 40%|‚ñà‚ñà‚ñà‚ñà      | 8/20 [17:35<26:22, 131.85s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 8 | Eval Loss: 4.0461\n"]},{"name":"stderr","output_type":"stream","text":[]},{"name":"stdout","output_type":"stream","text":["[9,   100] loss: 2.319\n"]},{"name":"stderr","output_type":"stream","text":[]},{"name":"stdout","output_type":"stream","text":["[9,   200] loss: 2.361\n"]},{"name":"stderr","output_type":"stream","text":[]},{"name":"stdout","output_type":"stream","text":["[9,   300] loss: 2.412\n"]},{"name":"stderr","output_type":"stream","text":[]},{"name":"stdout","output_type":"stream","text":["Epoch 9 | Train Loss: 2.3615\n"]},{"name":"stderr","output_type":"stream","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:03<00:00,  9.19it/s]\n"," 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 9/20 [19:48<24:11, 131.97s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 9 | Eval Loss: 4.0144\n"]},{"name":"stderr","output_type":"stream","text":[]},{"name":"stdout","output_type":"stream","text":["[10,   100] loss: 2.034\n"]},{"name":"stderr","output_type":"stream","text":[]},{"name":"stdout","output_type":"stream","text":["[10,   200] loss: 2.127\n"]},{"name":"stderr","output_type":"stream","text":[]},{"name":"stdout","output_type":"stream","text":["[10,   300] loss: 2.165\n"]},{"name":"stderr","output_type":"stream","text":[]},{"name":"stdout","output_type":"stream","text":["Epoch 10 | Train Loss: 2.1095\n"]},{"name":"stderr","output_type":"stream","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:03<00:00,  9.45it/s]\n","                                               \r"]},{"name":"stdout","output_type":"stream","text":["Epoch 10 | Eval Loss: 4.0594\n","Early stopping...\n"]}],"source":["from modeling import seq2seq_train\n","\n","# ETS: ~30 mins to run with a batch size of 32 for 20 epochs\n","seq2seq_train(model=encoder_decoder,\n","              train_loader=scomp_train_dataloader,\n","              eval_loader=scomp_val_dataloader,\n","              optimizer=optimizer,\n","              criterion=criterion,\n","              device=device,\n","              tensorboard_path=\"./tensorboard/encoder_decoder\")\n","# save the model\n","torch.save(encoder_decoder.state_dict(), \"models/encoder_decoder.pt\")"]},{"cell_type":"markdown","metadata":{},"source":["Now we have the finetuned encoder-decoder model, we will use it to generate simplified text from the test set and compute a rouge score."]},{"cell_type":"code","execution_count":61,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:03<00:00,  9.81it/s]\n"]}],"source":["from modeling import seq2seq_generate\n","test_generations = seq2seq_generate(encoder_decoder, scomp_test_dataloader, custom_tokenizer, device=device)"]},{"cell_type":"markdown","metadata":{},"source":["Inspect the generations. Do they look like reasonable outputs?"]},{"cell_type":"code","execution_count":62,"metadata":{},"outputs":[{"data":{"text/plain":["[{'input': ['the',\n","   'euro',\n","   'has',\n","   'been',\n","   'dealt',\n","   'a',\n","   'downward',\n","   'as',\n","   'a',\n","   'result',\n","   'of',\n","   'an',\n","   'unexpectedly',\n","   'press',\n","   'conference',\n","   'from'],\n","  'reference': ['dealt', 'a', 'downward', 'correction'],\n","  'prediction': ['derivative']},\n"," {'input': ['and',\n","   'of',\n","   'the',\n","   'of',\n","   'informs',\n","   'that',\n","   'the',\n","   'volume',\n","   'of',\n","   'the',\n","   'international',\n","   'reserves',\n","   'of',\n","   'the',\n","   'amounted',\n","   'to',\n","   'billion',\n","   'as',\n","   'of'],\n","  'reference': ['reserves', 'of', 'the', 'amounted', 'to'],\n","  'prediction': ['to', 'from']},\n"," {'input': ['latest',\n","   'state',\n","   'figures',\n","   'released',\n","   'indicate',\n","   'unemployment',\n","   'continues',\n","   'to',\n","   'rise',\n","   'in',\n","   'the',\n","   'at',\n","   'the',\n","   'same',\n","   'time',\n","   'as',\n","   'there',\n","   'is',\n","   'modest',\n","   'job'],\n","  'reference': ['continues', 'to', 'rise', 'in'],\n","  'prediction': ['agrees', 'report', 'begin', 'in', 'to']},\n"," {'input': ['on',\n","   'announced',\n","   'a',\n","   'billion',\n","   'stimulus',\n","   'package',\n","   'to',\n","   'boost',\n","   'domestic',\n","   'demand',\n","   'and',\n","   'a',\n","   'slew',\n","   'of',\n","   'measures',\n","   'to',\n","   'ease',\n","   'credit',\n","   'crunch',\n","   'to',\n","   'offset',\n","   'the',\n","   'adverse',\n","   'impact',\n","   'on',\n","   'its',\n","   'economy',\n","   'from',\n","   'the',\n","   'global',\n","   'economic'],\n","  'reference': ['announces', 'billion', 'stimulus', 'package'],\n","  'prediction': ['to',\n","   'pricing',\n","   'billion',\n","   'downloads',\n","   'package',\n","   'to',\n","   'to']},\n"," {'input': ['mortgage',\n","   'rates',\n","   'have',\n","   'been',\n","   'low',\n","   'for',\n","   'the',\n","   'entire',\n","   'year',\n","   'and',\n","   'nothing',\n","   'has',\n","   'changed',\n","   'in',\n","   'the',\n","   'month',\n","   'of'],\n","  'reference': ['mortgage', 'rates', '--'],\n","  'prediction': ['mortgage', 'rates', 'for', 'to']}]"]},"execution_count":62,"metadata":{},"output_type":"execute_result"}],"source":["test_generations[:5]"]},{"cell_type":"markdown","metadata":{},"source":["Let's implement an evaluation function for ROUGE score.\n","\n","**ROUGE score** stands for Recall-Oriented Understudy for Gisting Evaluation. In its simplest form ROUGE score is the quotient of the matching words under the total count of words in reference sentence. Regarding the denominator ROUGE is a recall oriented metric. \n","\n","![rouge.png](docs/rouge.png)\n","\n","**ROUGE-L score** is based on the length of the longest common subsequence (LCS). To counter the disadvantages of a pure recall metric as in ROUGE-N, Rouge-L calculates the weighted harmonic mean (or f-measure) combining the precision score and the recall score.\n","\n","![rouge_l.png](docs/rouge_l.png)\n","\n","‚ÑπÔ∏è Source: [Original article](https://clementbm.github.io/theory/2021/12/23/rouge-bleu-scores.html#bleu)"]},{"cell_type":"markdown","metadata":{},"source":["<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #03befc;background-color:#eff7fe;border-radius: 15px;color:#424242;\">\n","\n","üéØ Goal:  **Go to `modeling.py` and implement the `evaluate_rouge` method.**\n","    \n","</div>"]},{"cell_type":"markdown","metadata":{},"source":["Calculate Rouge scores."]},{"cell_type":"code","execution_count":63,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading builder script: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6.27k/6.27k [00:00<00:00, 10.6MB/s]\n"]},{"name":"stdout","output_type":"stream","text":["{'rouge1': 0.21788946256104091, 'rouge2': 0.05595396360175767, 'rougeL': 0.2137954765103363, 'rougeLsum': 0.21370764613484425}\n"]}],"source":["from modeling import evaluate_rouge\n","\n","print(evaluate_rouge(test_generations))"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"22\"></a>\n","## üéØ Q3.2: **Finetune pretrained T5 model on text simplification task**.\n","\n","\n","<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #03befc;background-color:#eff7fe;border-radius: 15px;color:#424242;\">\n","\n","**In this section, we will take a pretrained [T5](https://arxiv.org/abs/1910.10683) model which is also an encoder-decoder model but based on the transformer architecture and finetune it on our task. You will need to do the following main steps:**\n","\n","- **Step 1**: Load T5 Model from Huggingface\n","\n","- **Step 2**: Implement Pytorch dataset for this model\n","\n","- **Step 3**: Run model finetuning\n","\n","- **Step 4**: Test and evaluate model performance\n","\n","\n","**TODOüîª: follow the instructions below**.\n","</div>"]},{"cell_type":"markdown","metadata":{},"source":["Initialize T5 model from Huggingface pretrained model."]},{"cell_type":"code","execution_count":64,"metadata":{},"outputs":[],"source":["from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n","\n","model_name = \"t5-small\"\n","t5_tokenizer = AutoTokenizer.from_pretrained(model_name)\n","# Make sure to put your model on the GPU\n","t5_model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)"]},{"cell_type":"markdown","metadata":{},"source":["Let's define a pytorch dataset for our T5 model."]},{"cell_type":"markdown","metadata":{},"source":["<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #03befc;background-color:#eff7fe;border-radius: 15px;color:#424242;\">\n","\n","üéØ Goal:  **Go to `modeling.py` and implement the `SCompT5Dataset` class.**\n","    \n","</div>"]},{"cell_type":"code","execution_count":65,"metadata":{},"outputs":[],"source":["from data import ScompT5Dataset\n","scomp_t5_train_dataset = ScompT5Dataset(scomp_train, t5_tokenizer)\n","scomp_t5_val_dataset = ScompT5Dataset(scomp_val, t5_tokenizer)\n","scomp_t5_test_dataset = ScompT5Dataset(scomp_test, t5_tokenizer)"]},{"cell_type":"markdown","metadata":{},"source":["Prepare finetuning arguments"]},{"cell_type":"code","execution_count":66,"metadata":{},"outputs":[],"source":["from transformers import TrainingArguments, Trainer\n","\n","# create the finetuning trainer\n","# TODO: set the hyperparameters to reasonable values\n","training_args = TrainingArguments(\n","    output_dir=f\"finetune_{model_name}-SCOMP\",\n","    evaluation_strategy=\"epoch\",\n","    per_device_train_batch_size=32,\n","    per_device_eval_batch_size=32,\n","    logging_steps=100,\n","    learning_rate=3e-4,\n","    num_train_epochs=3,\n","    save_strategy=\"no\",\n","    weight_decay=0.01,\n","    report_to=\"tensorboard\",\n","    logging_dir=\"./tensorboard/t5-scomp\")"]},{"cell_type":"markdown","metadata":{},"source":["#### Run the model finetuning"]},{"cell_type":"code","execution_count":67,"metadata":{},"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='939' max='939' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [939/939 03:27, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.097600</td>\n","      <td>0.083922</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.084000</td>\n","      <td>0.081840</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.077200</td>\n","      <td>0.080437</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["trainer = Trainer(\n","    model=t5_model,\n","    args=training_args,\n","    train_dataset=scomp_t5_train_dataset,\n","    eval_dataset=scomp_t5_val_dataset\n",")\n","\n","trainer.train()\n","trainer.save_model(f\"models/finetune_{model_name}_scomp\")"]},{"cell_type":"markdown","metadata":{},"source":["Now we will load our final finetuned model from the last checkpoint and evaluate it on the test set."]},{"cell_type":"code","execution_count":68,"metadata":{},"outputs":[],"source":["from transformers import T5ForConditionalGeneration\n","t5_model = T5ForConditionalGeneration.from_pretrained(f\"models/finetune_{model_name}_scomp\").to(device)"]},{"cell_type":"markdown","metadata":{},"source":["<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #03befc;background-color:#eff7fe;border-radius: 15px;color:#424242;\">\n","\n","üéØ Goal:  **Go to `modeling.py` and implement the `t5_generate` method.**\n","    \n","</div>"]},{"cell_type":"code","execution_count":75,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [01:29<00:00, 11.13it/s]\n"]}],"source":["from modeling import t5_generate\n","\n","test_t5_generations = t5_generate(scomp_t5_test_dataset, t5_model, t5_tokenizer, device=device)"]},{"cell_type":"markdown","metadata":{},"source":["Let's inspect the generations. Are they better than the ones generated by the encoder-decoder model? Provide some reasons why one model's generations are better than the other."]},{"cell_type":"code","execution_count":76,"metadata":{},"outputs":[{"data":{"text/plain":["[{'input': 'ICAP has sold a 12% stake in Traiana to seven of its leading customers, giving the business a valuation of $300m.',\n","  'reference': 'Icap sells 12% stake in Traiana',\n","  'prediction': 'ICAP sells 12% stake in Traiana to seven leading customers'},\n"," {'input': 'BRITISH soul singer Amy Winehouse has undergone more tests after being taken to hospital four days ago, but hopes to perform as scheduled next week, her office said on Thursday.',\n","  'reference': 'British singer Amy Winehouse undergoes more tests',\n","  'prediction': 'Amy Winehouse underwent more tests after being taken to hospital'},\n"," {'input': 'The new Scout.com 2012 rankings are out and loaded with Indiana players or those with ties to the state.',\n","  'reference': 'New Scout.com rankings loaded with Indiana players',\n","  'prediction': 'Scout.com 2012 rankings are out and loaded with Indiana players'},\n"," {'input': 'Arkansas held its first practice in full pads Saturday, but even then coaches saw the Razorbacks be a little tentative in making hits.',\n","  'reference': 'Arkansas holds first practice in full pads',\n","  'prediction': 'Arkansas holds first practice in full pads Saturday'},\n"," {'input': \"Michele Bachmann laced into President Barack Obama at a South Carolina tea party rally Saturday, saying his decision to take military action in Libya was foolish'' and that he's not on our side anymore.''\",\n","  'reference': \"Michele Bachmann says president Barack Obama is 'not on our side'\",\n","  'prediction': 'Michele Bachmann laces into President Obama at a tea party rally'}]"]},"execution_count":76,"metadata":{},"output_type":"execute_result"}],"source":["test_t5_generations[:5]"]},{"cell_type":"markdown","metadata":{},"source":["**Answer:**\n","The reason for the better performance of the T5 model can be the fact that it is a transformer-based model and it can handle long-range dependencies better than the LSTM-based encoder-decoder model (even we use attention mechanism to not forget first outputs as well). Also, the T5 model is pretrained on a large corpus and it can generalize better than the encoder-decoder model. The T5 model is also a more complex model than the encoder-decoder model and it can capture more complex patterns in the data."]},{"cell_type":"markdown","metadata":{},"source":["Finally, let's compute the ROUGE scores."]},{"cell_type":"code","execution_count":77,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["{'rouge1': 0.7981605814101909, 'rouge2': 0.7250050193321764, 'rougeL': 0.7571108444023207, 'rougeLsum': 0.7572399465880988}\n"]}],"source":["from modeling import evaluate_rouge\n","\n","print(evaluate_rouge(test_t5_generations))"]},{"cell_type":"markdown","metadata":{},"source":["<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #8e7cc3;background-color:#e4e1eb;border-radius: 15px;color:#424242;\">\n","\n","üéâ Excellent work! You just finished the code implementation parts of the assignment. \n","\n","#### Part 3 - Checklist\n","Here are the elements you will need for the report in Part 4:\n","\n","- [X] Finetuned encoder-decoder model and its rouge scores.\n","- [X] Finetuned T5 model and its rouge scores.\n","</div>"]},{"cell_type":"markdown","metadata":{},"source":["---\n","\n","<a id=\"4\"></a>\n","# PART 4: Write your report üìò\n","\n","Fill in the tables with the respective scores. "]},{"cell_type":"markdown","metadata":{},"source":["<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #03befc;background-color:#eff7fe;border-radius: 15px;text-align:center;color:#424242;\">\n","\n","#### Perplexity results on Language Models\n","\n","| Model - Variant | PPL |\n","|:--------- | :-----: |\n","| LSTM Variant A - Embeddings trained from scratch | 1.2643251471892072 |\n","| LSTM Variant B - Pre-trained embeddings & frozen | 1.6305144083032515 |\n","||||\n","| DistilGPT2 - Trained from scratch | 362.730 |\n","| Pre-trained DistilGPT2 | 100.631 |\n","    \n","#### Performance scores on Text Simplification\n","| Model - Variant | ROUGE-1 | ROUGE-2 | ROUGE-L | ROUGE-Lsum |\n","|:--------- | :-----: | :-----: |  :-----: |  :-----: | \n","| Finetuned Encoder-Decoder| 0.2179 |0.05596 |  0.2138 |0.2137 |\n","| Finetuned T5 | 0.7982 |0.7250 |  0.7571 |0.7572 |\n","</div>"]},{"cell_type":"markdown","metadata":{},"source":["### Questions related to the AI-based tools usage:"]},{"cell_type":"markdown","metadata":{},"source":["Q: The types of problems you chose to use tools on -- did you use them on every part of the assignment? Only for specific sections of code? What kind of code? \\\n","A: I havent intentionally used any AI-based tools in this assignment but github copilot was enabled till the announcement done about the usage of AI-based tools (so, it was open in Part-1 and Part-2 and in small part of Part-3). I also used in writing some comments in some parts of the code. Specifically, for one line codes that I is trivial to write, I used it to be faster."]},{"cell_type":"markdown","metadata":{},"source":["Q: How well did the tool(s) you employed do in those problems? Did you at any point refine how you were prompting them? Did you need to edit their outputs? How much did you need to change, on average? \\\n","A: It is giving correct response in trivial one line parts, but for the actual code parts, since it is deeply aware of the concept, it gives incorrect advices (it generally gives advice directly mostly based on most implementation found on internet without considering task-specific updates). So, for trivial one line codes, I mostly used advice (even without using copilot I would give the same answers) and for the multiple lines of codes part with task-specific updates, I used %10 percent at most and not relied on it."]},{"cell_type":"markdown","metadata":{},"source":["Q: Overall, where did you find the tool(s) succeeded with some degree of ease, and where did they struggle? \\\n","A: As I explained, in trivial one line codes, it is successful, but for the multiple lines of codes part with task-specific updates, it is not successful as it tend to give more generic answers."]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["YYTL0zJ1nIE_","m06WLo6qUvcm","jBU8CTeo1Uy4","ZOD9aSZIiTAC","6Mmm46nr6SZK","07Q5by1kiTAQ","HPDNtdxFUvcn","Smi1xBm3iTAV","Wsyfaq8yUg0j","BbpZkBndX259","3wBTcLdQUotA","ZyRP0QzGX8_4","ieaNrQIJzow-","Z29EEczseE9-","DdNMjJm4gK8W","zyg5BbR6jgoB"],"gpuType":"A100","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3.10.8 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"vscode":{"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}},"widgets":{"application/vnd.jupyter.widget-state+json":{"04d7f784399e421493ffbd8d02e007da":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_285a4d5837b2481f9a9c94902d501f31","max":192680,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c38330ee41c94fe08dc11c047fb57db8","value":192680}},"093cb168c2b24cfbb199171a0f60b96e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0fb98d2d737d4148a75386484c838fb8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"138871ee82ff47c3af673a08bd3ec4d0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"192d348aadd647b081f0f52a232fc953":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f9155aa243924a1c8135ca6d06a63d1b","placeholder":"‚Äã","style":"IPY_MODEL_68953a0dfe4345238ceb3c41e647dbc7","value":"Filter: 100%"}},"1da2811f157d44b9bf33518ddaaf7442":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1dbcea3369004cc8bcbb563845e8185b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c308ad3e35d64a428afa303d9bdd3fde","placeholder":"‚Äã","style":"IPY_MODEL_d191da7183e440838dc22930b47eb76e","value":" 192680/192680 [00:51&lt;00:00, 3754.06 examples/s]"}},"1dfcf13e5feb491aa0fd84f03851f326":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"285a4d5837b2481f9a9c94902d501f31":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a5278ebb1774d2b83a4dbeb47a2cd9b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"33a9fa0d8d604710bec9fc806a6917d2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_830aa101c887417a918712f2a5ee18ef","IPY_MODEL_3f3b978021f34c93941567c169f312b4","IPY_MODEL_1dbcea3369004cc8bcbb563845e8185b"],"layout":"IPY_MODEL_eb11abc069224b2f9e8ee35f403f9b88"}},"3bf734883fb64e8b97625db34c364f40":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3f3b978021f34c93941567c169f312b4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2a5278ebb1774d2b83a4dbeb47a2cd9b","max":192680,"min":0,"orientation":"horizontal","style":"IPY_MODEL_da19f2f9eaeb4724aae004722a1b1e3e","value":192680}},"5da3fb9adbaa4d99a44b2054506c8b12":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"61616b00cc534fa8b321a5dbad789e24":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6263c708fb1448de8587a657fcf2d38f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"68953a0dfe4345238ceb3c41e647dbc7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7095989fcb954bbbb0512bb5363f19c4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"70f25545be2d42ccad3d36fd1974f942":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7540eab42af64d088cbb5d3e92c994a5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ff2575473f3443c1b71d30f29b507cca","placeholder":"‚Äã","style":"IPY_MODEL_1da2811f157d44b9bf33518ddaaf7442","value":" 257472/257472 [03:29&lt;00:00, 1247.92 examples/s]"}},"8250f82beb194339b7a0272dc7da6bbe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_de7a729fa16544de9b9480e41f1a9d60","placeholder":"‚Äã","style":"IPY_MODEL_eb23d79b77ca4e5e920032339b4eabb8","value":"Map: 100%"}},"827526a107f745b0b686efe5da122833":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"830aa101c887417a918712f2a5ee18ef":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3bf734883fb64e8b97625db34c364f40","placeholder":"‚Äã","style":"IPY_MODEL_0fb98d2d737d4148a75386484c838fb8","value":"Map: 100%"}},"8b6fd1a431a14aea98b821f4aaf34a31":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"98297cde5bff45c594db633c7845e8a1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d87dc786c0c4b7a92140a6859c86e2f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8250f82beb194339b7a0272dc7da6bbe","IPY_MODEL_04d7f784399e421493ffbd8d02e007da","IPY_MODEL_f56202dca8854edfb0fdc69c131cad6b"],"layout":"IPY_MODEL_1dfcf13e5feb491aa0fd84f03851f326"}},"a1d3e6439dad4c57b8f94115a153fe25":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bb2190eebc7e428b96d4bede0f1f9d55":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_192d348aadd647b081f0f52a232fc953","IPY_MODEL_c88866f880d74e83a45d94c624f2a30e","IPY_MODEL_7540eab42af64d088cbb5d3e92c994a5"],"layout":"IPY_MODEL_d66f1974b6e34111b538985e810f3837"}},"c22beae6fb16496e9f3f25239341becf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8b6fd1a431a14aea98b821f4aaf34a31","placeholder":"‚Äã","style":"IPY_MODEL_70f25545be2d42ccad3d36fd1974f942","value":" 257472/257472 [01:51&lt;00:00, 2103.77 examples/s]"}},"c308ad3e35d64a428afa303d9bdd3fde":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c38330ee41c94fe08dc11c047fb57db8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c7c1bcb88c7a4f48ba5f818a4a697f5e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_093cb168c2b24cfbb199171a0f60b96e","placeholder":"‚Äã","style":"IPY_MODEL_6263c708fb1448de8587a657fcf2d38f","value":"Map: 100%"}},"c88866f880d74e83a45d94c624f2a30e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_61616b00cc534fa8b321a5dbad789e24","max":257472,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7095989fcb954bbbb0512bb5363f19c4","value":257472}},"d191da7183e440838dc22930b47eb76e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d66f1974b6e34111b538985e810f3837":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d9487cb740524a9989e94ce5d87e8c98":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c7c1bcb88c7a4f48ba5f818a4a697f5e","IPY_MODEL_fd072dd48e394637ae6b4068e4ad30de","IPY_MODEL_c22beae6fb16496e9f3f25239341becf"],"layout":"IPY_MODEL_138871ee82ff47c3af673a08bd3ec4d0"}},"da19f2f9eaeb4724aae004722a1b1e3e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"de7a729fa16544de9b9480e41f1a9d60":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb11abc069224b2f9e8ee35f403f9b88":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb23d79b77ca4e5e920032339b4eabb8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f56202dca8854edfb0fdc69c131cad6b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_98297cde5bff45c594db633c7845e8a1","placeholder":"‚Äã","style":"IPY_MODEL_a1d3e6439dad4c57b8f94115a153fe25","value":" 192680/192680 [03:11&lt;00:00, 1016.46 examples/s]"}},"f9155aa243924a1c8135ca6d06a63d1b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd072dd48e394637ae6b4068e4ad30de":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_827526a107f745b0b686efe5da122833","max":257472,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5da3fb9adbaa4d99a44b2054506c8b12","value":257472}},"ff2575473f3443c1b71d30f29b507cca":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}
