  0%|          | 0/20 [00:00<?, ?it/s]loss: 10.833251953125
loss: 10.658503532409668
loss: 10.528519630432129
loss: 10.396955490112305
loss: 10.190363883972168
loss: 9.965405464172363
loss: 9.908792495727539
loss: 9.547776222229004
loss: 9.419792175292969
loss: 9.19368839263916
loss: 8.82861042022705
loss: 8.327042579650879
loss: 7.916407108306885
loss: 7.574058532714844
loss: 6.730169296264648
loss: 6.064470291137695
loss: 6.528791904449463
loss: 6.431502819061279
loss: 5.811689376831055
loss: 6.4504780769348145
loss: 5.850615978240967
loss: 6.204909324645996
loss: 5.621681213378906
loss: 5.577636241912842
loss: 5.383096218109131
loss: 5.171995162963867
loss: 5.337218284606934
loss: 5.207001686096191
loss: 5.232482433319092
loss: 5.103745460510254
loss: 5.218851566314697
loss: 5.421114921569824
loss: 5.607654571533203
loss: 5.2740478515625
loss: 5.387986183166504
loss: 5.295517921447754
loss: 5.297937393188477
loss: 5.31120491027832
loss: 5.186347007751465
loss: 5.3328633308410645
loss: 5.504120349884033
loss: 5.362460613250732
loss: 5.075460910797119
loss: 5.086126327514648
loss: 4.98705530166626
loss: 5.148478031158447
loss: 5.232396602630615
loss: 5.410511016845703
loss: 4.674076557159424
loss: 5.483157157897949
loss: 5.497057914733887
loss: 5.011178493499756
loss: 4.960126876831055
loss: 4.552461624145508
loss: 4.811930179595947
loss: 5.142630577087402
loss: 5.126102924346924
loss: 4.694896697998047
loss: 4.713009834289551
loss: 5.240365982055664
loss: 4.92946195602417
loss: 4.730662822723389
loss: 4.5922346115112305
loss: 5.0604095458984375
loss: 4.840499401092529
loss: 5.019038677215576
loss: 5.181414604187012
loss: 5.346714496612549
loss: 4.962052345275879
loss: 4.7642364501953125
loss: 5.258916854858398
loss: 5.21807861328125
loss: 4.905547142028809
loss: 5.069005966186523
loss: 4.626753330230713
loss: 4.931873798370361
loss: 4.302405834197998
loss: 4.488332748413086
loss: 4.550350666046143
loss: 4.490736484527588
loss: 5.082625865936279
loss: 4.572554588317871
loss: 5.294369220733643
loss: 4.996971130371094
loss: 5.177213191986084
loss: 4.122810363769531
loss: 4.305229187011719
loss: 4.879916667938232
loss: 4.6595611572265625
loss: 4.968460559844971
loss: 4.200662612915039
loss: 4.896526336669922
loss: 4.721085548400879
loss: 4.875365734100342
loss: 5.130237102508545
loss: 4.562178134918213
loss: 4.872086048126221
loss: 4.72797966003418
loss: 4.772305965423584
loss: 4.605850696563721
[1,   100] loss: 5.737
loss: 4.390043258666992
loss: 4.8188300132751465
loss: 4.894684791564941
loss: 4.765501022338867
loss: 4.863522052764893
loss: 4.786339282989502
loss: 4.798588275909424
loss: 4.36701774597168
loss: 5.05329704284668
loss: 5.3320841789245605
loss: 4.835586071014404
loss: 4.561392784118652
loss: 5.12916898727417
loss: 4.680996894836426
loss: 4.688619136810303
loss: 4.552791118621826
loss: 4.653946399688721
loss: 4.58963680267334
loss: 4.812560558319092
loss: 4.467169761657715
loss: 4.897483825683594
loss: 5.030139923095703
loss: 5.311006546020508
loss: 4.567229270935059
loss: 4.46934175491333
loss: 4.891762733459473
loss: 4.268640995025635
loss: 4.5403594970703125
loss: 4.612152576446533
loss: 5.088947772979736
loss: 4.8518476486206055
loss: 4.837724208831787
loss: 4.87708044052124
loss: 4.504746913909912
loss: 4.797614574432373
loss: 4.600991725921631
loss: 4.576951026916504
loss: 5.295611381530762
loss: 4.7836432456970215
loss: 4.893505096435547
loss: 5.042713165283203
loss: 4.646191596984863
loss: 4.531669616699219
loss: 4.56704044342041
loss: 4.715713024139404
loss: 4.6477251052856445
loss: 4.6546807289123535
loss: 4.3667802810668945
loss: 4.646225452423096
loss: 4.071915149688721
loss: 4.449380874633789
loss: 4.533146858215332
loss: 4.81932258605957
loss: 4.678061485290527
loss: 4.744546890258789
loss: 4.2044878005981445
loss: 4.91049337387085
loss: 4.875677585601807
loss: 4.4902801513671875
loss: 4.563015937805176
loss: 4.89451265335083
loss: 4.860836029052734
loss: 4.30811071395874
loss: 4.505794525146484
loss: 4.530046463012695
loss: 4.5296406745910645
loss: 4.790024280548096
loss: 4.891845703125
loss: 4.061526775360107
loss: 4.363203048706055
loss: 4.54033899307251
loss: 4.634326934814453
loss: 4.979358196258545
loss: 4.758371829986572
loss: 5.047279357910156
loss: 5.049234867095947
loss: 4.427762508392334
loss: 4.870835781097412
loss: 5.060379981994629
loss: 4.486856460571289
loss: 4.539865970611572
loss: 4.533740520477295
loss: 4.585695266723633
loss: 4.481232643127441
loss: 4.349852085113525
loss: 4.927708148956299
loss: 4.4149322509765625
loss: 4.944331169128418
loss: 4.6881327629089355
loss: 4.6838860511779785
loss: 4.245142936706543
loss: 4.477813720703125
loss: 4.6103715896606445
loss: 4.774722099304199
loss: 4.608152866363525
loss: 4.463687419891357
loss: 4.468216419219971
loss: 4.472905158996582
loss: 5.18912935256958
loss: 3.8768866062164307
[1,   200] loss: 4.678
loss: 4.71279239654541
loss: 5.06422758102417
loss: 4.687941074371338
loss: 5.117371082305908
loss: 4.7822113037109375
loss: 4.2406439781188965
loss: 4.562870025634766
loss: 4.4378981590271
loss: 4.558007717132568
loss: 4.431731224060059
loss: 4.716780185699463
loss: 4.900364398956299
loss: 4.624393939971924
loss: 4.917525768280029
loss: 5.23858118057251
loss: 4.687200546264648
loss: 4.422516345977783
loss: 4.03177547454834
loss: 5.273130893707275
loss: 4.6123809814453125
loss: 4.506063461303711
loss: 4.672787666320801
loss: 4.8350982666015625
loss: 4.596503257751465
loss: 5.035397529602051
loss: 4.48768424987793
loss: 4.457265377044678
loss: 4.654912948608398
loss: 4.53805685043335
loss: 4.501397609710693
loss: 4.603030204772949
loss: 4.427660942077637
loss: 4.730165481567383
loss: 4.58475399017334
loss: 4.483090877532959
loss: 4.582435131072998
loss: 4.0301713943481445
loss: 4.658497333526611
loss: 4.704622268676758
loss: 5.032632827758789
loss: 5.034179210662842
loss: 4.817582130432129
loss: 4.395737171173096
loss: 4.232654094696045
loss: 4.656450271606445
loss: 5.058448314666748
loss: 4.266692638397217
loss: 4.476430892944336
loss: 5.011826992034912
loss: 4.256911277770996
loss: 4.6655120849609375
loss: 4.754462242126465
loss: 4.345458984375
loss: 4.637289524078369
loss: 4.491077899932861
loss: 4.798738956451416
loss: 4.475148677825928
loss: 4.577216148376465
loss: 4.869511127471924
loss: 4.783250331878662
loss: 4.18575382232666
loss: 4.296775817871094
loss: 4.153623580932617
loss: 4.8314642906188965
loss: 4.599878787994385
loss: 4.888948440551758
loss: 4.2053399085998535
loss: 4.827050685882568
loss: 4.908380508422852
loss: 4.624691486358643
loss: 4.727954387664795
loss: 4.3450822830200195
loss: 4.334530353546143
loss: 4.7242608070373535
loss: 4.865140914916992
loss: 4.111247539520264
loss: 4.589240074157715
loss: 4.451457500457764
loss: 4.698249340057373
loss: 4.433312892913818
loss: 4.454304218292236
loss: 4.7443647384643555
loss: 3.9954981803894043
loss: 4.516414642333984
loss: 4.520622730255127
loss: 4.579201698303223
loss: 4.403054237365723
loss: 4.7774200439453125
loss: 4.68641996383667
loss: 4.560783863067627
loss: 4.533191680908203
loss: 4.463730335235596
loss: 4.734210968017578
loss: 4.508944511413574
loss: 4.690310955047607
loss: 4.46330451965332
loss: 4.112875938415527
loss: 4.646080017089844
loss: 4.83948278427124
loss: 4.890540599822998
[1,   300] loss: 4.607
loss: 4.853511810302734
loss: 4.860781192779541
loss: 4.388852119445801
loss: 4.571352481842041
loss: 4.721827983856201
loss: 4.259497165679932
loss: 4.655679702758789
loss: 4.5480241775512695
loss: 4.088205337524414
loss: 4.112209796905518
loss: 4.308773517608643
loss: 4.271544456481934
loss: 4.856893539428711
Epoch 1 | Train Loss: 4.9864
100%|██████████| 32/32 [00:19<00:00,  1.62it/s]
  5%|▌         | 1/20 [10:35<3:21:15, 635.53s/it]Epoch 1 | Eval Loss: 4.5303
loss: 4.2214460372924805
loss: 4.030948162078857
loss: 4.2960734367370605
loss: 3.949509859085083
loss: 4.612051486968994
loss: 4.291109085083008
loss: 4.166414737701416
loss: 4.26228141784668
loss: 4.159858226776123
loss: 4.27561092376709
loss: 4.428623676300049
loss: 4.603748321533203
loss: 4.319990634918213
loss: 4.17707633972168
loss: 4.7438812255859375
loss: 4.184711933135986
loss: 4.086985111236572
loss: 4.490148067474365
loss: 4.350531101226807
loss: 4.666723251342773
loss: 4.213839530944824
loss: 4.15625
loss: 4.243488788604736
loss: 4.79944372177124
loss: 4.361276149749756
loss: 4.460738658905029
loss: 4.012537002563477
loss: 4.187374114990234
loss: 4.464632511138916
loss: 4.408476829528809
loss: 4.15720272064209
loss: 4.091133117675781
loss: 3.7816615104675293
loss: 4.448615074157715
loss: 4.045424938201904
loss: 4.085070610046387
loss: 4.107285022735596
loss: 4.295655727386475
loss: 4.149046421051025
loss: 4.620486736297607
loss: 4.240651607513428
loss: 4.194142818450928
loss: 3.872605800628662
loss: 4.283497333526611
loss: 3.951521873474121
loss: 3.9874234199523926
loss: 4.123607158660889
loss: 4.385828971862793
loss: 4.313298225402832
loss: 4.595716953277588
loss: 4.156154632568359
loss: 4.635704517364502
loss: 3.9881434440612793
loss: 4.375332355499268
loss: 4.304128646850586
loss: 4.559628486633301
loss: 4.302971363067627
loss: 4.246311664581299
loss: 4.603442668914795
loss: 4.174770832061768
loss: 4.390323638916016
loss: 4.225135326385498
loss: 3.9157941341400146
loss: 4.322847843170166
loss: 4.2722883224487305
loss: 4.183799743652344
loss: 4.357208251953125
loss: 4.184665203094482
loss: 4.094142436981201
loss: 4.785772800445557
loss: 4.611956596374512
loss: 4.236018180847168
loss: 4.5905609130859375
loss: 4.067160129547119
loss: 4.445852756500244
loss: 4.564483165740967
loss: 4.6050214767456055
loss: 4.3035888671875
loss: 4.51170539855957
loss: 4.66079044342041
loss: 3.7617411613464355
loss: 4.457502841949463
loss: 4.390854358673096
loss: 3.469862937927246
loss: 4.6254353523254395
loss: 4.095704078674316
loss: 3.830732822418213
loss: 4.262260437011719
loss: 4.363509178161621
loss: 4.156106472015381
loss: 4.35886287689209
loss: 4.17932653427124
loss: 3.934406280517578
loss: 4.522555351257324
loss: 4.642678737640381
loss: 4.640918254852295
loss: 4.157958984375
loss: 4.245287895202637
loss: 4.671073913574219
loss: 3.9702389240264893
[2,   100] loss: 4.288
loss: 4.156620025634766
loss: 3.7575197219848633
loss: 4.517814636230469
loss: 4.066371917724609
loss: 3.9559590816497803
loss: 4.17507266998291
loss: 4.342856407165527
loss: 4.394707679748535
loss: 4.452223300933838
loss: 4.2703857421875
loss: 4.336146831512451
loss: 4.680581092834473
loss: 4.035256862640381
loss: 4.08514928817749
loss: 3.9788553714752197
loss: 4.073992729187012
loss: 3.9482569694519043
loss: 4.470524787902832
loss: 4.497175216674805
loss: 3.9420883655548096
loss: 4.208333492279053
loss: 4.146144866943359
loss: 4.47036600112915
loss: 4.290060043334961
loss: 4.316122531890869
loss: 4.299907207489014
loss: 4.223995685577393
loss: 4.141153335571289
loss: 4.21921443939209
loss: 3.701119899749756
loss: 4.662283897399902
loss: 4.12770938873291
loss: 4.215647220611572
loss: 4.088315963745117
loss: 4.4508161544799805
loss: 4.207170486450195
loss: 3.975627899169922
loss: 4.439486503601074
loss: 4.418090343475342
loss: 4.004211902618408
loss: 4.412188529968262
loss: 4.432711601257324
loss: 4.372139930725098
loss: 4.222711086273193
loss: 4.445866584777832
loss: 4.344084739685059
loss: 3.8285109996795654
loss: 4.389890193939209
loss: 4.553413391113281
loss: 4.135315418243408
loss: 4.436707973480225
loss: 4.541456699371338
loss: 4.228011608123779
loss: 4.244104385375977
loss: 4.388286113739014
loss: 4.544546127319336
loss: 4.194098472595215
loss: 4.051281929016113
loss: 4.06527853012085
loss: 4.408566951751709
loss: 4.2654852867126465
loss: 4.554788589477539
loss: 3.7347214221954346
loss: 4.420791149139404
loss: 3.7299749851226807
loss: 4.3208184242248535
loss: 3.8494319915771484
loss: 4.259859085083008
loss: 4.394130706787109
loss: 4.05975341796875
loss: 4.0084686279296875
loss: 3.955662250518799
loss: 4.304421901702881
loss: 3.9702248573303223
loss: 4.078207492828369
loss: 4.139718532562256
loss: 4.067358016967773
loss: 4.231998443603516
loss: 4.120195388793945
loss: 3.980274200439453
loss: 3.9152896404266357
loss: 3.9151651859283447
loss: 4.323980808258057
loss: 4.222978115081787
loss: 4.117462158203125
loss: 4.103518009185791
loss: 3.9234604835510254
loss: 3.9031403064727783
loss: 4.114891529083252
loss: 4.358078479766846
loss: 4.302918910980225
loss: 3.9036943912506104
loss: 4.3556718826293945
loss: 3.7643373012542725
loss: 4.304609298706055
loss: 4.1138916015625
loss: 4.1200737953186035
loss: 4.376875400543213
loss: 4.163511276245117
loss: 4.244082450866699
[2,   200] loss: 4.200
loss: 4.3767008781433105
loss: 3.849155902862549
loss: 3.6794116497039795
loss: 4.352912902832031
loss: 3.9935922622680664
loss: 4.009300231933594
loss: 4.475395679473877
loss: 4.10553503036499
loss: 4.572902679443359
loss: 4.218564510345459
loss: 4.215738773345947
loss: 4.058162689208984
loss: 4.075777053833008
loss: 4.03749942779541
loss: 4.046635150909424
loss: 4.396603584289551
loss: 4.0026679039001465
loss: 4.101646423339844
loss: 4.109307289123535
loss: 4.385490894317627
loss: 4.174347877502441
loss: 4.497344970703125
loss: 4.445937156677246
loss: 3.8696045875549316
loss: 4.114099979400635
loss: 4.007770538330078
loss: 4.1390156745910645
loss: 4.629721164703369
loss: 4.026526927947998
loss: 4.083519458770752
loss: 4.352149486541748
loss: 4.29084587097168
loss: 4.263445854187012
loss: 3.9719274044036865
loss: 3.8340749740600586
loss: 4.199847221374512
loss: 4.330265045166016
loss: 3.949083089828491
loss: 3.8423349857330322
loss: 4.289519309997559
loss: 4.352273464202881
loss: 4.2273030281066895
loss: 4.188293933868408
loss: 4.188875675201416
loss: 4.4901838302612305
loss: 3.852489471435547
loss: 4.181114673614502
loss: 4.105475425720215
loss: 3.673748016357422
loss: 4.310674667358398
loss: 4.215376377105713
loss: 4.542308807373047
loss: 4.882816791534424
loss: 4.613173484802246
loss: 4.281195163726807
loss: 4.116659164428711
loss: 4.354842662811279
loss: 4.077335357666016
loss: 4.314833164215088
loss: 4.1551313400268555
loss: 4.378480911254883
loss: 4.340350151062012
loss: 4.209191799163818
loss: 3.9138123989105225
loss: 4.237153053283691
loss: 3.990370512008667
loss: 4.129949569702148
loss: 4.065177917480469
loss: 4.254980087280273
loss: 4.072503089904785
loss: 4.283890247344971
loss: 4.331185817718506
loss: 4.400722503662109
loss: 4.270928382873535
loss: 4.001408100128174
loss: 4.322702407836914
loss: 4.241225719451904
loss: 4.519711971282959
loss: 4.239427089691162
loss: 4.377420425415039
loss: 4.151646137237549
loss: 3.958223342895508
loss: 4.286122798919678
loss: 4.321043014526367
loss: 4.010936737060547
loss: 4.320927619934082
loss: 3.998720407485962
loss: 4.005377769470215
loss: 4.280728816986084
loss: 3.9776840209960938
loss: 4.109634876251221
loss: 3.8503236770629883
loss: 4.115841865539551
loss: 4.230828762054443
loss: 4.115506649017334
loss: 4.486515998840332
loss: 4.21200704574585
loss: 4.375267028808594
loss: 4.377803802490234
loss: 3.950242042541504
[2,   300] loss: 4.192
loss: 4.30600643157959
loss: 4.040544509887695
loss: 4.255952835083008
loss: 4.43888521194458
loss: 3.8915765285491943
loss: 3.9322996139526367
loss: 4.070810317993164
loss: 4.240426540374756
loss: 3.893982410430908
loss: 4.050560474395752
loss: 4.545818328857422
loss: 4.115344524383545
loss: 3.984927177429199
Epoch 2 | Train Loss: 4.2228
100%|██████████| 32/32 [00:19<00:00,  1.63it/s]
 10%|█         | 2/20 [21:25<3:13:11, 643.99s/it]Epoch 2 | Eval Loss: 4.3307
loss: 4.460230827331543
loss: 4.401653289794922
loss: 3.919299602508545
loss: 3.8129348754882812
loss: 3.6217422485351562
loss: 4.054423809051514
loss: 3.972080945968628
loss: 4.077040195465088
loss: 3.682654857635498
loss: 4.284801959991455
loss: 3.904445171356201
loss: 4.155364990234375
loss: 4.17128324508667
loss: 4.287618637084961
loss: 4.012216567993164
loss: 3.772846221923828
loss: 4.013673782348633
loss: 4.286825180053711
loss: 4.061931610107422
loss: 4.021647930145264
loss: 3.9686577320098877
loss: 4.139309883117676
loss: 3.9412057399749756
loss: 4.186363697052002
loss: 4.209707736968994
loss: 3.839704990386963
loss: 4.126397609710693
loss: 4.111082077026367
loss: 4.221688747406006
loss: 3.9775326251983643
loss: 4.08254337310791
loss: 4.029937267303467
loss: 3.5502889156341553
loss: 3.8242616653442383
loss: 4.1157708168029785
loss: 3.6767208576202393
loss: 4.443819999694824
loss: 3.935896873474121
loss: 3.8963229656219482
loss: 3.743164300918579
loss: 4.158204078674316
loss: 3.677572250366211
loss: 4.216320037841797
loss: 4.162316799163818
loss: 4.192338466644287
loss: 3.980363607406616
loss: 4.0166730880737305
loss: 4.111506462097168
loss: 3.896998882293701
loss: 3.6218647956848145
loss: 3.6529769897460938
loss: 4.146491050720215
loss: 4.115943431854248
loss: 4.085714817047119
loss: 3.5844898223876953
loss: 4.099541664123535
loss: 4.261934757232666
loss: 3.788252115249634
loss: 3.9709112644195557
loss: 4.15928316116333
loss: 4.282277584075928
loss: 4.074794769287109
loss: 3.742565393447876
loss: 3.952559232711792
loss: 3.95888352394104
loss: 3.63375186920166
loss: 4.287209510803223
loss: 3.8504297733306885
loss: 4.214649677276611
loss: 3.9584569931030273
loss: 3.7012507915496826
loss: 4.141716957092285
loss: 3.739159107208252
loss: 3.9504623413085938
loss: 3.867734670639038
loss: 3.7203030586242676
loss: 3.9570138454437256
loss: 3.7650113105773926
loss: 3.8692238330841064
loss: 4.072329521179199
loss: 3.6579432487487793
loss: 3.489537000656128
loss: 4.047426223754883
loss: 4.295312881469727
loss: 3.952226400375366
loss: 3.8538458347320557
loss: 3.818253517150879
loss: 3.907613754272461
loss: 4.134283065795898
loss: 3.852869749069214
loss: 3.88063383102417
loss: 3.793933153152466
loss: 3.691030740737915
loss: 4.096332550048828
loss: 3.6558992862701416
loss: 3.938020944595337
loss: 3.7397451400756836
loss: 3.57639479637146
loss: 3.8248038291931152
loss: 4.071883678436279
[3,   100] loss: 3.969
loss: 3.9273736476898193
loss: 3.9915928840637207
loss: 4.025557518005371
loss: 3.8999130725860596
loss: 4.146411418914795
loss: 4.365889072418213
loss: 4.1887383460998535
loss: 3.843198299407959
loss: 3.984628677368164
loss: 3.6618688106536865
loss: 3.688692808151245
loss: 3.940013885498047
loss: 4.246038436889648
loss: 4.258621692657471
loss: 4.027507305145264
loss: 3.885760545730591
loss: 3.6397478580474854
loss: 4.027072906494141
loss: 3.7587592601776123
loss: 4.232044696807861
loss: 3.8239715099334717
loss: 4.186374664306641
loss: 4.254048824310303
loss: 3.593477249145508
loss: 3.8714654445648193
loss: 4.064899921417236
loss: 3.7840511798858643
loss: 3.9281485080718994
loss: 4.189889430999756
loss: 3.8726937770843506
loss: 4.181224822998047
loss: 4.266689777374268
loss: 3.4901773929595947
loss: 3.9412925243377686
loss: 3.639289617538452
loss: 3.5095059871673584
loss: 3.922574758529663
loss: 4.201598167419434
loss: 3.969696283340454
loss: 3.5701892375946045
loss: 3.901411294937134
loss: 4.067283630371094
loss: 3.652038812637329
loss: 3.563857316970825
loss: 4.378500938415527
loss: 3.8377504348754883
loss: 3.9492387771606445
loss: 3.665724992752075
loss: 3.521939992904663
loss: 3.8869643211364746
loss: 3.705599069595337
loss: 3.3817734718322754
loss: 3.872997522354126
loss: 4.082001209259033
loss: 4.216985702514648
loss: 3.9781320095062256
loss: 3.6446924209594727
loss: 3.7224233150482178
loss: 3.815707206726074
loss: 4.067836761474609
loss: 4.076037406921387
loss: 3.8137009143829346
loss: 3.876155376434326
loss: 3.6701667308807373
loss: 4.646717071533203
loss: 4.006278991699219
loss: 3.7593679428100586
loss: 3.673407793045044
loss: 3.6702399253845215
loss: 3.4112343788146973
loss: 3.1594929695129395
loss: 4.13970422744751
loss: 4.40084981918335
loss: 4.225406646728516
loss: 4.133198261260986
loss: 3.93495512008667
loss: 4.084399700164795
loss: 4.037484645843506
loss: 3.8743910789489746
loss: 3.7507264614105225
loss: 3.668020248413086
loss: 3.867342948913574
loss: 4.157161235809326
loss: 4.230569362640381
loss: 4.0073957443237305
loss: 3.5487465858459473
loss: 4.05126953125
loss: 3.9593887329101562
loss: 3.932985305786133
loss: 4.233480930328369
loss: 3.8107383251190186
loss: 3.796736240386963
loss: 3.687713384628296
loss: 4.159332275390625
loss: 3.7052860260009766
loss: 3.7115120887756348
loss: 3.438810110092163
loss: 4.101962566375732
loss: 3.671328067779541
loss: 3.4120914936065674
[3,   200] loss: 3.904
loss: 3.522646427154541
loss: 4.451781272888184
loss: 3.943354368209839
loss: 3.7907652854919434
loss: 4.031641006469727
loss: 3.7297701835632324
loss: 4.041020393371582
loss: 3.444722890853882
loss: 4.053529262542725
loss: 3.6119370460510254
loss: 3.7592196464538574
loss: 3.7582359313964844
loss: 3.7064294815063477
loss: 3.625107765197754
loss: 3.551887273788452
loss: 4.247297763824463
loss: 3.602759599685669
loss: 4.118500709533691
loss: 4.061715126037598
loss: 3.6394834518432617
loss: 3.914398431777954
loss: 3.8483893871307373
loss: 4.01287841796875
loss: 3.9801456928253174
loss: 4.406570911407471
loss: 3.883864402770996
loss: 4.218394756317139
loss: 4.041982650756836
loss: 3.565595865249634
loss: 3.947638511657715
loss: 4.019416332244873
loss: 3.818974018096924
loss: 3.701389789581299
loss: 3.60583758354187
loss: 4.013679504394531
loss: 4.1015496253967285
loss: 4.153405666351318
loss: 3.694145917892456
loss: 3.849210739135742
loss: 3.6265268325805664
loss: 3.733314275741577
loss: 3.5026378631591797
loss: 4.002708435058594
loss: 4.068267345428467
loss: 4.001811981201172
loss: 3.446214199066162
loss: 3.8313918113708496
loss: 3.3939568996429443
loss: 4.088181018829346
loss: 4.026379108428955
loss: 3.977480173110962
loss: 3.598374128341675
loss: 4.094284534454346
loss: 4.134598731994629
loss: 3.662158966064453
loss: 4.141055583953857
loss: 4.133945465087891
loss: 4.11298942565918
loss: 3.968959331512451
loss: 3.9730441570281982
loss: 3.7241923809051514
loss: 3.5187950134277344
loss: 3.4162096977233887
loss: 3.9972431659698486
loss: 4.0503082275390625
loss: 3.951521396636963
loss: 3.939141273498535
loss: 4.000791549682617
loss: 3.2461278438568115
loss: 4.1422247886657715
loss: 3.8104138374328613
loss: 4.1225666999816895
loss: 4.016602993011475
loss: 4.143869876861572
loss: 3.8058791160583496
loss: 3.915379047393799
loss: 3.9971723556518555
loss: 3.876241445541382
loss: 3.91970157623291
loss: 3.5062010288238525
loss: 3.9946742057800293
loss: 3.8787851333618164
loss: 4.065404415130615
loss: 4.000787734985352
loss: 3.437159299850464
loss: 3.640456438064575
loss: 3.8739993572235107
loss: 3.6094465255737305
loss: 3.7207884788513184
loss: 4.368279933929443
loss: 3.5543723106384277
loss: 3.575977087020874
loss: 4.077042579650879
loss: 3.3573110103607178
loss: 3.9832663536071777
loss: 3.9981563091278076
loss: 3.9470362663269043
loss: 3.9197654724121094
loss: 3.784473419189453
loss: 3.9087557792663574
[3,   300] loss: 3.868
loss: 3.834014654159546
loss: 3.7460198402404785
loss: 3.7048392295837402
loss: 3.2875778675079346
loss: 4.012084007263184
loss: 3.596904754638672
loss: 3.707760810852051
loss: 4.011091232299805
loss: 3.2367208003997803
loss: 3.521843910217285
loss: 3.806572914123535
loss: 3.656954288482666
loss: 3.9427590370178223
Epoch 3 | Train Loss: 3.9047
100%|██████████| 32/32 [00:19<00:00,  1.64it/s]
 15%|█▌        | 3/20 [32:20<3:03:56, 649.24s/it]Epoch 3 | Eval Loss: 4.1752
loss: 3.5670289993286133
loss: 3.3726680278778076
loss: 3.648782968521118
loss: 3.7110235691070557
loss: 3.524747610092163
loss: 3.644073486328125
loss: 3.489229202270508
loss: 3.7835116386413574
loss: 3.122450590133667
loss: 3.6761724948883057
loss: 3.7110190391540527
loss: 3.4314403533935547
loss: 3.923130512237549
loss: 3.476893901824951
loss: 3.8439700603485107
loss: 3.3935744762420654
loss: 3.6738991737365723
loss: 3.661799430847168
loss: 3.751322031021118
loss: 3.530569076538086
loss: 3.544116735458374
loss: 3.543738603591919
loss: 3.4911465644836426
loss: 3.447333812713623
loss: 3.500580310821533
loss: 3.7651562690734863
loss: 3.7771263122558594
loss: 3.339318037033081
loss: 3.528029680252075
loss: 3.7328734397888184
loss: 3.801292657852173
loss: 3.7341980934143066
loss: 3.5989155769348145
loss: 4.064547061920166
loss: 3.439049005508423
loss: 3.4929323196411133
loss: 3.585550546646118
loss: 3.620720624923706
loss: 3.292147397994995
loss: 3.478332757949829
loss: 3.8713314533233643
loss: 3.6116228103637695
loss: 3.509646415710449
loss: 3.5606725215911865
loss: 3.6376700401306152
loss: 3.4203391075134277
loss: 3.320669412612915
loss: 3.793877601623535
loss: 3.270780324935913
loss: 3.6722753047943115
loss: 3.315134286880493
loss: 3.5081491470336914
loss: 3.3823108673095703
loss: 3.5589895248413086
loss: 3.67244029045105
loss: 3.742231845855713
loss: 3.679659366607666
loss: 3.8366870880126953
loss: 3.593879461288452
loss: 3.89851975440979
loss: 3.8802199363708496
loss: 3.4456379413604736
loss: 3.579596519470215
loss: 3.418264627456665
loss: 3.300096273422241
loss: 3.6175663471221924
loss: 4.159494400024414
loss: 3.21397066116333
loss: 3.034029006958008
loss: 3.5038766860961914
loss: 3.6551403999328613
loss: 3.251255750656128
loss: 3.846792221069336
loss: 3.5771703720092773
loss: 3.5537497997283936
loss: 3.755861520767212
loss: 3.6222357749938965
loss: 3.7751030921936035
loss: 3.6452274322509766
loss: 3.67631459236145
loss: 3.7757959365844727
loss: 3.451280355453491
loss: 3.8248043060302734
loss: 3.5128142833709717
loss: 3.3688693046569824
loss: 3.9865872859954834
loss: 3.2285776138305664
loss: 3.6811845302581787
loss: 3.6453757286071777
loss: 3.7733640670776367
loss: 3.686969041824341
loss: 3.319580316543579
loss: 3.2694692611694336
loss: 3.532909393310547
loss: 3.729261875152588
loss: 3.4984376430511475
loss: 3.926189661026001
loss: 3.8233256340026855
loss: 3.2652032375335693
loss: 3.680222511291504
[4,   100] loss: 3.591
loss: 3.5220255851745605
loss: 3.7982208728790283
loss: 3.389744997024536
loss: 3.6750426292419434
loss: 3.444850444793701
loss: 3.498668670654297
loss: 3.632920742034912
loss: 3.1402461528778076
loss: 3.6021740436553955
loss: 3.5811548233032227
loss: 3.412485361099243
loss: 3.8198344707489014
loss: 3.5932605266571045
loss: 3.6740520000457764
loss: 3.4841785430908203
loss: 3.61472225189209
loss: 3.4440314769744873
loss: 3.8661651611328125
loss: 3.609637498855591
loss: 4.024317264556885
loss: 3.377889394760132
loss: 3.7019612789154053
loss: 3.539199113845825
loss: 3.7906200885772705
loss: 3.720590829849243
loss: 3.5238494873046875
loss: 3.5546875
loss: 3.820028066635132
loss: 3.6195590496063232
loss: 3.771545648574829
loss: 3.3766565322875977
loss: 3.6328091621398926
loss: 3.2975351810455322
loss: 3.92848801612854
loss: 3.2848567962646484
loss: 3.7493178844451904
loss: 3.4314024448394775
loss: 3.461932420730591
loss: 3.698101282119751
loss: 4.0549235343933105
loss: 3.640451669692993
loss: 3.632607936859131
loss: 3.567258596420288
loss: 3.7144765853881836
loss: 3.5414540767669678
loss: 3.410579204559326
loss: 3.4518613815307617
loss: 3.478799819946289
loss: 3.7394235134124756
loss: 3.5589325428009033
loss: 3.1975386142730713
loss: 3.386195421218872
loss: 3.8107495307922363
loss: 3.874100923538208
loss: 3.5760321617126465
loss: 3.6255481243133545
loss: 3.593290328979492
loss: 3.6776490211486816
loss: 3.3937315940856934
loss: 3.716278076171875
loss: 3.5988709926605225
loss: 3.34893536567688
loss: 3.9011623859405518
loss: 3.262600898742676
loss: 3.7187764644622803
loss: 3.749035120010376
loss: 3.4916975498199463
loss: 3.5042028427124023
loss: 3.6400983333587646
loss: 3.8922832012176514
loss: 3.45017147064209
loss: 3.776014804840088
loss: 3.560948610305786
loss: 3.7832484245300293
loss: 3.4360690116882324
loss: 3.3535280227661133
loss: 3.735757827758789
loss: 3.7329061031341553
loss: 3.602569580078125
loss: 3.1405112743377686
loss: 3.465179920196533
loss: 3.856996774673462
loss: 3.4290428161621094
loss: 3.6691086292266846
loss: 3.617586612701416
loss: 3.477614402770996
loss: 3.9060447216033936
loss: 3.289635181427002
loss: 3.471470355987549
loss: 3.3065056800842285
loss: 3.3466224670410156
loss: 3.495896816253662
loss: 3.752119779586792
loss: 4.121656894683838
loss: 3.5229649543762207
loss: 3.6338629722595215
loss: 3.5813605785369873
loss: 3.5222179889678955
loss: 3.4545202255249023
loss: 3.3833367824554443
[4,   200] loss: 3.587
loss: 3.8724191188812256
loss: 3.757690906524658
loss: 3.6922335624694824
loss: 3.2649998664855957
loss: 3.382723808288574
loss: 3.78375506401062
loss: 3.284550666809082
loss: 3.4871737957000732
loss: 3.5336527824401855
loss: 3.572922468185425
loss: 3.209092855453491
loss: 3.9678149223327637
loss: 3.5098793506622314
loss: 3.8945744037628174
loss: 3.470877170562744
loss: 3.794255256652832
loss: 3.376915454864502
loss: 3.7782912254333496
loss: 3.396742820739746
loss: 3.9112548828125
loss: 3.2453765869140625
loss: 3.233100175857544
loss: 4.069474697113037
loss: 3.4810290336608887
loss: 3.7524571418762207
loss: 3.6639904975891113
loss: 3.450103759765625
loss: 3.481829881668091
loss: 3.760110378265381
loss: 3.52362322807312
loss: 3.7595572471618652
loss: 3.8944027423858643
loss: 3.552236795425415
loss: 3.628734588623047
loss: 3.5173399448394775
loss: 3.6536803245544434
loss: 3.7846615314483643
loss: 3.4045681953430176
loss: 3.679443120956421
loss: 3.563729763031006
loss: 3.8716373443603516
loss: 3.460254192352295
loss: 3.7997303009033203
loss: 3.540839672088623
loss: 3.507690191268921
loss: 3.243149757385254
loss: 3.5532288551330566
loss: 3.4203872680664062
loss: 4.02695369720459
loss: 3.7445266246795654
loss: 3.9524049758911133
loss: 3.381427764892578
loss: 3.8113105297088623
loss: 3.514552593231201
loss: 3.6710205078125
loss: 3.204606533050537
loss: 3.6648788452148438
loss: 3.8006794452667236
loss: 3.2644500732421875
loss: 3.0662925243377686
loss: 3.5015976428985596
loss: 3.3632278442382812
loss: 3.714994430541992
loss: 3.5466949939727783
loss: 3.5674962997436523
loss: 3.62034010887146
loss: 3.402815580368042
loss: 3.534799098968506
loss: 3.438333749771118
loss: 3.3710737228393555
loss: 3.6899592876434326
loss: 3.6159043312072754
loss: 3.9518232345581055
loss: 3.767714262008667
loss: 3.3786420822143555
loss: 3.4474141597747803
loss: 3.3976967334747314
loss: 3.258587121963501
loss: 3.5774271488189697
loss: 3.350353240966797
loss: 3.5685524940490723
loss: 3.76298451423645
loss: 3.466608762741089
loss: 3.5451364517211914
loss: 3.890338897705078
loss: 3.5819060802459717
loss: 3.5847461223602295
loss: 3.5535359382629395
loss: 3.6211984157562256
loss: 3.412083387374878
loss: 3.6506998538970947
loss: 3.5414867401123047
loss: 3.8252298831939697
loss: 3.7562007904052734
loss: 3.4357833862304688
loss: 3.6685941219329834
loss: 3.2533700466156006
loss: 3.5558788776397705
loss: 3.395489454269409
loss: 3.5064585208892822
[4,   300] loss: 3.576
loss: 3.799862861633301
loss: 3.7607717514038086
loss: 3.427330732345581
loss: 3.486884593963623
loss: 3.308776378631592
loss: 3.8899760246276855
loss: 3.7705395221710205
loss: 3.1610872745513916
loss: 3.492025136947632
loss: 3.160433053970337
loss: 3.474531888961792
loss: 3.3694703578948975
loss: 3.976609945297241
Epoch 4 | Train Loss: 3.5830
100%|██████████| 32/32 [00:19<00:00,  1.65it/s]
 20%|██        | 4/20 [43:17<2:53:56, 652.25s/it]Epoch 4 | Eval Loss: 4.0205
loss: 2.992999792098999
loss: 3.393371343612671
loss: 3.492997884750366
loss: 3.457550287246704
loss: 3.378830909729004
loss: 3.164158821105957
loss: 3.245798110961914
loss: 2.9607033729553223
loss: 3.3387296199798584
loss: 3.043464183807373
loss: 3.204725742340088
loss: 3.611856460571289
loss: 2.777007579803467
loss: 3.269155502319336
loss: 3.020608425140381
loss: 3.1026880741119385
loss: 3.232178211212158
loss: 3.2011003494262695
loss: 3.610464096069336
loss: 2.9011824131011963
loss: 3.0059235095977783
loss: 3.626749277114868
loss: 3.2982609272003174
loss: 3.4249353408813477
loss: 2.8450212478637695
loss: 3.3997745513916016
loss: 2.9919958114624023
loss: 3.2820024490356445
loss: 3.5045974254608154
loss: 3.2083914279937744
loss: 3.0425562858581543
loss: 3.0051329135894775
loss: 3.169084072113037
loss: 3.362778902053833
loss: 3.4279935359954834
loss: 3.4530467987060547
loss: 3.1325607299804688
loss: 3.4554591178894043
loss: 3.1185543537139893
loss: 3.140819549560547
loss: 3.2827677726745605
loss: 3.4439308643341064
loss: 3.2839255332946777
loss: 3.280834913253784
loss: 3.2353286743164062
loss: 3.2458066940307617
loss: 3.126751661300659
loss: 3.3601603507995605
loss: 3.2377538681030273
loss: 3.43144154548645
loss: 3.3975253105163574
loss: 3.4728779792785645
loss: 3.2477385997772217
loss: 3.2944772243499756
loss: 3.274531841278076
loss: 3.376316547393799
loss: 3.346999406814575
loss: 2.9809165000915527
loss: 3.2672338485717773
loss: 3.196810245513916
loss: 3.2191834449768066
loss: 3.476604461669922
loss: 3.2650327682495117
loss: 3.4566140174865723
loss: 3.3645434379577637
loss: 3.2312967777252197
loss: 3.175645351409912
loss: 3.119108200073242
loss: 3.6558005809783936
loss: 2.9977989196777344
loss: 3.2613699436187744
loss: 2.9894821643829346
loss: 2.920686960220337
loss: 3.6081855297088623
loss: 3.22531795501709
loss: 2.9179508686065674
loss: 3.0658352375030518
loss: 3.167717456817627
loss: 3.40217924118042
loss: 3.1997833251953125
loss: 3.40779447555542
loss: 2.8214869499206543
loss: 3.215858221054077
loss: 3.1261284351348877
loss: 3.282012701034546
loss: 3.144041061401367
loss: 3.7290303707122803
loss: 2.6532363891601562
loss: 3.2905380725860596
loss: 3.1479556560516357
loss: 3.3997106552124023
loss: 3.2153913974761963
loss: 2.957806348800659
loss: 2.642242431640625
loss: 3.299442768096924
loss: 3.52272367477417
loss: 3.2707016468048096
loss: 3.371368885040283
loss: 3.405400037765503
loss: 3.231238603591919
[5,   100] loss: 3.239
loss: 3.090322971343994
loss: 3.326549530029297
loss: 3.119981527328491
loss: 3.343935012817383
loss: 2.783123016357422
loss: 3.329319477081299
loss: 3.2580316066741943
loss: 3.430464029312134
loss: 3.692251205444336
loss: 3.6488280296325684
loss: 3.1661555767059326
loss: 3.297929286956787
loss: 3.2171170711517334
loss: 3.4691641330718994
loss: 3.2704660892486572
loss: 3.339015007019043
loss: 3.172041416168213
loss: 3.6920342445373535
loss: 3.2596330642700195
loss: 3.3233635425567627
loss: 2.988668441772461
loss: 3.390617847442627
loss: 3.4816904067993164
loss: 3.4879062175750732
loss: 3.3951706886291504
loss: 3.2995240688323975
loss: 2.857813596725464
loss: 3.4168224334716797
loss: 3.229865312576294
loss: 2.992016315460205
loss: 3.5338380336761475
loss: 3.1853623390197754
loss: 3.2918102741241455
loss: 3.149737596511841
loss: 3.5951569080352783
loss: 3.237342357635498
loss: 3.021862506866455
loss: 3.5389022827148438
loss: 3.054003953933716
loss: 3.2889928817749023
loss: 3.3729467391967773
loss: 3.4114623069763184
loss: 3.397822856903076
loss: 3.3181769847869873
loss: 3.239449977874756
loss: 3.1106033325195312
loss: 3.1203465461730957
loss: 3.0200321674346924
loss: 3.0072133541107178
loss: 3.0799717903137207
loss: 3.282407760620117
loss: 2.803001880645752
loss: 3.390094041824341
loss: 3.4031174182891846
loss: 3.149379253387451
loss: 3.2293572425842285
loss: 3.2447397708892822
loss: 3.1891839504241943
loss: 3.2871968746185303
loss: 3.403012752532959
loss: 3.1019139289855957
loss: 3.2395694255828857
loss: 3.329129934310913
loss: 3.2121007442474365
loss: 3.400820732116699
loss: 3.1430890560150146
loss: 3.058023452758789
loss: 3.2179789543151855
loss: 3.4053776264190674
loss: 3.256519079208374
loss: 3.262336015701294
loss: 3.5309317111968994
loss: 3.4632351398468018
loss: 3.4357669353485107
loss: 3.299064874649048
loss: 3.071390151977539
loss: 2.8008508682250977
loss: 3.4141430854797363
loss: 3.6743054389953613
loss: 3.450394868850708
loss: 2.92264986038208
loss: 3.270967960357666
loss: 3.074816942214966
loss: 3.2351572513580322
loss: 3.304288864135742
loss: 3.464712619781494
loss: 3.30525279045105
loss: 3.0804498195648193
loss: 3.0186431407928467
loss: 3.145907163619995
loss: 3.2155873775482178
loss: 3.249568223953247
loss: 3.3555190563201904
loss: 3.223511219024658
loss: 3.5020012855529785
loss: 3.1407480239868164
loss: 3.1541147232055664
loss: 3.3098294734954834
loss: 2.952989101409912
loss: 3.203403949737549
[5,   200] loss: 3.260
loss: 3.3247575759887695
loss: 3.3701863288879395
loss: 3.069000482559204
loss: 3.3672752380371094
loss: 3.3072187900543213
loss: 3.6419336795806885
loss: 3.1427228450775146
loss: 3.367788553237915
loss: 3.2180700302124023
loss: 3.2626452445983887
loss: 3.0988190174102783
loss: 3.030127763748169
loss: 2.9172871112823486
loss: 3.1645591259002686
loss: 2.974405288696289
loss: 3.407632350921631
loss: 3.676206111907959
loss: 3.1768155097961426
loss: 3.167410135269165
loss: 3.213263511657715
loss: 3.3374311923980713
loss: 3.35722279548645
loss: 3.029998779296875
loss: 2.9768552780151367
loss: 3.4612984657287598
loss: 3.265850782394409
loss: 3.2572665214538574
loss: 3.2585346698760986
loss: 3.319098711013794
loss: 3.714900255203247
loss: 3.168930768966675
loss: 2.863156318664551
loss: 3.2407386302948
loss: 3.057220697402954
loss: 3.287461996078491
loss: 3.1747236251831055
loss: 2.9364094734191895
loss: 3.147578239440918
loss: 3.322845697402954
loss: 3.022434711456299
loss: 3.1711184978485107
loss: 3.513385772705078
loss: 3.103088617324829
loss: 2.766948699951172
loss: 3.429671287536621
loss: 3.0320680141448975
loss: 3.577648401260376
loss: 3.23500657081604
loss: 3.4884612560272217
loss: 3.3387610912323
loss: 3.0601367950439453
loss: 3.0179386138916016
loss: 2.9826319217681885
loss: 3.2133781909942627
loss: 3.174029588699341
loss: 3.080739736557007
loss: 3.2453134059906006
loss: 3.0434885025024414
loss: 3.227789878845215
loss: 3.3907485008239746
loss: 3.029498338699341
loss: 3.386105537414551
loss: 3.197819709777832
loss: 2.7205817699432373
loss: 2.9970169067382812
loss: 3.2393789291381836
loss: 3.085650682449341
loss: 3.520324230194092
loss: 3.2488481998443604
loss: 3.269639253616333
loss: 3.188584089279175
loss: 3.2450478076934814
loss: 3.44657039642334
loss: 3.156719446182251
loss: 2.9387028217315674
loss: 3.417374610900879
loss: 3.2431867122650146
loss: 3.069871187210083
loss: 3.1899068355560303
loss: 3.097458600997925
loss: 3.0032289028167725
loss: 2.896425724029541
loss: 3.083529472351074
loss: 3.2073516845703125
loss: 2.822125196456909
loss: 2.742952346801758
loss: 3.522892951965332
loss: 3.24649977684021
loss: 3.4004557132720947
loss: 3.3355584144592285
loss: 3.0677576065063477
loss: 3.26987361907959
loss: 3.201477289199829
loss: 3.7104039192199707
loss: 3.1004719734191895
loss: 3.1572654247283936
loss: 3.4205987453460693
loss: 3.1150074005126953
loss: 3.1518852710723877
loss: 3.3505516052246094
[5,   300] loss: 3.207
loss: 3.2921040058135986
loss: 3.28385591506958
loss: 3.047947883605957
loss: 2.919085741043091
loss: 3.2852861881256104
loss: 2.8161306381225586
loss: 3.3014683723449707
loss: 3.133539915084839
loss: 3.077709197998047
loss: 2.9958386421203613
loss: 3.390540361404419
loss: 3.087425708770752
loss: 3.906144618988037
Epoch 5 | Train Loss: 3.2338
100%|██████████| 32/32 [00:19<00:00,  1.62it/s]
 25%|██▌       | 5/20 [54:21<2:44:04, 656.32s/it]Epoch 5 | Eval Loss: 3.9094
loss: 2.9363691806793213
loss: 2.92563796043396
loss: 2.7339913845062256
loss: 2.779017210006714
loss: 2.9407050609588623
loss: 2.807072162628174
loss: 3.0072882175445557
loss: 3.010542869567871
loss: 2.941443920135498
loss: 2.8575141429901123
loss: 2.6034324169158936
loss: 2.9903135299682617
loss: 2.8002829551696777
loss: 2.833303213119507
loss: 3.040249824523926
loss: 3.0420665740966797
loss: 3.0615346431732178
loss: 2.857391119003296
loss: 2.835273265838623
loss: 2.765303134918213
loss: 2.693065881729126
loss: 2.577845573425293
loss: 2.478886127471924
loss: 3.2229373455047607
loss: 2.837057113647461
loss: 2.8904011249542236
loss: 2.9541687965393066
loss: 2.766536235809326
loss: 2.968263626098633
loss: 2.7921500205993652
loss: 2.9654459953308105
loss: 2.8663082122802734
loss: 2.7980475425720215
loss: 2.979323625564575
loss: 2.9095590114593506
loss: 3.2603561878204346
loss: 2.732512950897217
loss: 2.897096633911133
loss: 2.9598827362060547
loss: 2.9826457500457764
loss: 2.728757619857788
loss: 2.9475314617156982
loss: 3.0804250240325928
loss: 3.2273316383361816
loss: 2.7066428661346436
loss: 2.7584211826324463
loss: 2.7860605716705322
loss: 2.7003493309020996
loss: 2.556453227996826
loss: 2.8423688411712646
loss: 2.7835066318511963
loss: 2.7913031578063965
loss: 2.8045949935913086
loss: 3.0840156078338623
loss: 2.869858980178833
loss: 2.6460628509521484
loss: 2.8079590797424316
loss: 2.937227487564087
loss: 2.622784376144409
loss: 2.7208127975463867
loss: 2.781383991241455
loss: 3.051312208175659
loss: 2.709017753601074
loss: 2.838430166244507
loss: 2.464365005493164
loss: 2.5995147228240967
loss: 2.709324836730957
loss: 2.978593587875366
loss: 2.5517826080322266
loss: 3.1840226650238037
loss: 3.151033878326416
loss: 3.2353897094726562
loss: 2.640674591064453
loss: 2.7710111141204834
loss: 2.919724702835083
loss: 2.875432252883911
loss: 2.877464532852173
loss: 2.7875847816467285
loss: 3.3543014526367188
loss: 2.748358964920044
loss: 3.0062694549560547
loss: 2.9336750507354736
loss: 2.733095645904541
loss: 3.0183708667755127
loss: 2.9490432739257812
loss: 2.809678792953491
loss: 3.0903260707855225
loss: 2.751183032989502
loss: 2.8784799575805664
loss: 2.841294050216675
loss: 2.746622085571289
loss: 3.0706543922424316
loss: 2.9850144386291504
loss: 2.903559684753418
loss: 2.787407636642456
loss: 3.002034902572632
loss: 2.9437525272369385
loss: 3.1202642917633057
loss: 2.8581557273864746
loss: 2.747295618057251
[6,   100] loss: 2.871
loss: 2.93022084236145
loss: 3.0743496417999268
loss: 2.9049057960510254
loss: 3.3446338176727295
loss: 2.604036808013916
loss: 2.8666579723358154
loss: 2.863476514816284
loss: 2.958441972732544
loss: 2.817824125289917
loss: 2.6833012104034424
loss: 2.810781717300415
loss: 2.5899791717529297
loss: 2.823793888092041
loss: 2.7779767513275146
loss: 2.8378899097442627
loss: 2.8620338439941406
loss: 2.8411617279052734
loss: 2.881012201309204
loss: 3.0515921115875244
loss: 2.6638920307159424
loss: 2.513127088546753
loss: 2.79974365234375
loss: 2.7169864177703857
loss: 3.085172653198242
loss: 2.8264598846435547
loss: 2.944507360458374
loss: 2.819091558456421
loss: 3.0707364082336426
loss: 3.021385669708252
loss: 3.1354775428771973
loss: 2.8186228275299072
loss: 2.70115327835083
loss: 2.829951047897339
loss: 2.533613681793213
loss: 3.252748966217041
loss: 2.6960365772247314
loss: 2.9596123695373535
loss: 2.7800545692443848
loss: 2.8633768558502197
loss: 2.774397373199463
loss: 2.5624070167541504
loss: 2.999173164367676
loss: 2.9811034202575684
loss: 3.0152671337127686
loss: 2.875121593475342
loss: 2.8351492881774902
loss: 3.02578067779541
loss: 3.0673251152038574
loss: 2.984194755554199
loss: 2.7152249813079834
loss: 2.961510419845581
loss: 2.7508912086486816
loss: 3.189659833908081
loss: 2.897662401199341
loss: 2.6233112812042236
loss: 3.0991828441619873
loss: 2.8179287910461426
loss: 2.867483615875244
loss: 2.9622812271118164
loss: 2.7150204181671143
loss: 2.908294200897217
loss: 2.7127037048339844
loss: 2.5490574836730957
loss: 2.65598464012146
loss: 2.924969434738159
loss: 2.789843797683716
loss: 3.0821499824523926
loss: 2.8766744136810303
loss: 3.0442497730255127
loss: 2.7411611080169678
loss: 2.674562454223633
loss: 2.947195529937744
loss: 2.9897706508636475
loss: 3.0900588035583496
loss: 2.814185619354248
loss: 2.7060837745666504
loss: 2.6512467861175537
loss: 2.643723487854004
loss: 2.82686710357666
loss: 2.8685286045074463
loss: 2.984039783477783
loss: 3.03230619430542
loss: 3.3461830615997314
loss: 2.7229063510894775
loss: 2.6915745735168457
loss: 2.771284580230713
loss: 2.9788191318511963
loss: 2.6617822647094727
loss: 2.715496063232422
loss: 2.7898125648498535
loss: 2.844892978668213
loss: 2.966486692428589
loss: 2.9950435161590576
loss: 2.920955181121826
loss: 2.673705577850342
loss: 3.060131072998047
loss: 2.429549217224121
loss: 2.7042791843414307
loss: 2.502474069595337
loss: 3.063779592514038
[6,   200] loss: 2.856
loss: 2.9912607669830322
loss: 2.810537815093994
loss: 2.905851364135742
loss: 2.5478861331939697
loss: 2.7892165184020996
loss: 2.734875440597534
loss: 2.4358720779418945
loss: 2.804673910140991
loss: 2.531416416168213
loss: 2.6420071125030518
loss: 2.9736194610595703
loss: 3.0368871688842773
loss: 2.9317727088928223
loss: 2.8313770294189453
loss: 2.8412277698516846
loss: 3.006650447845459
loss: 2.90466570854187
loss: 2.9018242359161377
loss: 2.898592233657837
loss: 2.810248613357544
loss: 2.711977005004883
loss: 2.723851203918457
loss: 2.6573987007141113
loss: 2.895561695098877
loss: 3.092221975326538
loss: 2.929560422897339
loss: 3.116243839263916
loss: 2.82165789604187
loss: 2.9333410263061523
loss: 2.4745025634765625
loss: 3.100703477859497
loss: 2.6343636512756348
loss: 2.687105894088745
loss: 2.596879243850708
loss: 2.7518184185028076
loss: 2.859034538269043
loss: 2.9679696559906006
loss: 2.975555181503296
loss: 3.0647008419036865
loss: 2.796426773071289
loss: 2.954766035079956
loss: 2.6135945320129395
loss: 2.58803129196167
loss: 2.7473225593566895
loss: 2.6760153770446777
loss: 3.0124406814575195
loss: 2.7473130226135254
loss: 2.954829692840576
loss: 2.7716293334960938
loss: 2.7917888164520264
loss: 3.218817710876465
loss: 2.7289106845855713
loss: 2.798959970474243
loss: 3.01247239112854
loss: 2.7631146907806396
loss: 2.9063913822174072
loss: 2.5981407165527344
loss: 2.7971599102020264
loss: 2.905177593231201
loss: 3.0660150051116943
loss: 2.8809826374053955
loss: 3.1117024421691895
loss: 2.85906720161438
loss: 2.9652233123779297
loss: 2.7724897861480713
loss: 2.7343156337738037
loss: 2.946415901184082
loss: 2.847630262374878
loss: 2.452183961868286
loss: 2.9040753841400146
loss: 2.750589609146118
loss: 3.006863594055176
loss: 2.7204346656799316
loss: 2.8757030963897705
loss: 3.3886094093322754
loss: 2.5524590015411377
loss: 2.7041518688201904
loss: 2.8015518188476562
loss: 2.6334586143493652
loss: 3.015822172164917
loss: 2.8688385486602783
loss: 2.661499261856079
loss: 2.6265854835510254
loss: 2.7439825534820557
loss: 2.7040112018585205
loss: 2.741251230239868
loss: 2.8381714820861816
loss: 2.4155380725860596
loss: 2.896880626678467
loss: 2.6841888427734375
loss: 3.0000975131988525
loss: 2.8183417320251465
loss: 2.8483476638793945
loss: 2.8430933952331543
loss: 3.162540912628174
loss: 2.704362392425537
loss: 2.5946762561798096
loss: 2.4985272884368896
loss: 2.936431884765625
loss: 3.141063690185547
[6,   300] loss: 2.824
loss: 2.7440783977508545
loss: 2.5718271732330322
loss: 2.6377243995666504
loss: 2.6602442264556885
loss: 3.209743022918701
loss: 2.8184497356414795
loss: 2.931474447250366
loss: 2.877727508544922
loss: 2.763894557952881
loss: 2.788177728652954
loss: 2.9769208431243896
loss: 2.859339714050293
loss: 2.806285858154297
Epoch 6 | Train Loss: 2.8492
100%|██████████| 32/32 [00:19<00:00,  1.66it/s]
 30%|███       | 6/20 [1:05:28<2:34:02, 660.18s/it]Epoch 6 | Eval Loss: 3.7829
loss: 2.184129476547241
loss: 2.454347610473633
loss: 2.5587048530578613
loss: 2.5547730922698975
loss: 2.48626708984375
loss: 2.557856798171997
loss: 2.4846231937408447
loss: 2.3704240322113037
loss: 2.458077907562256
loss: 2.2001073360443115
loss: 2.5809378623962402
loss: 2.334878921508789
loss: 2.716756582260132
loss: 2.0972368717193604
loss: 2.3104450702667236
loss: 2.5309433937072754
loss: 2.518470287322998
loss: 2.6944854259490967
loss: 2.5007500648498535
loss: 2.408440351486206
loss: 2.329254150390625
loss: 2.8420028686523438
loss: 2.6683871746063232
loss: 2.6002256870269775
loss: 2.497507333755493
loss: 2.2037487030029297
loss: 2.4324278831481934
loss: 2.579165458679199
loss: 2.2040371894836426
loss: 2.294663429260254
loss: 2.6577508449554443
loss: 2.24765944480896
loss: 2.105741500854492
loss: 2.309624195098877
loss: 2.609611988067627
loss: 2.593743085861206
loss: 2.843719482421875
loss: 2.3410816192626953
loss: 2.574920177459717
loss: 2.380084991455078
loss: 2.5649521350860596
loss: 2.7555480003356934
loss: 2.178048610687256
loss: 2.375666856765747
loss: 2.3567395210266113
loss: 2.259425640106201
loss: 2.3319106101989746
loss: 2.2148265838623047
loss: 2.500250816345215
loss: 2.493036985397339
loss: 2.10746169090271
loss: 2.425452470779419
loss: 2.285649538040161
loss: 2.461902141571045
loss: 2.2232015132904053
loss: 2.1014626026153564
loss: 2.649374485015869
loss: 2.363259792327881
loss: 2.3525633811950684
loss: 2.4730310440063477
loss: 2.4189558029174805
loss: 2.3411269187927246
loss: 2.282780170440674
loss: 2.614128828048706
loss: 2.2807061672210693
loss: 2.475292921066284
loss: 2.504624605178833
loss: 1.925106406211853
loss: 2.428473711013794
loss: 2.5165281295776367
loss: 2.4670913219451904
loss: 2.4742343425750732
loss: 2.327483654022217
loss: 2.612781047821045
loss: 2.4975433349609375
loss: 2.6173458099365234
loss: 2.634671688079834
loss: 2.3522205352783203
loss: 2.261080503463745
loss: 2.472832202911377
loss: 2.250701665878296
loss: 2.937351703643799
loss: 2.6306443214416504
loss: 2.3519887924194336
loss: 2.6830081939697266
loss: 2.162018060684204
loss: 2.5240349769592285
loss: 2.3670847415924072
loss: 2.036694288253784
loss: 2.216917037963867
loss: 2.16282320022583
loss: 2.465853214263916
loss: 2.336702823638916
loss: 2.282357931137085
loss: 2.4534876346588135
loss: 2.668712854385376
loss: 2.2357637882232666
loss: 2.611046075820923
loss: 2.273371696472168
loss: 2.4156486988067627
[7,   100] loss: 2.424
loss: 2.415598154067993
loss: 2.6420998573303223
loss: 2.4255778789520264
loss: 2.4660165309906006
loss: 2.3945364952087402
loss: 2.3731372356414795
loss: 2.7440271377563477
loss: 2.477160692214966
loss: 2.5991063117980957
loss: 2.4688031673431396
loss: 2.8031818866729736
loss: 2.556480646133423
loss: 2.439749240875244
loss: 2.0438549518585205
loss: 2.4480443000793457
loss: 2.2955424785614014
loss: 2.5054104328155518
loss: 2.5277562141418457
loss: 2.6315677165985107
loss: 2.588758707046509
loss: 2.3314483165740967
loss: 2.4756386280059814
loss: 2.7048792839050293
loss: 2.729027032852173
loss: 2.2320563793182373
loss: 2.8534445762634277
loss: 2.302432060241699
loss: 2.4641404151916504
loss: 2.586113929748535
loss: 2.5650100708007812
loss: 2.514464855194092
loss: 2.8290398120880127
loss: 2.391078472137451
loss: 2.3243765830993652
loss: 2.4427099227905273
loss: 2.395627021789551
loss: 2.363840103149414
loss: 2.4132914543151855
loss: 2.732513189315796
loss: 2.319380283355713
loss: 2.237819194793701
loss: 2.58809494972229
loss: 2.7690563201904297
loss: 2.443434953689575
loss: 2.3240933418273926
loss: 2.511110305786133
loss: 2.7194948196411133
loss: 2.68239426612854
loss: 2.4366066455841064
loss: 2.5898022651672363
loss: 2.4973440170288086
loss: 2.404677391052246
loss: 2.4547343254089355
loss: 2.82108736038208
loss: 2.40967059135437
loss: 2.4646689891815186
loss: 2.550891637802124
loss: 2.6631600856781006
loss: 2.3432540893554688
loss: 2.560488224029541
loss: 2.3531651496887207
loss: 2.7502996921539307
loss: 2.4753804206848145
loss: 2.12675404548645
loss: 2.7453598976135254
loss: 2.474013090133667
loss: 2.5335333347320557
loss: 2.546126127243042
loss: 2.3699147701263428
loss: 2.4397225379943848
loss: 2.4725558757781982
loss: 2.548427104949951
loss: 2.3122904300689697
loss: 2.503767728805542
loss: 2.3202927112579346
loss: 2.51206374168396
loss: 2.690507650375366
loss: 2.5929059982299805
loss: 2.5093555450439453
loss: 2.4175515174865723
loss: 2.2131073474884033
loss: 2.565945625305176
loss: 2.5534257888793945
loss: 2.3117635250091553
loss: 2.355989694595337
loss: 2.5468108654022217
loss: 2.6397955417633057
loss: 2.561204671859741
loss: 2.5768136978149414
loss: 2.357738733291626
loss: 2.4621686935424805
loss: 2.3684656620025635
loss: 2.2151968479156494
loss: 2.4601664543151855
loss: 2.5828697681427
loss: 2.5369975566864014
loss: 2.2872650623321533
loss: 2.5731544494628906
loss: 2.5000579357147217
loss: 2.4749467372894287
[7,   200] loss: 2.491
loss: 2.4800922870635986
loss: 2.520977258682251
loss: 2.4127330780029297
loss: 2.5903830528259277
loss: 2.7478442192077637
loss: 2.368818521499634
loss: 2.109663248062134
loss: 2.5518558025360107
loss: 2.5400609970092773
loss: 2.450562000274658
loss: 2.5555338859558105
loss: 2.480013847351074
loss: 2.2951951026916504
loss: 2.5257909297943115
loss: 2.266831874847412
loss: 2.5381081104278564
loss: 2.7894651889801025
loss: 2.4154741764068604
loss: 2.5492453575134277
loss: 2.4997589588165283
loss: 2.8381640911102295
loss: 2.4292526245117188
loss: 2.719292163848877
loss: 2.553053379058838
loss: 2.535350799560547
loss: 2.2542665004730225
loss: 2.646263599395752
loss: 2.375467538833618
loss: 2.734347343444824
loss: 2.3532657623291016
loss: 2.4211981296539307
loss: 2.8065102100372314
loss: 2.8053438663482666
loss: 2.2745602130889893
loss: 2.5645639896392822
loss: 2.380643367767334
loss: 2.501905679702759
loss: 2.402872085571289
loss: 2.164827346801758
loss: 2.4322991371154785
loss: 2.621648073196411
loss: 2.198465347290039
loss: 2.7654669284820557
loss: 2.3312315940856934
loss: 2.484760284423828
loss: 2.313288688659668
loss: 2.3526954650878906
loss: 2.3823680877685547
loss: 2.7089266777038574
loss: 2.4537715911865234
loss: 2.5293962955474854
loss: 2.5845980644226074
loss: 2.3456461429595947
loss: 2.062389612197876
loss: 2.3931798934936523
loss: 2.6392970085144043
loss: 2.5129170417785645
loss: 2.6665287017822266
loss: 2.6268486976623535
loss: 2.291759967803955
loss: 2.648479461669922
loss: 2.344757318496704
loss: 2.641087770462036
loss: 2.240161180496216
loss: 2.5752646923065186
loss: 2.415102005004883
loss: 2.3245232105255127
loss: 2.630218029022217
loss: 2.652188301086426
loss: 2.308070421218872
loss: 2.42706561088562
loss: 2.64776611328125
loss: 2.784689426422119
loss: 2.5040476322174072
loss: 2.5057172775268555
loss: 2.743809461593628
loss: 2.5750539302825928
loss: 2.072216749191284
loss: 2.498049736022949
loss: 2.230134963989258
loss: 2.388578414916992
loss: 2.7286200523376465
loss: 2.610637664794922
loss: 2.750709056854248
loss: 2.473714828491211
loss: 2.5963525772094727
loss: 2.705575942993164
loss: 2.388906240463257
loss: 2.4928760528564453
loss: 2.6077473163604736
loss: 2.494703769683838
loss: 2.626176357269287
loss: 2.151139259338379
loss: 2.489898443222046
loss: 2.529301881790161
loss: 2.5277373790740967
loss: 2.511678457260132
loss: 2.113025665283203
loss: 2.703895092010498
loss: 2.421494483947754
[7,   300] loss: 2.492
loss: 2.149878978729248
loss: 2.5709168910980225
loss: 2.533533811569214
loss: 2.267576217651367
loss: 2.54158353805542
loss: 2.541722059249878
loss: 2.549992799758911
loss: 2.594663381576538
loss: 2.6038498878479004
loss: 2.5886967182159424
loss: 2.4879283905029297
loss: 2.5302014350891113
loss: 2.65403413772583
Epoch 7 | Train Loss: 2.4707
100%|██████████| 32/32 [00:19<00:00,  1.63it/s]
 35%|███▌      | 7/20 [1:16:33<2:23:22, 661.74s/it]Epoch 7 | Eval Loss: 3.7254
loss: 1.9653890132904053
loss: 1.8925904035568237
loss: 2.1587908267974854
loss: 1.944693684577942
loss: 1.9534392356872559
loss: 1.9056649208068848
loss: 1.9276347160339355
loss: 1.9418936967849731
loss: 2.030642032623291
loss: 2.0603811740875244
loss: 2.062432050704956
loss: 1.952047348022461
loss: 1.9380955696105957
loss: 2.014446973800659
loss: 2.057534694671631
loss: 1.8209028244018555
loss: 2.1701865196228027
loss: 2.011415481567383
loss: 1.7975109815597534
loss: 2.1444904804229736
loss: 2.1027486324310303
loss: 1.6238890886306763
loss: 2.059666156768799
loss: 2.007960557937622
loss: 1.9046001434326172
loss: 2.145028829574585
loss: 2.000619888305664
loss: 2.1555709838867188
loss: 2.0213217735290527
loss: 2.0851845741271973
loss: 1.7435154914855957
loss: 2.030988931655884
loss: 2.0975961685180664
loss: 1.7864341735839844
loss: 1.977476716041565
loss: 2.0466785430908203
loss: 1.9062556028366089
loss: 2.4576268196105957
loss: 1.9822945594787598
loss: 2.0869383811950684
loss: 2.1346828937530518
loss: 1.986037254333496
loss: 2.625014305114746
loss: 2.06986665725708
loss: 2.0789635181427
loss: 2.1206982135772705
loss: 1.8309916257858276
loss: 1.9847824573516846
loss: 2.2874393463134766
loss: 2.048412561416626
loss: 1.9716012477874756
loss: 2.1080539226531982
loss: 2.355926990509033
loss: 2.075674057006836
loss: 1.8502339124679565
loss: 2.0089330673217773
loss: 2.2046267986297607
loss: 2.0552592277526855
loss: 1.9241666793823242
loss: 1.942420482635498
loss: 2.008505344390869
loss: 1.9293320178985596
loss: 2.189129590988159
loss: 2.0746145248413086
loss: 2.0339853763580322
loss: 2.054133415222168
loss: 2.029157876968384
loss: 2.2560982704162598
loss: 2.1816415786743164
loss: 2.272596597671509
loss: 1.9606099128723145
loss: 2.2184152603149414
loss: 1.9780791997909546
loss: 1.9879467487335205
loss: 1.8798561096191406
loss: 1.9796262979507446
loss: 1.9746942520141602
loss: 2.0731112957000732
loss: 2.0232625007629395
loss: 2.226027727127075
loss: 2.096517562866211
loss: 2.2430999279022217
loss: 2.0990240573883057
loss: 2.2518110275268555
loss: 2.0633482933044434
loss: 1.6575534343719482
loss: 2.3190300464630127
loss: 2.0779361724853516
loss: 1.9259387254714966
loss: 2.119600772857666
loss: 2.11777663230896
loss: 1.9338099956512451
loss: 2.2179503440856934
loss: 2.550178050994873
loss: 2.487570285797119
loss: 2.087101936340332
loss: 2.166208028793335
loss: 1.9564788341522217
loss: 2.20450496673584
loss: 2.3392109870910645
[8,   100] loss: 2.059
loss: 2.5288825035095215
loss: 1.9179781675338745
loss: 2.0877771377563477
loss: 1.8659292459487915
loss: 2.084848642349243
loss: 2.0434374809265137
loss: 2.033653497695923
loss: 2.197603702545166
loss: 2.1105422973632812
loss: 2.0315499305725098
loss: 2.0320851802825928
loss: 1.8894751071929932
loss: 2.106524705886841
loss: 2.0451529026031494
loss: 2.1715035438537598
loss: 2.4197888374328613
loss: 2.0873944759368896
loss: 1.900192379951477
loss: 1.8398398160934448
loss: 1.9188772439956665
loss: 2.0906200408935547
loss: 2.3067708015441895
loss: 1.8962258100509644
loss: 2.1887705326080322
loss: 2.25097918510437
loss: 2.0144264698028564
loss: 2.4718236923217773
loss: 1.8483797311782837
loss: 2.3395509719848633
loss: 2.2396161556243896
loss: 2.29956316947937
loss: 1.9156877994537354
loss: 2.3201699256896973
loss: 2.2032155990600586
loss: 2.271355152130127
loss: 2.034766912460327
loss: 2.160717248916626
loss: 1.9641538858413696
loss: 2.11308217048645
loss: 2.3425662517547607
loss: 2.2329678535461426
loss: 1.9757190942764282
loss: 1.9524112939834595
loss: 2.098522424697876
loss: 2.0400638580322266
loss: 2.133829116821289
loss: 2.1370694637298584
loss: 2.0345406532287598
loss: 2.2303783893585205
loss: 2.063063859939575
loss: 2.270719289779663
loss: 2.3475098609924316
loss: 2.2333474159240723
loss: 2.258161783218384
loss: 2.0183982849121094
loss: 2.0472145080566406
loss: 2.381240129470825
loss: 2.1934263706207275
loss: 2.403987169265747
loss: 1.887649416923523
loss: 2.0850417613983154
loss: 2.0822463035583496
loss: 2.009361505508423
loss: 2.376648426055908
loss: 2.0916287899017334
loss: 2.359680414199829
loss: 2.254864454269409
loss: 1.9823912382125854
loss: 2.1189870834350586
loss: 1.9608889818191528
loss: 2.1308977603912354
loss: 2.2307827472686768
loss: 2.0293943881988525
loss: 2.0773696899414062
loss: 1.9488952159881592
loss: 2.2512638568878174
loss: 2.1820473670959473
loss: 2.168766498565674
loss: 2.205214500427246
loss: 2.1214797496795654
loss: 2.181446075439453
loss: 2.2845141887664795
loss: 2.1142449378967285
loss: 2.0476608276367188
loss: 1.7250725030899048
loss: 2.530299425125122
loss: 2.249788284301758
loss: 2.2897980213165283
loss: 2.170741081237793
loss: 2.0452077388763428
loss: 2.067941427230835
loss: 2.277317762374878
loss: 2.1919384002685547
loss: 2.06614351272583
loss: 2.09961199760437
loss: 2.3399040699005127
loss: 2.001811981201172
loss: 2.019761562347412
loss: 2.304395914077759
loss: 2.092327117919922
[8,   200] loss: 2.133
loss: 2.3947200775146484
loss: 1.972291111946106
loss: 2.03201961517334
loss: 2.108978033065796
loss: 2.116790533065796
loss: 2.1146397590637207
loss: 2.1284141540527344
loss: 2.4328832626342773
loss: 1.8870720863342285
loss: 2.154160499572754
loss: 2.450420379638672
loss: 1.9523390531539917
loss: 2.2152059078216553
loss: 1.9417946338653564
loss: 2.07607102394104
loss: 2.050006866455078
loss: 2.137294054031372
loss: 2.374868631362915
loss: 1.9604068994522095
loss: 2.156484842300415
loss: 2.0209670066833496
loss: 1.9360579252243042
loss: 2.038564443588257
loss: 2.124312162399292
loss: 1.9345767498016357
loss: 2.155355453491211
loss: 1.8994585275650024
loss: 2.045888662338257
loss: 2.3696448802948
loss: 2.0762999057769775
loss: 2.126067638397217
loss: 1.9665591716766357
loss: 2.172588348388672
loss: 2.2918853759765625
loss: 2.1357901096343994
loss: 2.0828168392181396
loss: 2.065488576889038
loss: 2.2025437355041504
loss: 2.2526707649230957
loss: 2.1640498638153076
loss: 1.9474177360534668
loss: 2.0340659618377686
loss: 2.246504783630371
loss: 2.2345986366271973
loss: 2.3430733680725098
loss: 2.3398277759552
loss: 2.1448984146118164
loss: 1.992416501045227
loss: 2.1112256050109863
loss: 2.2512145042419434
loss: 2.1644437313079834
loss: 2.4343442916870117
loss: 1.9915046691894531
loss: 2.06329083442688
loss: 2.2263147830963135
loss: 2.2063119411468506
loss: 2.074389696121216
loss: 1.94971764087677
loss: 2.097688913345337
loss: 2.048985481262207
loss: 2.1422104835510254
loss: 2.143772840499878
loss: 2.198777675628662
loss: 2.183885097503662
loss: 2.2513794898986816
loss: 2.159599781036377
loss: 2.321265935897827
loss: 2.3360166549682617
loss: 2.1145243644714355
loss: 2.1695404052734375
loss: 2.1805903911590576
loss: 2.237393617630005
loss: 2.117859125137329
loss: 2.1227476596832275
loss: 2.5858733654022217
loss: 2.1756937503814697
loss: 2.0345942974090576
loss: 2.355710029602051
loss: 2.0033538341522217
loss: 2.2210397720336914
loss: 2.0327799320220947
loss: 2.2723326683044434
loss: 2.0860438346862793
loss: 1.6861697435379028
loss: 1.9085512161254883
loss: 1.9180432558059692
loss: 2.020420789718628
loss: 2.0416648387908936
loss: 2.1609230041503906
loss: 1.928890585899353
loss: 2.26295804977417
loss: 2.2949678897857666
loss: 2.3961634635925293
loss: 2.2360024452209473
loss: 2.007239580154419
loss: 2.0662474632263184
loss: 2.3648643493652344
loss: 2.1059186458587646
loss: 2.136669397354126
loss: 2.023681879043579
[8,   300] loss: 2.136
loss: 2.2187156677246094
loss: 2.3154730796813965
loss: 2.1830291748046875
loss: 2.127032518386841
loss: 1.9901769161224365
loss: 2.21089243888855
loss: 2.183403730392456
loss: 1.8592313528060913
loss: 2.3308191299438477
loss: 2.3786118030548096
loss: 2.312791347503662
loss: 2.1317760944366455
loss: 1.9837822914123535
Epoch 8 | Train Loss: 2.1119
100%|██████████| 32/32 [00:19<00:00,  1.65it/s]
 40%|████      | 8/20 [1:27:39<2:12:33, 662.81s/it]Epoch 8 | Eval Loss: 3.6305
loss: 1.642735481262207
loss: 1.4509830474853516
loss: 1.8544632196426392
loss: 1.7645373344421387
loss: 1.7294570207595825
loss: 1.689128041267395
loss: 1.7912594079971313
loss: 1.6647059917449951
loss: 1.7133921384811401
loss: 2.062696695327759
loss: 1.7211450338363647
loss: 1.821385383605957
loss: 1.6933175325393677
loss: 1.659422516822815
loss: 1.7059835195541382
loss: 1.7593016624450684
loss: 1.7032604217529297
loss: 1.5284751653671265
loss: 1.9755840301513672
loss: 1.5996311902999878
loss: 1.756121039390564
loss: 1.820764422416687
loss: 1.774472713470459
loss: 1.7351365089416504
loss: 1.8364728689193726
loss: 1.8548303842544556
loss: 2.03643798828125
loss: 1.688292145729065
loss: 1.6533092260360718
loss: 1.4690521955490112
loss: 1.779497504234314
loss: 1.725725531578064
loss: 1.4715029001235962
loss: 1.7816656827926636
loss: 1.492554783821106
loss: 1.477028250694275
loss: 1.85557222366333
loss: 1.625335693359375
loss: 1.6535756587982178
loss: 1.7698581218719482
loss: 1.5508203506469727
loss: 1.8301591873168945
loss: 1.9733259677886963
loss: 1.9234004020690918
loss: 1.6478888988494873
loss: 1.6420327425003052
loss: 2.0386669635772705
loss: 1.9313267469406128
loss: 1.837221622467041
loss: 1.6338037252426147
loss: 2.0780162811279297
loss: 1.759827733039856
loss: 1.9055849313735962
loss: 1.9017399549484253
loss: 1.7561051845550537
loss: 1.8356521129608154
loss: 1.8651823997497559
loss: 1.7267175912857056
loss: 1.838572382926941
loss: 1.7698568105697632
loss: 1.677300214767456
loss: 1.9130499362945557
loss: 1.7418155670166016
loss: 1.711236596107483
loss: 1.7245910167694092
loss: 1.933367133140564
loss: 1.8052083253860474
loss: 1.7340198755264282
loss: 1.745793104171753
loss: 1.522517204284668
loss: 1.9658422470092773
loss: 1.7842744588851929
loss: 1.8118762969970703
loss: 2.1239287853240967
loss: 1.762109398841858
loss: 1.9159296751022339
loss: 1.7844465970993042
loss: 1.916048288345337
loss: 1.9250528812408447
loss: 1.7514046430587769
loss: 1.750193476676941
loss: 1.9604243040084839
loss: 1.8615127801895142
loss: 1.7664587497711182
loss: 1.655026912689209
loss: 1.6634737253189087
loss: 1.9557236433029175
loss: 1.8790184259414673
loss: 1.715436577796936
loss: 1.7847496271133423
loss: 1.9305081367492676
loss: 1.5355185270309448
loss: 1.758443832397461
loss: 1.8584696054458618
loss: 1.6747963428497314
loss: 1.665128231048584
loss: 1.7549817562103271
loss: 1.5680322647094727
loss: 1.6309967041015625
loss: 1.8388913869857788
[9,   100] loss: 1.767
loss: 1.6216222047805786
loss: 1.8607091903686523
loss: 1.7852798700332642
loss: 1.8445643186569214
loss: 1.7887351512908936
loss: 1.8187986612319946
loss: 1.6713947057724
loss: 1.7349721193313599
loss: 1.8268004655838013
loss: 1.7470591068267822
loss: 1.9867194890975952
loss: 2.075777053833008
loss: 1.8520267009735107
loss: 1.7297883033752441
loss: 1.6964828968048096
loss: 1.8872342109680176
loss: 1.9176759719848633
loss: 1.7629083395004272
loss: 1.7930994033813477
loss: 1.9180166721343994
loss: 1.5703006982803345
loss: 1.8062697649002075
loss: 1.9233200550079346
loss: 2.052031993865967
loss: 1.8640154600143433
loss: 1.553418755531311
loss: 1.677484393119812
loss: 1.7984305620193481
loss: 1.8163723945617676
loss: 1.891534447669983
loss: 1.949695348739624
loss: 1.8081681728363037
loss: 1.7645550966262817
loss: 1.8466463088989258
loss: 1.5060533285140991
loss: 1.8959190845489502
loss: 1.8347814083099365
loss: 2.130056381225586
loss: 1.8720557689666748
loss: 1.9755967855453491
loss: 1.8896687030792236
loss: 1.6912009716033936
loss: 2.0077011585235596
loss: 1.7535985708236694
loss: 1.8662865161895752
loss: 1.8188107013702393
loss: 1.7536972761154175
loss: 1.7971135377883911
loss: 1.5614643096923828
loss: 1.5882666110992432
loss: 1.8899515867233276
loss: 1.6919984817504883
loss: 1.7529577016830444
loss: 1.875712513923645
loss: 1.8646868467330933
loss: 1.7454842329025269
loss: 1.6502318382263184
loss: 1.755056619644165
loss: 1.8211983442306519
loss: 1.9585238695144653
loss: 1.7258048057556152
loss: 1.9110581874847412
loss: 1.8593199253082275
loss: 1.6544498205184937
loss: 1.8368386030197144
loss: 2.065430164337158
loss: 1.8624249696731567
loss: 1.9275364875793457
loss: 2.1800012588500977
loss: 1.5547668933868408
loss: 1.6218839883804321
loss: 2.001641273498535
loss: 1.6910865306854248
loss: 1.5046002864837646
loss: 1.4772237539291382
loss: 1.8074169158935547
loss: 2.117720365524292
loss: 1.7874675989151
loss: 1.918803334236145
loss: 1.8530564308166504
loss: 1.5030701160430908
loss: 1.7536956071853638
loss: 1.932037353515625
loss: 2.134895086288452
loss: 1.5825291872024536
loss: 1.8696043491363525
loss: 1.6932843923568726
loss: 1.7082079648971558
loss: 1.9528224468231201
loss: 1.9989428520202637
loss: 1.9696866273880005
loss: 1.635133981704712
loss: 1.8498588800430298
loss: 1.7137296199798584
loss: 1.8034827709197998
loss: 1.9821323156356812
loss: 1.8922747373580933
loss: 1.7966651916503906
loss: 1.6409547328948975
loss: 1.9806965589523315
[9,   200] loss: 1.813
loss: 1.577573299407959
loss: 1.6144639253616333
loss: 1.6853338479995728
loss: 1.9973832368850708
loss: 1.6556860208511353
loss: 2.253380537033081
loss: 1.9938695430755615
loss: 1.682414174079895
loss: 1.9652652740478516
loss: 1.7402410507202148
loss: 1.7917646169662476
loss: 1.9389688968658447
loss: 1.9579530954360962
loss: 1.6335135698318481
loss: 1.6561652421951294
loss: 2.161837339401245
loss: 1.8760986328125
loss: 1.8957653045654297
loss: 1.8652743101119995
loss: 1.9022972583770752
loss: 1.7572213411331177
loss: 1.716701626777649
loss: 1.7211730480194092
loss: 1.5925816297531128
loss: 1.8041170835494995
loss: 1.798871636390686
loss: 1.9978523254394531
loss: 1.932847261428833
loss: 2.006176471710205
loss: 1.780705213546753
loss: 1.6997402906417847
loss: 2.346491575241089
loss: 1.945670247077942
loss: 1.9092479944229126
loss: 1.8541839122772217
loss: 1.7329031229019165
loss: 1.6117439270019531
loss: 2.026853561401367
loss: 1.845885157585144
loss: 1.8841495513916016
loss: 2.080254077911377
loss: 1.8507564067840576
loss: 2.017310619354248
loss: 1.741317629814148
loss: 1.8913207054138184
loss: 1.527345895767212
loss: 2.0663373470306396
loss: 1.5954692363739014
loss: 2.0821099281311035
loss: 1.8601576089859009
loss: 1.7714345455169678
loss: 1.8279956579208374
loss: 1.8845860958099365
loss: 1.9029368162155151
loss: 1.901123046875
loss: 1.859026312828064
loss: 1.8204394578933716
loss: 1.75960111618042
loss: 2.085777521133423
loss: 1.9405642747879028
loss: 1.6427074670791626
loss: 1.8621554374694824
loss: 1.7521798610687256
loss: 1.7937595844268799
loss: 1.856878638267517
loss: 1.9025888442993164
loss: 1.9142943620681763
loss: 1.6180188655853271
loss: 1.8335075378417969
loss: 1.932052493095398
loss: 1.6266899108886719
loss: 1.776259183883667
loss: 1.803488850593567
loss: 1.7605197429656982
loss: 1.7924354076385498
loss: 2.059506416320801
loss: 1.6833008527755737
loss: 1.8389496803283691
loss: 1.8390369415283203
loss: 1.6405831575393677
loss: 1.9182647466659546
loss: 1.8689897060394287
loss: 1.6152305603027344
loss: 2.159728527069092
loss: 1.8546581268310547
loss: 1.7802883386611938
loss: 1.8319908380508423
loss: 1.8175277709960938
loss: 1.9178049564361572
loss: 1.9247277975082397
loss: 1.7939188480377197
loss: 2.0179455280303955
loss: 1.8008668422698975
loss: 1.9708508253097534
loss: 2.0497941970825195
loss: 1.7968831062316895
loss: 1.795398235321045
loss: 1.9837133884429932
loss: 1.8332442045211792
loss: 1.6448464393615723
[9,   300] loss: 1.846
loss: 1.7969341278076172
loss: 1.877883791923523
loss: 1.878542423248291
loss: 1.8554781675338745
loss: 1.5647881031036377
loss: 2.0511598587036133
loss: 2.0289244651794434
loss: 1.9468259811401367
loss: 1.8987362384796143
loss: 1.8779882192611694
loss: 1.70750093460083
loss: 1.6849727630615234
loss: 1.90077543258667
Epoch 9 | Train Loss: 1.8105
100%|██████████| 32/32 [00:19<00:00,  1.63it/s]
                                                   Epoch 9 | Eval Loss: 3.6622
Early stopping...

